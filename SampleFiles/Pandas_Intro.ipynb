{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " s = pd.Series([1,3,5,np.nan,6,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     3\n",
       "2     5\n",
       "3   NaN\n",
       "4     6\n",
       "5     8\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = pd.date_range('20130101', periods=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n",
       "               '2013-01-05', '2013-01-06'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>-0.933725</td>\n",
       "      <td>-1.686625</td>\n",
       "      <td>0.734706</td>\n",
       "      <td>-0.270680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.070754</td>\n",
       "      <td>0.645371</td>\n",
       "      <td>-0.335992</td>\n",
       "      <td>1.954248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.844866</td>\n",
       "      <td>-0.192917</td>\n",
       "      <td>-0.454513</td>\n",
       "      <td>0.810609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-1.312353</td>\n",
       "      <td>0.144470</td>\n",
       "      <td>-0.517330</td>\n",
       "      <td>-1.575527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-1.984207</td>\n",
       "      <td>1.156644</td>\n",
       "      <td>0.838379</td>\n",
       "      <td>-1.109181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>0.442428</td>\n",
       "      <td>-1.381972</td>\n",
       "      <td>0.872564</td>\n",
       "      <td>-1.892367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-01 -0.933725 -1.686625  0.734706 -0.270680\n",
       "2013-01-02 -0.070754  0.645371 -0.335992  1.954248\n",
       "2013-01-03 -0.844866 -0.192917 -0.454513  0.810609\n",
       "2013-01-04 -1.312353  0.144470 -0.517330 -1.575527\n",
       "2013-01-05 -1.984207  1.156644  0.838379 -1.109181\n",
       "2013-01-06  0.442428 -1.381972  0.872564 -1.892367"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({ 'A' : 1.,'B' : pd.Timestamp('20130102'),'C' : pd.Series(1,index=list(range(4)),dtype='float32'),'D' : np.array([3] * 4,dtype='int32'),'E' : pd.Categorical([\"test\",\"train\",\"test\",\"train\"]),'F' : 'foo' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A          B  C  D      E    F\n",
       "0  1 2013-01-02  1  3   test  foo\n",
       "1  1 2013-01-02  1  3  train  foo\n",
       "2  1 2013-01-02  1  3   test  foo\n",
       "3  1 2013-01-02  1  3  train  foo"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A           float64\n",
       "B    datetime64[ns]\n",
       "C           float32\n",
       "D             int32\n",
       "E          category\n",
       "F            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>-0.933725</td>\n",
       "      <td>-1.686625</td>\n",
       "      <td>0.734706</td>\n",
       "      <td>-0.270680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.070754</td>\n",
       "      <td>0.645371</td>\n",
       "      <td>-0.335992</td>\n",
       "      <td>1.954248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-01 -0.933725 -1.686625  0.734706 -0.270680\n",
       "2013-01-02 -0.070754  0.645371 -0.335992  1.954248"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-1.312353</td>\n",
       "      <td>0.144470</td>\n",
       "      <td>-0.517330</td>\n",
       "      <td>-1.575527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-1.984207</td>\n",
       "      <td>1.156644</td>\n",
       "      <td>0.838379</td>\n",
       "      <td>-1.109181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>0.442428</td>\n",
       "      <td>-1.381972</td>\n",
       "      <td>0.872564</td>\n",
       "      <td>-1.892367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-04 -1.312353  0.144470 -0.517330 -1.575527\n",
       "2013-01-05 -1.984207  1.156644  0.838379 -1.109181\n",
       "2013-01-06  0.442428 -1.381972  0.872564 -1.892367"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n",
       "               '2013-01-05', '2013-01-06'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'A', u'B', u'C', u'D'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.93372547, -1.68662545,  0.73470627, -0.27067956],\n",
       "       [-0.07075399,  0.64537121, -0.33599194,  1.95424784],\n",
       "       [-0.84486578, -0.192917  , -0.45451282,  0.81060851],\n",
       "       [-1.31235293,  0.14447031, -0.51732957, -1.57552748],\n",
       "       [-1.9842073 ,  1.15664408,  0.83837927, -1.10918092],\n",
       "       [ 0.44242807, -1.38197244,  0.87256448, -1.89236737]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.783913</td>\n",
       "      <td>-0.219172</td>\n",
       "      <td>0.189636</td>\n",
       "      <td>-0.347150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.867020</td>\n",
       "      <td>1.120603</td>\n",
       "      <td>0.689257</td>\n",
       "      <td>1.491307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.984207</td>\n",
       "      <td>-1.686625</td>\n",
       "      <td>-0.517330</td>\n",
       "      <td>-1.892367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.217696</td>\n",
       "      <td>-1.084709</td>\n",
       "      <td>-0.424883</td>\n",
       "      <td>-1.458941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.889296</td>\n",
       "      <td>-0.024223</td>\n",
       "      <td>0.199357</td>\n",
       "      <td>-0.689930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.264282</td>\n",
       "      <td>0.520146</td>\n",
       "      <td>0.812461</td>\n",
       "      <td>0.540286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.442428</td>\n",
       "      <td>1.156644</td>\n",
       "      <td>0.872564</td>\n",
       "      <td>1.954248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         B         C         D\n",
       "count  6.000000  6.000000  6.000000  6.000000\n",
       "mean  -0.783913 -0.219172  0.189636 -0.347150\n",
       "std    0.867020  1.120603  0.689257  1.491307\n",
       "min   -1.984207 -1.686625 -0.517330 -1.892367\n",
       "25%   -1.217696 -1.084709 -0.424883 -1.458941\n",
       "50%   -0.889296 -0.024223  0.199357 -0.689930\n",
       "75%   -0.264282  0.520146  0.812461  0.540286\n",
       "max    0.442428  1.156644  0.872564  1.954248"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2013-01-01 00:00:00</th>\n",
       "      <th>2013-01-02 00:00:00</th>\n",
       "      <th>2013-01-03 00:00:00</th>\n",
       "      <th>2013-01-04 00:00:00</th>\n",
       "      <th>2013-01-05 00:00:00</th>\n",
       "      <th>2013-01-06 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>-0.933725</td>\n",
       "      <td>-0.070754</td>\n",
       "      <td>-0.844866</td>\n",
       "      <td>-1.312353</td>\n",
       "      <td>-1.984207</td>\n",
       "      <td>0.442428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-1.686625</td>\n",
       "      <td>0.645371</td>\n",
       "      <td>-0.192917</td>\n",
       "      <td>0.144470</td>\n",
       "      <td>1.156644</td>\n",
       "      <td>-1.381972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.734706</td>\n",
       "      <td>-0.335992</td>\n",
       "      <td>-0.454513</td>\n",
       "      <td>-0.517330</td>\n",
       "      <td>0.838379</td>\n",
       "      <td>0.872564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>-0.270680</td>\n",
       "      <td>1.954248</td>\n",
       "      <td>0.810609</td>\n",
       "      <td>-1.575527</td>\n",
       "      <td>-1.109181</td>\n",
       "      <td>-1.892367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2013-01-01  2013-01-02  2013-01-03  2013-01-04  2013-01-05  2013-01-06\n",
       "A   -0.933725   -0.070754   -0.844866   -1.312353   -1.984207    0.442428\n",
       "B   -1.686625    0.645371   -0.192917    0.144470    1.156644   -1.381972\n",
       "C    0.734706   -0.335992   -0.454513   -0.517330    0.838379    0.872564\n",
       "D   -0.270680    1.954248    0.810609   -1.575527   -1.109181   -1.892367"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>-0.270680</td>\n",
       "      <td>0.734706</td>\n",
       "      <td>-1.686625</td>\n",
       "      <td>-0.933725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>1.954248</td>\n",
       "      <td>-0.335992</td>\n",
       "      <td>0.645371</td>\n",
       "      <td>-0.070754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.810609</td>\n",
       "      <td>-0.454513</td>\n",
       "      <td>-0.192917</td>\n",
       "      <td>-0.844866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-1.575527</td>\n",
       "      <td>-0.517330</td>\n",
       "      <td>0.144470</td>\n",
       "      <td>-1.312353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-1.109181</td>\n",
       "      <td>0.838379</td>\n",
       "      <td>1.156644</td>\n",
       "      <td>-1.984207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>-1.892367</td>\n",
       "      <td>0.872564</td>\n",
       "      <td>-1.381972</td>\n",
       "      <td>0.442428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   D         C         B         A\n",
       "2013-01-01 -0.270680  0.734706 -1.686625 -0.933725\n",
       "2013-01-02  1.954248 -0.335992  0.645371 -0.070754\n",
       "2013-01-03  0.810609 -0.454513 -0.192917 -0.844866\n",
       "2013-01-04 -1.575527 -0.517330  0.144470 -1.312353\n",
       "2013-01-05 -1.109181  0.838379  1.156644 -1.984207\n",
       "2013-01-06 -1.892367  0.872564 -1.381972  0.442428"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_index(axis=1,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-1.984207</td>\n",
       "      <td>1.156644</td>\n",
       "      <td>0.838379</td>\n",
       "      <td>-1.109181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.070754</td>\n",
       "      <td>0.645371</td>\n",
       "      <td>-0.335992</td>\n",
       "      <td>1.954248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-1.312353</td>\n",
       "      <td>0.144470</td>\n",
       "      <td>-0.517330</td>\n",
       "      <td>-1.575527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.844866</td>\n",
       "      <td>-0.192917</td>\n",
       "      <td>-0.454513</td>\n",
       "      <td>0.810609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>0.442428</td>\n",
       "      <td>-1.381972</td>\n",
       "      <td>0.872564</td>\n",
       "      <td>-1.892367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>-0.933725</td>\n",
       "      <td>-1.686625</td>\n",
       "      <td>0.734706</td>\n",
       "      <td>-0.270680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-05 -1.984207  1.156644  0.838379 -1.109181\n",
       "2013-01-02 -0.070754  0.645371 -0.335992  1.954248\n",
       "2013-01-04 -1.312353  0.144470 -0.517330 -1.575527\n",
       "2013-01-03 -0.844866 -0.192917 -0.454513  0.810609\n",
       "2013-01-06  0.442428 -1.381972  0.872564 -1.892367\n",
       "2013-01-01 -0.933725 -1.686625  0.734706 -0.270680"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='B',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013-01-01   -0.933725\n",
       "2013-01-02   -0.070754\n",
       "2013-01-03   -0.844866\n",
       "2013-01-04   -1.312353\n",
       "2013-01-05   -1.984207\n",
       "2013-01-06    0.442428\n",
       "Freq: D, Name: A, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>-0.933725</td>\n",
       "      <td>-1.686625</td>\n",
       "      <td>0.734706</td>\n",
       "      <td>-0.270680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.070754</td>\n",
       "      <td>0.645371</td>\n",
       "      <td>-0.335992</td>\n",
       "      <td>1.954248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.844866</td>\n",
       "      <td>-0.192917</td>\n",
       "      <td>-0.454513</td>\n",
       "      <td>0.810609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-01 -0.933725 -1.686625  0.734706 -0.270680\n",
       "2013-01-02 -0.070754  0.645371 -0.335992  1.954248\n",
       "2013-01-03 -0.844866 -0.192917 -0.454513  0.810609"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.070754</td>\n",
       "      <td>0.645371</td>\n",
       "      <td>-0.335992</td>\n",
       "      <td>1.954248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.844866</td>\n",
       "      <td>-0.192917</td>\n",
       "      <td>-0.454513</td>\n",
       "      <td>0.810609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-1.312353</td>\n",
       "      <td>0.144470</td>\n",
       "      <td>-0.517330</td>\n",
       "      <td>-1.575527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-02 -0.070754  0.645371 -0.335992  1.954248\n",
       "2013-01-03 -0.844866 -0.192917 -0.454513  0.810609\n",
       "2013-01-04 -1.312353  0.144470 -0.517330 -1.575527"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['20130102':'20130104']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A   -0.933725\n",
       "B   -1.686625\n",
       "C    0.734706\n",
       "D   -0.270680\n",
       "Name: 2013-01-01 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[dates[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>-0.933725</td>\n",
       "      <td>-1.686625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.070754</td>\n",
       "      <td>0.645371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.844866</td>\n",
       "      <td>-0.192917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-1.312353</td>\n",
       "      <td>0.144470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-1.984207</td>\n",
       "      <td>1.156644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>0.442428</td>\n",
       "      <td>-1.381972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B\n",
       "2013-01-01 -0.933725 -1.686625\n",
       "2013-01-02 -0.070754  0.645371\n",
       "2013-01-03 -0.844866 -0.192917\n",
       "2013-01-04 -1.312353  0.144470\n",
       "2013-01-05 -1.984207  1.156644\n",
       "2013-01-06  0.442428 -1.381972"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,['A','B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.070754</td>\n",
       "      <td>0.645371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.844866</td>\n",
       "      <td>-0.192917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-1.312353</td>\n",
       "      <td>0.144470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B\n",
       "2013-01-02 -0.070754  0.645371\n",
       "2013-01-03 -0.844866 -0.192917\n",
       "2013-01-04 -1.312353  0.144470"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['20130102':'20130104',['A','B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.93372547282129414"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[dates[0],'A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.93372547282129414"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.at[dates[0],'A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A   -1.312353\n",
       "B    0.144470\n",
       "C   -0.517330\n",
       "D   -1.575527\n",
       "Name: 2013-01-04 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-1.312353</td>\n",
       "      <td>0.144470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-1.984207</td>\n",
       "      <td>1.156644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B\n",
       "2013-01-04 -1.312353  0.144470\n",
       "2013-01-05 -1.984207  1.156644"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3:5,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.070754</td>\n",
       "      <td>-0.335992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.844866</td>\n",
       "      <td>-0.454513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-1.984207</td>\n",
       "      <td>0.838379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         C\n",
       "2013-01-02 -0.070754 -0.335992\n",
       "2013-01-03 -0.844866 -0.454513\n",
       "2013-01-05 -1.984207  0.838379"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[1,2,4],[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.070754</td>\n",
       "      <td>0.645371</td>\n",
       "      <td>-0.335992</td>\n",
       "      <td>1.954248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.844866</td>\n",
       "      <td>-0.192917</td>\n",
       "      <td>-0.454513</td>\n",
       "      <td>0.810609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-02 -0.070754  0.645371 -0.335992  1.954248\n",
       "2013-01-03 -0.844866 -0.192917 -0.454513  0.810609"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>-1.686625</td>\n",
       "      <td>0.734706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>0.645371</td>\n",
       "      <td>-0.335992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.192917</td>\n",
       "      <td>-0.454513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>0.144470</td>\n",
       "      <td>-0.517330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>1.156644</td>\n",
       "      <td>0.838379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>-1.381972</td>\n",
       "      <td>0.872564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   B         C\n",
       "2013-01-01 -1.686625  0.734706\n",
       "2013-01-02  0.645371 -0.335992\n",
       "2013-01-03 -0.192917 -0.454513\n",
       "2013-01-04  0.144470 -0.517330\n",
       "2013-01-05  1.156644  0.838379\n",
       "2013-01-06 -1.381972  0.872564"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64537121291942579"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64537121291942579"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iat[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734706</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.954248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.810609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.144470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.156644</td>\n",
       "      <td>0.838379</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>0.442428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.872564</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-01       NaN       NaN  0.734706       NaN\n",
       "2013-01-02       NaN  0.645371       NaN  1.954248\n",
       "2013-01-03       NaN       NaN       NaN  0.810609\n",
       "2013-01-04       NaN  0.144470       NaN       NaN\n",
       "2013-01-05       NaN  1.156644  0.838379       NaN\n",
       "2013-01-06  0.442428       NaN  0.872564       NaN"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>-0.933725</td>\n",
       "      <td>-1.686625</td>\n",
       "      <td>0.734706</td>\n",
       "      <td>-0.270680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.070754</td>\n",
       "      <td>0.645371</td>\n",
       "      <td>-0.335992</td>\n",
       "      <td>1.954248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.844866</td>\n",
       "      <td>-0.192917</td>\n",
       "      <td>-0.454513</td>\n",
       "      <td>0.810609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-1.312353</td>\n",
       "      <td>0.144470</td>\n",
       "      <td>-0.517330</td>\n",
       "      <td>-1.575527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-1.984207</td>\n",
       "      <td>1.156644</td>\n",
       "      <td>0.838379</td>\n",
       "      <td>-1.109181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>0.442428</td>\n",
       "      <td>-1.381972</td>\n",
       "      <td>0.872564</td>\n",
       "      <td>-1.892367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-01 -0.933725 -1.686625  0.734706 -0.270680\n",
       "2013-01-02 -0.070754  0.645371 -0.335992  1.954248\n",
       "2013-01-03 -0.844866 -0.192917 -0.454513  0.810609\n",
       "2013-01-04 -1.312353  0.144470 -0.517330 -1.575527\n",
       "2013-01-05 -1.984207  1.156644  0.838379 -1.109181\n",
       "2013-01-06  0.442428 -1.381972  0.872564 -1.892367"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2['E'] = ['one', 'one','two','three','four','three']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>-0.933725</td>\n",
       "      <td>-1.686625</td>\n",
       "      <td>0.734706</td>\n",
       "      <td>-0.270680</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.070754</td>\n",
       "      <td>0.645371</td>\n",
       "      <td>-0.335992</td>\n",
       "      <td>1.954248</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.844866</td>\n",
       "      <td>-0.192917</td>\n",
       "      <td>-0.454513</td>\n",
       "      <td>0.810609</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-1.312353</td>\n",
       "      <td>0.144470</td>\n",
       "      <td>-0.517330</td>\n",
       "      <td>-1.575527</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-1.984207</td>\n",
       "      <td>1.156644</td>\n",
       "      <td>0.838379</td>\n",
       "      <td>-1.109181</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>0.442428</td>\n",
       "      <td>-1.381972</td>\n",
       "      <td>0.872564</td>\n",
       "      <td>-1.892367</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D      E\n",
       "2013-01-01 -0.933725 -1.686625  0.734706 -0.270680    one\n",
       "2013-01-02 -0.070754  0.645371 -0.335992  1.954248    one\n",
       "2013-01-03 -0.844866 -0.192917 -0.454513  0.810609    two\n",
       "2013-01-04 -1.312353  0.144470 -0.517330 -1.575527  three\n",
       "2013-01-05 -1.984207  1.156644  0.838379 -1.109181   four\n",
       "2013-01-06  0.442428 -1.381972  0.872564 -1.892367  three"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.844866</td>\n",
       "      <td>-0.192917</td>\n",
       "      <td>-0.454513</td>\n",
       "      <td>0.810609</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-1.984207</td>\n",
       "      <td>1.156644</td>\n",
       "      <td>0.838379</td>\n",
       "      <td>-1.109181</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D     E\n",
       "2013-01-03 -0.844866 -0.192917 -0.454513  0.810609   two\n",
       "2013-01-05 -1.984207  1.156644  0.838379 -1.109181  four"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['E'].isin(['two','four'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series([1,2,3,4,5,6], index=pd.date_range('20130102', periods=6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013-01-02    1\n",
       "2013-01-03    2\n",
       "2013-01-04    3\n",
       "2013-01-05    4\n",
       "2013-01-06    5\n",
       "2013-01-07    6\n",
       "Freq: D, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['F'] = s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.at[dates[0],'A'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.iat[0,1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iat[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[:,'D'] = np.array([5] * len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.734706</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.070754</td>\n",
       "      <td>0.645371</td>\n",
       "      <td>-0.335992</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.844866</td>\n",
       "      <td>-0.192917</td>\n",
       "      <td>-0.454513</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-1.312353</td>\n",
       "      <td>0.144470</td>\n",
       "      <td>-0.517330</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-1.984207</td>\n",
       "      <td>1.156644</td>\n",
       "      <td>0.838379</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>0.442428</td>\n",
       "      <td>-1.381972</td>\n",
       "      <td>0.872564</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D   F\n",
       "2013-01-01  0.000000  0.000000  0.734706  5 NaN\n",
       "2013-01-02 -0.070754  0.645371 -0.335992  5   1\n",
       "2013-01-03 -0.844866 -0.192917 -0.454513  5   2\n",
       "2013-01-04 -1.312353  0.144470 -0.517330  5   3\n",
       "2013-01-05 -1.984207  1.156644  0.838379  5   4\n",
       "2013-01-06  0.442428 -1.381972  0.872564  5   5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.734706</td>\n",
       "      <td>-5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.070754</td>\n",
       "      <td>-0.645371</td>\n",
       "      <td>-0.335992</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.844866</td>\n",
       "      <td>-0.192917</td>\n",
       "      <td>-0.454513</td>\n",
       "      <td>-5</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-1.312353</td>\n",
       "      <td>-0.144470</td>\n",
       "      <td>-0.517330</td>\n",
       "      <td>-5</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-1.984207</td>\n",
       "      <td>-1.156644</td>\n",
       "      <td>-0.838379</td>\n",
       "      <td>-5</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>-0.442428</td>\n",
       "      <td>-1.381972</td>\n",
       "      <td>-0.872564</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D   F\n",
       "2013-01-01  0.000000  0.000000 -0.734706 -5 NaN\n",
       "2013-01-02 -0.070754 -0.645371 -0.335992 -5  -1\n",
       "2013-01-03 -0.844866 -0.192917 -0.454513 -5  -2\n",
       "2013-01-04 -1.312353 -0.144470 -0.517330 -5  -3\n",
       "2013-01-05 -1.984207 -1.156644 -0.838379 -5  -4\n",
       "2013-01-06 -0.442428 -1.381972 -0.872564 -5  -5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2[df2 > 0] = -df2\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.734706</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.070754</td>\n",
       "      <td>0.645371</td>\n",
       "      <td>-0.335992</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.844866</td>\n",
       "      <td>-0.192917</td>\n",
       "      <td>-0.454513</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-1.312353</td>\n",
       "      <td>0.144470</td>\n",
       "      <td>-0.517330</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D   F   E\n",
       "2013-01-01  0.000000  0.000000  0.734706  5 NaN   1\n",
       "2013-01-02 -0.070754  0.645371 -0.335992  5   1   1\n",
       "2013-01-03 -0.844866 -0.192917 -0.454513  5   2 NaN\n",
       "2013-01-04 -1.312353  0.144470 -0.517330  5   3 NaN"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])\n",
    "df1.loc[dates[0]:dates[1],'E'] = 1\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.070754</td>\n",
       "      <td>0.645371</td>\n",
       "      <td>-0.335992</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D  F  E\n",
       "2013-01-02 -0.070754  0.645371 -0.335992  5  1  1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.734706</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.070754</td>\n",
       "      <td>0.645371</td>\n",
       "      <td>-0.335992</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.844866</td>\n",
       "      <td>-0.192917</td>\n",
       "      <td>-0.454513</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-1.312353</td>\n",
       "      <td>0.144470</td>\n",
       "      <td>-0.517330</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D  F  E\n",
       "2013-01-01  0.000000  0.000000  0.734706  5  5  1\n",
       "2013-01-02 -0.070754  0.645371 -0.335992  5  1  1\n",
       "2013-01-03 -0.844866 -0.192917 -0.454513  5  2  5\n",
       "2013-01-04 -1.312353  0.144470 -0.517330  5  3  5"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.fillna(value=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A      B      C      D      F      E\n",
       "2013-01-01  False  False  False  False   True  False\n",
       "2013-01-02  False  False  False  False  False  False\n",
       "2013-01-03  False  False  False  False  False   True\n",
       "2013-01-04  False  False  False  False  False   True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013-01-01    1.433677\n",
       "2013-01-02    1.247725\n",
       "2013-01-03    1.101541\n",
       "2013-01-04    1.262958\n",
       "2013-01-05    1.802163\n",
       "2013-01-06    1.986604\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013-01-01   NaN\n",
       "2013-01-02   NaN\n",
       "2013-01-03     1\n",
       "2013-01-04     3\n",
       "2013-01-05     5\n",
       "2013-01-06   NaN\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1,3,5,np.nan,6,8], index=dates).shift(2)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-1.844866</td>\n",
       "      <td>-1.192917</td>\n",
       "      <td>-1.454513</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-4.312353</td>\n",
       "      <td>-2.855530</td>\n",
       "      <td>-3.517330</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-6.984207</td>\n",
       "      <td>-3.843356</td>\n",
       "      <td>-4.161621</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C   D   F\n",
       "2013-01-01       NaN       NaN       NaN NaN NaN\n",
       "2013-01-02       NaN       NaN       NaN NaN NaN\n",
       "2013-01-03 -1.844866 -1.192917 -1.454513   4   1\n",
       "2013-01-04 -4.312353 -2.855530 -3.517330   2   0\n",
       "2013-01-05 -6.984207 -3.843356 -4.161621   0  -1\n",
       "2013-01-06       NaN       NaN       NaN NaN NaN"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sub(s, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.734706</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.070754</td>\n",
       "      <td>0.645371</td>\n",
       "      <td>0.398714</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.915620</td>\n",
       "      <td>0.452454</td>\n",
       "      <td>-0.055798</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-2.227973</td>\n",
       "      <td>0.596925</td>\n",
       "      <td>-0.573128</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-4.212180</td>\n",
       "      <td>1.753569</td>\n",
       "      <td>0.265251</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>-3.769752</td>\n",
       "      <td>0.371596</td>\n",
       "      <td>1.137816</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C   D   F\n",
       "2013-01-01  0.000000  0.000000  0.734706   5 NaN\n",
       "2013-01-02 -0.070754  0.645371  0.398714  10   1\n",
       "2013-01-03 -0.915620  0.452454 -0.055798  15   3\n",
       "2013-01-04 -2.227973  0.596925 -0.573128  20   6\n",
       "2013-01-05 -4.212180  1.753569  0.265251  25  10\n",
       "2013-01-06 -3.769752  0.371596  1.137816  30  15"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(np.cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    2.426635\n",
       "B    2.538617\n",
       "C    1.389894\n",
       "D    0.000000\n",
       "F    4.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    5\n",
       "2    3\n",
       "3    2\n",
       "4    6\n",
       "5    1\n",
       "6    0\n",
       "7    5\n",
       "8    0\n",
       "9    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(np.random.randint(0, 7, size=10))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2\n",
       "3    2\n",
       "2    2\n",
       "0    2\n",
       "6    1\n",
       "1    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       a\n",
       "1       b\n",
       "2       c\n",
       "3    aaba\n",
       "4    baca\n",
       "5     NaN\n",
       "6    caba\n",
       "7     dog\n",
       "8     cat\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])\n",
    "s.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.794910</td>\n",
       "      <td>1.110969</td>\n",
       "      <td>0.016898</td>\n",
       "      <td>0.948162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.881747</td>\n",
       "      <td>1.452845</td>\n",
       "      <td>-1.904949</td>\n",
       "      <td>0.543701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.284155</td>\n",
       "      <td>1.888038</td>\n",
       "      <td>-0.488088</td>\n",
       "      <td>0.411991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.211955</td>\n",
       "      <td>1.681698</td>\n",
       "      <td>-0.217110</td>\n",
       "      <td>-0.823888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.223768</td>\n",
       "      <td>-0.446847</td>\n",
       "      <td>1.403090</td>\n",
       "      <td>0.931342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.188499</td>\n",
       "      <td>1.324541</td>\n",
       "      <td>-0.917753</td>\n",
       "      <td>-0.124960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.626289</td>\n",
       "      <td>-1.728559</td>\n",
       "      <td>0.008784</td>\n",
       "      <td>-0.485294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.129983</td>\n",
       "      <td>0.099810</td>\n",
       "      <td>-0.246409</td>\n",
       "      <td>1.234392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.566164</td>\n",
       "      <td>-0.766213</td>\n",
       "      <td>0.657971</td>\n",
       "      <td>0.101130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.035788</td>\n",
       "      <td>0.093231</td>\n",
       "      <td>-0.554276</td>\n",
       "      <td>-0.717671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  0.794910  1.110969  0.016898  0.948162\n",
       "1  0.881747  1.452845 -1.904949  0.543701\n",
       "2  1.284155  1.888038 -0.488088  0.411991\n",
       "3  1.211955  1.681698 -0.217110 -0.823888\n",
       "4  0.223768 -0.446847  1.403090  0.931342\n",
       "5 -0.188499  1.324541 -0.917753 -0.124960\n",
       "6 -1.626289 -1.728559  0.008784 -0.485294\n",
       "7  0.129983  0.099810 -0.246409  1.234392\n",
       "8  1.566164 -0.766213  0.657971  0.101130\n",
       "9  0.035788  0.093231 -0.554276 -0.717671"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.794910</td>\n",
       "      <td>1.110969</td>\n",
       "      <td>0.016898</td>\n",
       "      <td>0.948162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.881747</td>\n",
       "      <td>1.452845</td>\n",
       "      <td>-1.904949</td>\n",
       "      <td>0.543701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.284155</td>\n",
       "      <td>1.888038</td>\n",
       "      <td>-0.488088</td>\n",
       "      <td>0.411991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.211955</td>\n",
       "      <td>1.681698</td>\n",
       "      <td>-0.217110</td>\n",
       "      <td>-0.823888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.223768</td>\n",
       "      <td>-0.446847</td>\n",
       "      <td>1.403090</td>\n",
       "      <td>0.931342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.188499</td>\n",
       "      <td>1.324541</td>\n",
       "      <td>-0.917753</td>\n",
       "      <td>-0.124960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.626289</td>\n",
       "      <td>-1.728559</td>\n",
       "      <td>0.008784</td>\n",
       "      <td>-0.485294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.129983</td>\n",
       "      <td>0.099810</td>\n",
       "      <td>-0.246409</td>\n",
       "      <td>1.234392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.566164</td>\n",
       "      <td>-0.766213</td>\n",
       "      <td>0.657971</td>\n",
       "      <td>0.101130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.035788</td>\n",
       "      <td>0.093231</td>\n",
       "      <td>-0.554276</td>\n",
       "      <td>-0.717671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  0.794910  1.110969  0.016898  0.948162\n",
       "1  0.881747  1.452845 -1.904949  0.543701\n",
       "2  1.284155  1.888038 -0.488088  0.411991\n",
       "3  1.211955  1.681698 -0.217110 -0.823888\n",
       "4  0.223768 -0.446847  1.403090  0.931342\n",
       "5 -0.188499  1.324541 -0.917753 -0.124960\n",
       "6 -1.626289 -1.728559  0.008784 -0.485294\n",
       "7  0.129983  0.099810 -0.246409  1.234392\n",
       "8  1.566164 -0.766213  0.657971  0.101130\n",
       "9  0.035788  0.093231 -0.554276 -0.717671"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pieces = [df[:3], df[3:7], df[7:]]\n",
    "pd.concat(pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key': ['foo', 'foo'], 'lval': [1, 2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>lval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  lval\n",
       "0  foo     1\n",
       "1  foo     2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>rval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foo</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  rval\n",
       "0  foo     4\n",
       "1  foo     5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]})\n",
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>lval</th>\n",
       "      <th>rval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foo</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foo</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>foo</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  lval  rval\n",
       "0  foo     1     4\n",
       "1  foo     1     5\n",
       "2  foo     2     4\n",
       "3  foo     2     5"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(left, right, on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.211609</td>\n",
       "      <td>-1.891279</td>\n",
       "      <td>-1.430581</td>\n",
       "      <td>-1.132062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.235443</td>\n",
       "      <td>0.020386</td>\n",
       "      <td>-0.085041</td>\n",
       "      <td>0.818348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.840145</td>\n",
       "      <td>-1.237004</td>\n",
       "      <td>-0.536518</td>\n",
       "      <td>-0.588825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.624471</td>\n",
       "      <td>0.699432</td>\n",
       "      <td>-0.403098</td>\n",
       "      <td>0.876243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.999186</td>\n",
       "      <td>0.495178</td>\n",
       "      <td>-0.661440</td>\n",
       "      <td>0.201023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.364006</td>\n",
       "      <td>-0.156587</td>\n",
       "      <td>-0.364337</td>\n",
       "      <td>0.666723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.560201</td>\n",
       "      <td>-1.893087</td>\n",
       "      <td>-0.806649</td>\n",
       "      <td>-0.612377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.353108</td>\n",
       "      <td>-0.847906</td>\n",
       "      <td>1.246821</td>\n",
       "      <td>-1.396700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "0  1.211609 -1.891279 -1.430581 -1.132062\n",
       "1 -1.235443  0.020386 -0.085041  0.818348\n",
       "2  0.840145 -1.237004 -0.536518 -0.588825\n",
       "3  1.624471  0.699432 -0.403098  0.876243\n",
       "4 -0.999186  0.495178 -0.661440  0.201023\n",
       "5  0.364006 -0.156587 -0.364337  0.666723\n",
       "6  0.560201 -1.893087 -0.806649 -0.612377\n",
       "7 -1.353108 -0.847906  1.246821 -1.396700"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(8, 4), columns=['A','B','C','D'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.211609</td>\n",
       "      <td>-1.891279</td>\n",
       "      <td>-1.430581</td>\n",
       "      <td>-1.132062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.235443</td>\n",
       "      <td>0.020386</td>\n",
       "      <td>-0.085041</td>\n",
       "      <td>0.818348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.840145</td>\n",
       "      <td>-1.237004</td>\n",
       "      <td>-0.536518</td>\n",
       "      <td>-0.588825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.624471</td>\n",
       "      <td>0.699432</td>\n",
       "      <td>-0.403098</td>\n",
       "      <td>0.876243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.999186</td>\n",
       "      <td>0.495178</td>\n",
       "      <td>-0.661440</td>\n",
       "      <td>0.201023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.364006</td>\n",
       "      <td>-0.156587</td>\n",
       "      <td>-0.364337</td>\n",
       "      <td>0.666723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.560201</td>\n",
       "      <td>-1.893087</td>\n",
       "      <td>-0.806649</td>\n",
       "      <td>-0.612377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.353108</td>\n",
       "      <td>-0.847906</td>\n",
       "      <td>1.246821</td>\n",
       "      <td>-1.396700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.624471</td>\n",
       "      <td>0.699432</td>\n",
       "      <td>-0.403098</td>\n",
       "      <td>0.876243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "0  1.211609 -1.891279 -1.430581 -1.132062\n",
       "1 -1.235443  0.020386 -0.085041  0.818348\n",
       "2  0.840145 -1.237004 -0.536518 -0.588825\n",
       "3  1.624471  0.699432 -0.403098  0.876243\n",
       "4 -0.999186  0.495178 -0.661440  0.201023\n",
       "5  0.364006 -0.156587 -0.364337  0.666723\n",
       "6  0.560201 -1.893087 -0.806649 -0.612377\n",
       "7 -1.353108 -0.847906  1.246821 -1.396700\n",
       "8  1.624471  0.699432 -0.403098  0.876243"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df.iloc[3]\n",
    "df.append(s,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>one</td>\n",
       "      <td>-0.026827</td>\n",
       "      <td>0.378569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bar</td>\n",
       "      <td>one</td>\n",
       "      <td>-0.575202</td>\n",
       "      <td>-0.417487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foo</td>\n",
       "      <td>two</td>\n",
       "      <td>-0.221085</td>\n",
       "      <td>-0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bar</td>\n",
       "      <td>three</td>\n",
       "      <td>0.919471</td>\n",
       "      <td>-0.888065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>foo</td>\n",
       "      <td>two</td>\n",
       "      <td>0.356406</td>\n",
       "      <td>1.216909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bar</td>\n",
       "      <td>two</td>\n",
       "      <td>-0.297687</td>\n",
       "      <td>-0.870837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>foo</td>\n",
       "      <td>one</td>\n",
       "      <td>0.585363</td>\n",
       "      <td>1.092969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>foo</td>\n",
       "      <td>three</td>\n",
       "      <td>-1.870521</td>\n",
       "      <td>1.329503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A      B         C         D\n",
       "0  foo    one -0.026827  0.378569\n",
       "1  bar    one -0.575202 -0.417487\n",
       "2  foo    two -0.221085 -0.002930\n",
       "3  bar  three  0.919471 -0.888065\n",
       "4  foo    two  0.356406  1.216909\n",
       "5  bar    two -0.297687 -0.870837\n",
       "6  foo    one  0.585363  1.092969\n",
       "7  foo  three -1.870521  1.329503"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
    "   ....:                           'foo', 'bar', 'foo', 'foo'],\n",
    "   ....:                    'B' : ['one', 'one', 'two', 'three',\n",
    "   ....:                           'two', 'two', 'one', 'three'],\n",
    "   ....:                    'C' : np.random.randn(8),\n",
    "   ....:                    'D' : np.random.randn(8)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">bar</th>\n",
       "      <th>one</th>\n",
       "      <td>-0.575202</td>\n",
       "      <td>-0.417487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>0.919471</td>\n",
       "      <td>-0.888065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-0.297687</td>\n",
       "      <td>-0.870837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">foo</th>\n",
       "      <th>one</th>\n",
       "      <td>0.558535</td>\n",
       "      <td>1.471538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>-1.870521</td>\n",
       "      <td>1.329503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>0.135321</td>\n",
       "      <td>1.213979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  C         D\n",
       "A   B                        \n",
       "bar one   -0.575202 -0.417487\n",
       "    three  0.919471 -0.888065\n",
       "    two   -0.297687 -0.870837\n",
       "foo one    0.558535  1.471538\n",
       "    three -1.870521  1.329503\n",
       "    two    0.135321  1.213979"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['A','B']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bar</th>\n",
       "      <th>one</th>\n",
       "      <td>0.240912</td>\n",
       "      <td>2.075088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>1.555329</td>\n",
       "      <td>0.263674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">baz</th>\n",
       "      <th>one</th>\n",
       "      <td>-1.751003</td>\n",
       "      <td>1.746611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-0.307005</td>\n",
       "      <td>-0.389579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A         B\n",
       "first second                    \n",
       "bar   one     0.240912  2.075088\n",
       "      two     1.555329  0.263674\n",
       "baz   one    -1.751003  1.746611\n",
       "      two    -0.307005 -0.389579"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples = list(zip(*[['bar', 'bar', 'baz', 'baz',\n",
    "   ....:                      'foo', 'foo', 'qux', 'qux'],\n",
    "   ....:                     ['one', 'two', 'one', 'two',\n",
    "   ....:                      'one', 'two', 'one', 'two']]))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B'])\n",
    "df2 = df[:4]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first  second   \n",
       "bar    one     A    0.240912\n",
       "               B    2.075088\n",
       "       two     A    1.555329\n",
       "               B    0.263674\n",
       "baz    one     A   -1.751003\n",
       "               B    1.746611\n",
       "       two     A   -0.307005\n",
       "               B   -0.389579\n",
       "dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked = df2.stack()\n",
    "stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bar</th>\n",
       "      <th>one</th>\n",
       "      <td>0.240912</td>\n",
       "      <td>2.075088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>1.555329</td>\n",
       "      <td>0.263674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">baz</th>\n",
       "      <th>one</th>\n",
       "      <td>-1.751003</td>\n",
       "      <td>1.746611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-0.307005</td>\n",
       "      <td>-0.389579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A         B\n",
       "first second                    \n",
       "bar   one     0.240912  2.075088\n",
       "      two     1.555329  0.263674\n",
       "baz   one    -1.751003  1.746611\n",
       "      two    -0.307005 -0.389579"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>second</th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bar</th>\n",
       "      <th>A</th>\n",
       "      <td>0.240912</td>\n",
       "      <td>1.555329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>2.075088</td>\n",
       "      <td>0.263674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">baz</th>\n",
       "      <th>A</th>\n",
       "      <td>-1.751003</td>\n",
       "      <td>-0.307005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>1.746611</td>\n",
       "      <td>-0.389579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "second        one       two\n",
       "first                      \n",
       "bar   A  0.240912  1.555329\n",
       "      B  2.075088  0.263674\n",
       "baz   A -1.751003 -0.307005\n",
       "      B  1.746611 -0.389579"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.unstack(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>bar</th>\n",
       "      <th>baz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">one</th>\n",
       "      <th>A</th>\n",
       "      <td>0.240912</td>\n",
       "      <td>-1.751003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>2.075088</td>\n",
       "      <td>1.746611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">two</th>\n",
       "      <th>A</th>\n",
       "      <td>1.555329</td>\n",
       "      <td>-0.307005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.263674</td>\n",
       "      <td>-0.389579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "first          bar       baz\n",
       "second                      \n",
       "one    A  0.240912 -1.751003\n",
       "       B  2.075088  1.746611\n",
       "two    A  1.555329 -0.307005\n",
       "       B  0.263674 -0.389579"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>A</td>\n",
       "      <td>foo</td>\n",
       "      <td>-1.704042</td>\n",
       "      <td>2.161522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one</td>\n",
       "      <td>B</td>\n",
       "      <td>foo</td>\n",
       "      <td>0.449398</td>\n",
       "      <td>0.638134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>two</td>\n",
       "      <td>C</td>\n",
       "      <td>foo</td>\n",
       "      <td>2.526100</td>\n",
       "      <td>-0.297249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>three</td>\n",
       "      <td>A</td>\n",
       "      <td>bar</td>\n",
       "      <td>0.694994</td>\n",
       "      <td>-0.035348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one</td>\n",
       "      <td>B</td>\n",
       "      <td>bar</td>\n",
       "      <td>-0.532760</td>\n",
       "      <td>0.100867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>one</td>\n",
       "      <td>C</td>\n",
       "      <td>bar</td>\n",
       "      <td>0.501186</td>\n",
       "      <td>-2.668392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>two</td>\n",
       "      <td>A</td>\n",
       "      <td>foo</td>\n",
       "      <td>-1.996052</td>\n",
       "      <td>0.751271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>three</td>\n",
       "      <td>B</td>\n",
       "      <td>foo</td>\n",
       "      <td>-0.204894</td>\n",
       "      <td>-1.249270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>one</td>\n",
       "      <td>C</td>\n",
       "      <td>foo</td>\n",
       "      <td>-1.076649</td>\n",
       "      <td>-1.392830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>one</td>\n",
       "      <td>A</td>\n",
       "      <td>bar</td>\n",
       "      <td>1.024328</td>\n",
       "      <td>-0.234666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>two</td>\n",
       "      <td>B</td>\n",
       "      <td>bar</td>\n",
       "      <td>0.361821</td>\n",
       "      <td>2.112590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>three</td>\n",
       "      <td>C</td>\n",
       "      <td>bar</td>\n",
       "      <td>-1.474350</td>\n",
       "      <td>0.638276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        A  B    C         D         E\n",
       "0     one  A  foo -1.704042  2.161522\n",
       "1     one  B  foo  0.449398  0.638134\n",
       "2     two  C  foo  2.526100 -0.297249\n",
       "3   three  A  bar  0.694994 -0.035348\n",
       "4     one  B  bar -0.532760  0.100867\n",
       "5     one  C  bar  0.501186 -2.668392\n",
       "6     two  A  foo -1.996052  0.751271\n",
       "7   three  B  foo -0.204894 -1.249270\n",
       "8     one  C  foo -1.076649 -1.392830\n",
       "9     one  A  bar  1.024328 -0.234666\n",
       "10    two  B  bar  0.361821  2.112590\n",
       "11  three  C  bar -1.474350  0.638276"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'A' : ['one', 'one', 'two', 'three'] * 3,\n",
    "   .....:                    'B' : ['A', 'B', 'C'] * 4,\n",
    "   .....:                    'C' : ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,\n",
    "   .....:                    'D' : np.random.randn(12),\n",
    "   .....:                    'E' : np.random.randn(12)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>bar</th>\n",
       "      <th>foo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">one</th>\n",
       "      <th>A</th>\n",
       "      <td>1.024328</td>\n",
       "      <td>-1.704042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-0.532760</td>\n",
       "      <td>0.449398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.501186</td>\n",
       "      <td>-1.076649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">three</th>\n",
       "      <th>A</th>\n",
       "      <td>0.694994</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.204894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>-1.474350</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">two</th>\n",
       "      <th>A</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.996052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.361821</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.526100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "C             bar       foo\n",
       "A     B                    \n",
       "one   A  1.024328 -1.704042\n",
       "      B -0.532760  0.449398\n",
       "      C  0.501186 -1.076649\n",
       "three A  0.694994       NaN\n",
       "      B       NaN -0.204894\n",
       "      C -1.474350       NaN\n",
       "two   A       NaN -1.996052\n",
       "      B  0.361821       NaN\n",
       "      C       NaN  2.526100"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-01-01    21713\n",
       "Freq: 10T, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = pd.date_range('1/1/2012', periods=100, freq='S')\n",
    "ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)\n",
    "ts.resample('10Min', how='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-06   -0.959711\n",
       "2012-03-07    0.526086\n",
       "2012-03-08   -0.521024\n",
       "2012-03-09    0.654200\n",
       "2012-03-10    0.886755\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = pd.date_range('3/6/2012 00:00', periods=5, freq='D')\n",
    "ts = pd.Series(np.random.randn(len(rng)), rng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Series in module pandas.core.series:\n",
      "\n",
      "class Series(pandas.core.base.IndexOpsMixin, pandas.core.strings.StringAccessorMixin, pandas.core.generic.NDFrame)\n",
      " |  One-dimensional ndarray with axis labels (including time series).\n",
      " |  \n",
      " |  Labels need not be unique but must be any hashable type. The object\n",
      " |  supports both integer- and label-based indexing and provides a host of\n",
      " |  methods for performing operations involving the index. Statistical\n",
      " |  methods from ndarray have been overridden to automatically exclude\n",
      " |  missing data (currently represented as NaN)\n",
      " |  \n",
      " |  Operations between Series (+, -, /, *, **) align values based on their\n",
      " |  associated index values-- they need not be the same length. The result\n",
      " |  index will be the sorted union of the two indexes.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : array-like, dict, or scalar value\n",
      " |      Contains data stored in Series\n",
      " |  index : array-like or Index (1d)\n",
      " |      Values must be unique and hashable, same length as data. Index\n",
      " |      object (or other iterable of same length as data) Will default to\n",
      " |      np.arange(len(data)) if not provided. If both a dict and index\n",
      " |      sequence are used, the index will override the keys found in the\n",
      " |      dict.\n",
      " |  dtype : numpy.dtype or None\n",
      " |      If None, dtype will be inferred\n",
      " |  copy : boolean, default False\n",
      " |      Copy input data\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Series\n",
      " |      pandas.core.base.IndexOpsMixin\n",
      " |      pandas.core.strings.StringAccessorMixin\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.base.StringMixin\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__ = wrapper(left, right, name='__add__', na_op=<function na_op>)\n",
      " |  \n",
      " |  __and__ = wrapper(self, other)\n",
      " |  \n",
      " |  __array__(self, result=None)\n",
      " |      the array interface, return my values\n",
      " |  \n",
      " |  __array_prepare__(self, result, context=None)\n",
      " |      Gets called prior to a ufunc\n",
      " |  \n",
      " |  __array_wrap__(self, result, context=None)\n",
      " |      Gets called after a ufunc\n",
      " |  \n",
      " |  __div__ = wrapper(left, right, name='__truediv__', na_op=<function na_op>)\n",
      " |  \n",
      " |  __eq__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __float__ = wrapper(self)\n",
      " |  \n",
      " |  __floordiv__ = wrapper(left, right, name='__floordiv__', na_op=<function na_op>)\n",
      " |  \n",
      " |  __ge__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __gt__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __iadd__ = f(self, other)\n",
      " |  \n",
      " |  __idiv__ = wrapper(left, right, name='__truediv__', na_op=<function na_op>)\n",
      " |  \n",
      " |  __imul__ = f(self, other)\n",
      " |  \n",
      " |  __init__(self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)\n",
      " |  \n",
      " |  __int__ = wrapper(self)\n",
      " |  \n",
      " |  __ipow__ = f(self, other)\n",
      " |  \n",
      " |  __isub__ = f(self, other)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      provide iteration over the values of the Series\n",
      " |      box values if necessary\n",
      " |  \n",
      " |  __itruediv__ = f(self, other)\n",
      " |  \n",
      " |  __le__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      return the length of the Series\n",
      " |  \n",
      " |  __long__ = wrapper(self)\n",
      " |  \n",
      " |  __lt__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __mod__ = wrapper(left, right, name='__mod__', na_op=<function na_op>)\n",
      " |  \n",
      " |  __mul__ = wrapper(left, right, name='__mul__', na_op=<function na_op>)\n",
      " |  \n",
      " |  __ne__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __or__ = wrapper(self, other)\n",
      " |  \n",
      " |  __pow__ = wrapper(left, right, name='__pow__', na_op=<function na_op>)\n",
      " |  \n",
      " |  __radd__ = wrapper(left, right, name='__radd__', na_op=<function na_op>)\n",
      " |  \n",
      " |  __rand__ = wrapper(self, other)\n",
      " |  \n",
      " |  __rdiv__ = wrapper(left, right, name='__rtruediv__', na_op=<function na_op>)\n",
      " |  \n",
      " |  __rfloordiv__ = wrapper(left, right, name='__rfloordiv__', na_op=<function na_op>)\n",
      " |  \n",
      " |  __rmod__ = wrapper(left, right, name='__rmod__', na_op=<function na_op>)\n",
      " |  \n",
      " |  __rmul__ = wrapper(left, right, name='__rmul__', na_op=<function na_op>)\n",
      " |  \n",
      " |  __ror__ = wrapper(self, other)\n",
      " |  \n",
      " |  __rpow__ = wrapper(left, right, name='__rpow__', na_op=<function na_op>)\n",
      " |  \n",
      " |  __rsub__ = wrapper(left, right, name='__rsub__', na_op=<function na_op>)\n",
      " |  \n",
      " |  __rtruediv__ = wrapper(left, right, name='__rtruediv__', na_op=<function na_op>)\n",
      " |  \n",
      " |  __rxor__ = wrapper(self, other)\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  __sub__ = wrapper(left, right, name='__sub__', na_op=<function na_op>)\n",
      " |  \n",
      " |  __truediv__ = wrapper(left, right, name='__truediv__', na_op=<function na_op>)\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |      Return a string representation for a particular DataFrame\n",
      " |      \n",
      " |      Invoked by unicode(df) in py2 only. Yields a Unicode String in both\n",
      " |      py2/py3.\n",
      " |  \n",
      " |  __xor__ = wrapper(self, other)\n",
      " |  \n",
      " |  add(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Addition of series and other, element-wise (binary operator `add`).\n",
      " |      \n",
      " |      Equivalent to ``series + other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.radd\n",
      " |  \n",
      " |  align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)\n",
      " |      Align two object on their axes with the\n",
      " |      specified join method for each axis Index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      " |      axis : allowed axis of the other object, default None\n",
      " |          Align on index (0), columns (1), or both (None)\n",
      " |      level : int or level name, default None\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      copy : boolean, default True\n",
      " |          Always returns new objects. If copy=False and no reindexing is\n",
      " |          required then original objects are returned.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      method : str, default None\n",
      " |      limit : int, default None\n",
      " |      fill_axis : {0, 'index'}, default 0\n",
      " |          Filling axis, method and limit\n",
      " |      broadcast_axis : {0, 'index'}, default None\n",
      " |          Broadcast values along this axis, if aligning two objects of\n",
      " |          different dimensions\n",
      " |      \n",
      " |          .. versionadded:: 0.17.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (left, right) : (Series, type of other)\n",
      " |          Aligned objects\n",
      " |  \n",
      " |  all(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)\n",
      " |      Return whether all elements are True over requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean data. If None, will attempt to use everything,\n",
      " |          then use only boolean data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      all : scalar or Series (if level specified)\n",
      " |  \n",
      " |  any(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)\n",
      " |      Return whether any element is True over requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean data. If None, will attempt to use everything,\n",
      " |          then use only boolean data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      any : scalar or Series (if level specified)\n",
      " |  \n",
      " |  append(self, to_append, verify_integrity=False)\n",
      " |      Concatenate two or more Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_append : Series or list/tuple of Series\n",
      " |      verify_integrity : boolean, default False\n",
      " |          If True, raise Exception on creating index with duplicates\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      appended : Series\n",
      " |  \n",
      " |  apply(self, func, convert_dtype=True, args=(), **kwds)\n",
      " |      Invoke function on values of Series. Can be ufunc (a NumPy function\n",
      " |      that applies to the entire Series) or a Python function that only works\n",
      " |      on single values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |      convert_dtype : boolean, default True\n",
      " |          Try to find better dtype for elementwise function results. If\n",
      " |          False, leave as dtype=object\n",
      " |      args : tuple\n",
      " |          Positional arguments to pass to function in addition to the value\n",
      " |      Additional keyword arguments will be passed as keywords to the function\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series or DataFrame if func returns a Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.map: For element-wise operations\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create a series with typical summer temperatures for each city.\n",
      " |      \n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> series = pd.Series([20, 21, 12], index=['London',\n",
      " |      ... 'New York','Helsinki'])\n",
      " |      London      20\n",
      " |      New York    21\n",
      " |      Helsinki    12\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Square the values by defining a function and passing it as an\n",
      " |      argument to ``apply()``.\n",
      " |      \n",
      " |      >>> def square(x):\n",
      " |      ...     return x**2\n",
      " |      >>> series.apply(square)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Square the values by passing an anonymous function as an\n",
      " |      argument to ``apply()``.\n",
      " |      \n",
      " |      >>> series.apply(lambda x: x**2)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Define a custom function that needs additional positional\n",
      " |      arguments and pass these additional arguments using the\n",
      " |      ``args`` keyword.\n",
      " |      \n",
      " |      >>> def subtract_custom_value(x, custom_value):\n",
      " |      ...     return x-custom_value\n",
      " |      \n",
      " |      >>> series.apply(subtract_custom_value, args=(5,))\n",
      " |      London      15\n",
      " |      New York    16\n",
      " |      Helsinki     7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Define a custom function that takes keyword arguments\n",
      " |      and pass these arguments to ``apply``.\n",
      " |      \n",
      " |      >>> def add_custom_values(x, **kwargs):\n",
      " |      ...     for month in kwargs:\n",
      " |      ...         x+=kwargs[month]\n",
      " |      ...         return x\n",
      " |      \n",
      " |      >>> series.apply(add_custom_values, june=30, july=20, august=25)\n",
      " |      London      95\n",
      " |      New York    96\n",
      " |      Helsinki    87\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Use a function from the Numpy library.\n",
      " |      \n",
      " |      >>> series.apply(np.log)\n",
      " |      London      2.995732\n",
      " |      New York    3.044522\n",
      " |      Helsinki    2.484907\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  argmax = idxmax(self, axis=None, out=None, skipna=True)\n",
      " |  \n",
      " |  argmin = idxmin(self, axis=None, out=None, skipna=True)\n",
      " |  \n",
      " |  argsort(self, axis=0, kind='quicksort', order=None)\n",
      " |      Overrides ndarray.argsort. Argsorts the value, omitting NA/null values,\n",
      " |      and places the result in the same locations as the non-NA values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int (can only be zero)\n",
      " |      kind : {'mergesort', 'quicksort', 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See np.sort for more\n",
      " |          information. 'mergesort' is the only stable algorithm\n",
      " |      order : ignored\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      argsorted : Series, with -1 indicated where nan values are present\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.argsort\n",
      " |  \n",
      " |  asof(self, where)\n",
      " |      Return last good (non-NaN) value in Series if value is NaN for\n",
      " |      requested date.\n",
      " |      \n",
      " |      If there is no good value, NaN is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : date or array of dates\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Dates are assumed to be sorted\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value or NaN\n",
      " |  \n",
      " |  autocorr(self, lag=1)\n",
      " |      Lag-N autocorrelation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lag : int, default 1\n",
      " |          Number of lags to apply before performing autocorrelation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      autocorr : float\n",
      " |  \n",
      " |  between(self, left, right, inclusive=True)\n",
      " |      Return boolean Series equivalent to left <= series <= right. NA values\n",
      " |      will be treated as False\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      left : scalar\n",
      " |          Left boundary\n",
      " |      right : scalar\n",
      " |          Right boundary\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_between : Series\n",
      " |  \n",
      " |  combine(self, other, func, fill_value=nan)\n",
      " |      Perform elementwise binary operation on two Series using given function\n",
      " |      with optional fill value when an index is missing from one Series or\n",
      " |      the other\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      func : function\n",
      " |      fill_value : scalar value\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |  \n",
      " |  combine_first(self, other)\n",
      " |      Combine Series values, choosing the calling Series's values\n",
      " |      first. Result index will be the union of the two indexes\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series\n",
      " |  \n",
      " |  compound(self, axis=None, skipna=None, level=None)\n",
      " |      Return the compound percentage of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      compounded : scalar or Series (if level specified)\n",
      " |  \n",
      " |  compress(self, condition, axis=0, out=None, **kwargs)\n",
      " |      Return selected slices of an array along given axis as a Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.compress\n",
      " |  \n",
      " |  corr(self, other, method='pearson', min_periods=None)\n",
      " |      Compute correlation with `other` Series, excluding missing values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      method : {'pearson', 'kendall', 'spearman'}\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      correlation : float\n",
      " |  \n",
      " |  count(self, level=None)\n",
      " |      Return number of non-NA/null observations in the Series\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a smaller Series\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nobs : int or Series (if level specified)\n",
      " |  \n",
      " |  cov(self, other, min_periods=None)\n",
      " |      Compute covariance with Series, excluding missing values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      covariance : float\n",
      " |      \n",
      " |      Normalized by N-1 (unbiased estimator).\n",
      " |  \n",
      " |  cummax = max(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)\n",
      " |      Return cumulative max over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      max : scalar\n",
      " |  \n",
      " |  cummin = min(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)\n",
      " |      Return cumulative min over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      min : scalar\n",
      " |  \n",
      " |  cumprod = prod(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)\n",
      " |      Return cumulative prod over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prod : scalar\n",
      " |  \n",
      " |  cumsum = sum(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)\n",
      " |      Return cumulative sum over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sum : scalar\n",
      " |  \n",
      " |  diff(self, periods=1)\n",
      " |      1st discrete difference of object\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming difference\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      diffed : Series\n",
      " |  \n",
      " |  div = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rtruediv\n",
      " |  \n",
      " |  divide = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rtruediv\n",
      " |  \n",
      " |  dot(self, other)\n",
      " |      Matrix multiplication with DataFrame or inner-product with Series\n",
      " |      objects\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or DataFrame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dot_product : scalar or Series\n",
      " |  \n",
      " |  drop_duplicates(*args, **kwargs)\n",
      " |      Return Series with duplicate values removed\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          - ``first`` : Drop duplicates except for the first occurrence.\n",
      " |          - ``last`` : Drop duplicates except for the last occurrence.\n",
      " |          - False : Drop all duplicates.\n",
      " |      take_last : deprecated\n",
      " |      inplace : boolean, default False\n",
      " |          If True, performs operation inplace and returns None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      deduplicated : Series\n",
      " |  \n",
      " |  dropna(self, axis=0, inplace=False, **kwargs)\n",
      " |      Return Series without null values\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      valid : Series\n",
      " |      inplace : boolean, default False\n",
      " |          Do operation in place.\n",
      " |  \n",
      " |  duplicated(*args, **kwargs)\n",
      " |      Return boolean Series denoting duplicate values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          - ``first`` : Mark duplicates as ``True`` except for the first occurrence.\n",
      " |          - ``last`` : Mark duplicates as ``True`` except for the last occurrence.\n",
      " |          - False : Mark all duplicates as ``True``.\n",
      " |      take_last : deprecated\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      duplicated : Series\n",
      " |  \n",
      " |  eq = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)\n",
      " |      Fill NA/NaN values using the specified method\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a dict/Series/DataFrame of\n",
      " |          values specifying which value to use for each index (for a Series) or\n",
      " |          column (for a DataFrame). (values not in the dict/Series/DataFrame will not be\n",
      " |          filled). This value cannot be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use NEXT valid observation to fill gap\n",
      " |      axis : {0, 'index'}\n",
      " |      inplace : boolean, default False\n",
      " |          If True, fill in place. Note: this will modify any\n",
      " |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled.\n",
      " |      downcast : dict, default is None\n",
      " |          a dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible)\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      reindex, asfreq\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : Series\n",
      " |  \n",
      " |  first_valid_index(self)\n",
      " |      Return label for first non-NA/null value\n",
      " |  \n",
      " |  floordiv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Integer division of series and other, element-wise (binary operator `floordiv`).\n",
      " |      \n",
      " |      Equivalent to ``series // other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rfloordiv\n",
      " |  \n",
      " |  ge = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  get_value(self, label, takeable=False)\n",
      " |      Quickly retrieve single value at passed index label\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : label\n",
      " |      takeable : interpret the index as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : scalar value\n",
      " |  \n",
      " |  get_values(self)\n",
      " |      same as values (but handles sparseness conversions); is a view\n",
      " |  \n",
      " |  gt = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  hist = hist_series(self, by=None, ax=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, figsize=None, bins=10, **kwds)\n",
      " |      Draw histogram of the input series using matplotlib\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups\n",
      " |      ax : matplotlib axis object\n",
      " |          If not passed, uses gca()\n",
      " |      grid : boolean, default True\n",
      " |          Whether to show axis grid lines\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size\n",
      " |      xrot : float, default None\n",
      " |          rotation of x axis labels\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size\n",
      " |      yrot : float, default None\n",
      " |          rotation of y axis labels\n",
      " |      figsize : tuple, default None\n",
      " |          figure size in inches by default\n",
      " |      bins: integer, default 10\n",
      " |          Number of histogram bins to be used\n",
      " |      kwds : keywords\n",
      " |          To be passed to the actual plotting function\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See matplotlib documentation online for more on this\n",
      " |  \n",
      " |  idxmax(self, axis=None, out=None, skipna=True)\n",
      " |      Index of first occurrence of maximum of values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Index of maximum of values\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmax``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.idxmax\n",
      " |      numpy.ndarray.argmax\n",
      " |  \n",
      " |  idxmin(self, axis=None, out=None, skipna=True)\n",
      " |      Index of first occurrence of minimum of values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Index of minimum of values\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmin``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.idxmin\n",
      " |      numpy.ndarray.argmin\n",
      " |  \n",
      " |  iget(self, i, axis=0)\n",
      " |      DEPRECATED. Use ``.iloc[i]`` or ``.iat[i]`` instead\n",
      " |  \n",
      " |  iget_value(self, i, axis=0)\n",
      " |      DEPRECATED. Use ``.iloc[i]`` or ``.iat[i]`` instead\n",
      " |  \n",
      " |  irow(self, i, axis=0)\n",
      " |      DEPRECATED. Use ``.iloc[i]`` or ``.iat[i]`` instead\n",
      " |  \n",
      " |  isin(self, values)\n",
      " |      Return a boolean :class:`~pandas.Series` showing whether each element\n",
      " |      in the :class:`~pandas.Series` is exactly contained in the passed\n",
      " |      sequence of ``values``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : list-like\n",
      " |          The sequence of values to test. Passing in a single string will\n",
      " |          raise a ``TypeError``. Instead, turn a single string into a\n",
      " |          ``list`` of one element.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      isin : Series (bool dtype)\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |        * If ``values`` is a string\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.isin\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = pd.Series(list('abc'))\n",
      " |      >>> s.isin(['a', 'c', 'e'])\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Passing a single string as ``s.isin('a')`` will raise an error. Use\n",
      " |      a list of one element instead:\n",
      " |      \n",
      " |      >>> s.isin(['a'])\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  iteritems(self)\n",
      " |      Lazily iterate over (index, value) tuples\n",
      " |  \n",
      " |  keys(self)\n",
      " |      Alias for index\n",
      " |  \n",
      " |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis using Fishers definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      kurt : scalar or Series (if level specified)\n",
      " |  \n",
      " |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |  \n",
      " |  last_valid_index(self)\n",
      " |      Return label for last non-NA/null value\n",
      " |  \n",
      " |  le = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  lt = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  mad(self, axis=None, skipna=None, level=None)\n",
      " |      Return the mean absolute deviation of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mad : scalar or Series (if level specified)\n",
      " |  \n",
      " |  map(self, arg, na_action=None)\n",
      " |      Map values of Series using input correspondence (which can be\n",
      " |      a dict, Series, or function)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg : function, dict, or Series\n",
      " |      na_action : {None, 'ignore'}\n",
      " |          If 'ignore', propagate NA values\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x\n",
      " |      one   1\n",
      " |      two   2\n",
      " |      three 3\n",
      " |      \n",
      " |      >>> y\n",
      " |      1  foo\n",
      " |      2  bar\n",
      " |      3  baz\n",
      " |      \n",
      " |      >>> x.map(y)\n",
      " |      one   foo\n",
      " |      two   bar\n",
      " |      three baz\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series\n",
      " |          same index as caller\n",
      " |  \n",
      " |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the maximum of the values in the object. If you\n",
      " |                                            want the *index* of the maximum, use ``idxmax``. This is the\n",
      " |                                            equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      max : scalar or Series (if level specified)\n",
      " |  \n",
      " |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the mean of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mean : scalar or Series (if level specified)\n",
      " |  \n",
      " |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the median of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      median : scalar or Series (if level specified)\n",
      " |  \n",
      " |  memory_usage(self, index=False, deep=False)\n",
      " |      Memory usage of the Series\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool\n",
      " |          Specifies whether to include memory usage of Series index\n",
      " |      deep : bool\n",
      " |          Introspect the data deeply, interrogate\n",
      " |          `object` dtypes for system-level memory consumption\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar bytes of memory consumed\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Memory usage does not include memory consumed by elements that\n",
      " |      are not components of the array if deep=False\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes\n",
      " |  \n",
      " |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the minimum of the values in the object. If you\n",
      " |                                            want the *index* of the minimum, use ``idxmin``. This is the\n",
      " |                                            equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      min : scalar or Series (if level specified)\n",
      " |  \n",
      " |  mod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Modulo of series and other, element-wise (binary operator `mod`).\n",
      " |      \n",
      " |      Equivalent to ``series % other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rmod\n",
      " |  \n",
      " |  mode(self)\n",
      " |      Returns the mode(s) of the dataset.\n",
      " |      \n",
      " |      Empty if nothing occurs at least 2 times.  Always returns Series even\n",
      " |      if only one value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sort : bool, default True\n",
      " |          If True, will lexicographically sort values, if False skips\n",
      " |          sorting. Result ordering when ``sort=False`` is not defined.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      modes : Series (sorted)\n",
      " |  \n",
      " |  mul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Multiplication of series and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``series * other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rmul\n",
      " |  \n",
      " |  multiply = mul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Multiplication of series and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``series * other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rmul\n",
      " |  \n",
      " |  ne = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  nlargest(*args, **kwargs)\n",
      " |      Return the largest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Return this many descending sorted values\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |      take_last : deprecated\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      top_n : Series\n",
      " |          The n largest values in the Series, in sorted order\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values(ascending=False).head(n)`` for small `n` relative\n",
      " |      to the size of the ``Series`` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nsmallest\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> s = pd.Series(np.random.randn(1e6))\n",
      " |      >>> s.nlargest(10)  # only sorts up to the N requested\n",
      " |  \n",
      " |  nonzero(self)\n",
      " |      Return the indices of the elements that are non-zero\n",
      " |      \n",
      " |      This method is equivalent to calling `numpy.nonzero` on the\n",
      " |      series data. For compatability with NumPy, the return value is\n",
      " |      the same (a tuple with an array of indices for each dimension),\n",
      " |      but it will always be a one-item tuple because series only have\n",
      " |      one dimension.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0, 3, 0, 4])\n",
      " |      >>> s.nonzero()\n",
      " |      (array([1, 3]),)\n",
      " |      >>> s.iloc[s.nonzero()[0]]\n",
      " |      1    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.nonzero\n",
      " |  \n",
      " |  nsmallest(*args, **kwargs)\n",
      " |      Return the smallest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Return this many ascending sorted values\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |      take_last : deprecated\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bottom_n : Series\n",
      " |          The n smallest values in the Series, in sorted order\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values().head(n)`` for small `n` relative to\n",
      " |      the size of the ``Series`` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nlargest\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> s = pd.Series(np.random.randn(1e6))\n",
      " |      >>> s.nsmallest(10)  # only sorts up to the N requested\n",
      " |  \n",
      " |  order(self, na_last=None, ascending=True, kind='quicksort', na_position='last', inplace=False)\n",
      " |      DEPRECATED: use :meth:`Series.sort_values`\n",
      " |      \n",
      " |      Sorts Series object, by value, maintaining index-value link.\n",
      " |      This will return a new Series by default. Series.sort is the equivalent but as an inplace method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      na_last : boolean (optional, default=True) (DEPRECATED; use na_position)\n",
      " |          Put NaN's at beginning or end\n",
      " |      ascending : boolean, default True\n",
      " |          Sort ascending. Passing False sorts descending\n",
      " |      kind : {'mergesort', 'quicksort', 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See np.sort for more\n",
      " |          information. 'mergesort' is the only stable algorithm\n",
      " |      na_position : {'first', 'last'} (optional, default='last')\n",
      " |          'first' puts NaNs at the beginning\n",
      " |          'last' puts NaNs at the end\n",
      " |      inplace : boolean, default False\n",
      " |          Do operation in place.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_values\n",
      " |  \n",
      " |  pow(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Exponential power of series and other, element-wise (binary operator `pow`).\n",
      " |      \n",
      " |      Equivalent to ``series ** other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rpow\n",
      " |  \n",
      " |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the product of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prod : scalar or Series (if level specified)\n",
      " |  \n",
      " |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |  \n",
      " |  ptp(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |                                            Returns the difference between the maximum value and the minimum\n",
      " |                                            value in the object. This is the equivalent of the ``numpy.ndarray``\n",
      " |                                            method ``ptp``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ptp : scalar or Series (if level specified)\n",
      " |  \n",
      " |  put(self, *args, **kwargs)\n",
      " |      return a ndarray with the values put\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.put\n",
      " |  \n",
      " |  quantile(self, q=0.5)\n",
      " |      Return value at the given quantile, a la numpy.percentile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          0 <= q <= 1, the quantile(s) to compute\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      quantile : float or Series\n",
      " |          if ``q`` is an array, a Series will be returned where the\n",
      " |          index is ``q`` and the values are the quantiles.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = Series([1, 2, 3, 4])\n",
      " |      >>> s.quantile(.5)\n",
      " |          2.5\n",
      " |      >>> s.quantile([.25, .5, .75])\n",
      " |      0.25    1.75\n",
      " |      0.50    2.50\n",
      " |      0.75    3.25\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  radd(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Addition of series and other, element-wise (binary operator `radd`).\n",
      " |      \n",
      " |      Equivalent to ``other + series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.add\n",
      " |  \n",
      " |  rank(self, method='average', na_option='keep', ascending=True, pct=False)\n",
      " |      Compute data ranks (1 through n). Equal values are assigned a rank that\n",
      " |      is the average of the ranks of those values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}\n",
      " |          * average: average rank of group\n",
      " |          * min: lowest rank in group\n",
      " |          * max: highest rank in group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups\n",
      " |      na_option : {'keep'}\n",
      " |          keep: leave NA values where they are\n",
      " |      ascending : boolean, default True\n",
      " |          False for ranks by high (1) to low (N)\n",
      " |      pct : boolean, default False\n",
      " |          Computes percentage rank of data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ranks : Series\n",
      " |  \n",
      " |  ravel(self, order='C')\n",
      " |      Return the flattened underlying data as an ndarray\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.ravel\n",
      " |  \n",
      " |  rdiv = rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.truediv\n",
      " |  \n",
      " |  reindex(self, index=None, **kwargs)\n",
      " |      Conform Series to new index with optional filling logic, placing\n",
      " |      NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      copy=False\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : array-like, optional (can be specified in order, or as\n",
      " |          keywords)\n",
      " |          New labels / index to conform to. Preferably an Index object to\n",
      " |          avoid duplicating data\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      " |          method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only  applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |            * default: don't fill gaps\n",
      " |            * pad / ffill: propagate last valid observation forward to next valid\n",
      " |            * backfill / bfill: use next valid observation to fill gap\n",
      " |            * nearest: use nearest valid observations to fill gap\n",
      " |      copy : boolean, default True\n",
      " |          Return a new object, even if the passed indexes are the same\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          .. versionadded:: 0.17.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create a dataframe with some fictional data.\n",
      " |      \n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...      'http_status': [200,200,404,404,301],\n",
      " |      ...      'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...       index=index)\n",
      " |      >>> df\n",
      " |                  http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |      \n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |      \n",
      " |      >>> new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...             'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |      \n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |      \n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |      \n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |              index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      \n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |      \n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |      \n",
      " |      For example, to backpropagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |      \n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29     100\n",
      " |      2009-12-30     100\n",
      " |      2009-12-31     100\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : Series\n",
      " |  \n",
      " |  reindex_axis(self, labels, axis=0, **kwargs)\n",
      " |      for compatibility with higher dims\n",
      " |  \n",
      " |  rename(self, index=None, **kwargs)\n",
      " |      Alter axes input function or functions. Function / dict values must be\n",
      " |      unique (1-to-1). Labels not contained in a dict / Series will be left\n",
      " |      as-is.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : dict-like or function, optional\n",
      " |          Transformation to apply to that axis values\n",
      " |      \n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to return a new Series. If True then value of copy is\n",
      " |          ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : Series (new object)\n",
      " |  \n",
      " |  reorder_levels(self, order)\n",
      " |      Rearrange index levels using input order. May not drop or duplicate\n",
      " |      levels\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order: list of int representing new level order.\n",
      " |             (reference level by number or key)\n",
      " |      axis: where to reorder levels\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller (new object)\n",
      " |  \n",
      " |  repeat(self, reps)\n",
      " |      return a new Series with the values repeated reps times\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.repeat\n",
      " |  \n",
      " |  reset_index(self, level=None, drop=False, name=None, inplace=False)\n",
      " |      Analogous to the :meth:`pandas.DataFrame.reset_index` function, see\n",
      " |      docstring there.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default None\n",
      " |          Only remove the given levels from the index. Removes all levels by\n",
      " |          default\n",
      " |      drop : boolean, default False\n",
      " |          Do not try to insert index into dataframe columns\n",
      " |      name : object, default None\n",
      " |          The name of the column corresponding to the Series values\n",
      " |      inplace : boolean, default False\n",
      " |          Modify the Series in place (do not create a new object)\n",
      " |      \n",
      " |      Returns\n",
      " |      ----------\n",
      " |      resetted : DataFrame, or Series if drop == True\n",
      " |  \n",
      " |  reshape(self, *args, **kwargs)\n",
      " |      return an ndarray with the values shape\n",
      " |      if the specified shape matches exactly the current shape, then\n",
      " |      return self (for compat)\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.take\n",
      " |  \n",
      " |  rfloordiv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Integer division of series and other, element-wise (binary operator `rfloordiv`).\n",
      " |      \n",
      " |      Equivalent to ``other // series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.floordiv\n",
      " |  \n",
      " |  rmod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Modulo of series and other, element-wise (binary operator `rmod`).\n",
      " |      \n",
      " |      Equivalent to ``other % series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.mod\n",
      " |  \n",
      " |  rmul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Multiplication of series and other, element-wise (binary operator `rmul`).\n",
      " |      \n",
      " |      Equivalent to ``other * series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.mul\n",
      " |  \n",
      " |  round(self, decimals=0, out=None)\n",
      " |          a.round(decimals=0, out=None)\n",
      " |      \n",
      " |      Return `a` with each element rounded to the given number of decimals.\n",
      " |      \n",
      " |      Refer to `numpy.around` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around : equivalent function\n",
      " |  \n",
      " |  rpow(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Exponential power of series and other, element-wise (binary operator `rpow`).\n",
      " |      \n",
      " |      Equivalent to ``other ** series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.pow\n",
      " |  \n",
      " |  rsub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Subtraction of series and other, element-wise (binary operator `rsub`).\n",
      " |      \n",
      " |      Equivalent to ``other - series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.sub\n",
      " |  \n",
      " |  rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.truediv\n",
      " |  \n",
      " |  searchsorted(self, v, side='left', sorter=None)\n",
      " |      Find indices where elements should be inserted to maintain order.\n",
      " |      \n",
      " |      Find the indices into a sorted Series `self` such that, if the\n",
      " |      corresponding elements in `v` were inserted before the indices, the\n",
      " |      order of `self` would be preserved.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      v : array_like\n",
      " |          Values to insert into `a`.\n",
      " |      side : {'left', 'right'}, optional\n",
      " |          If 'left', the index of the first suitable location found is given.\n",
      " |          If 'right', return the last such index.  If there is no suitable\n",
      " |          index, return either 0 or N (where N is the length of `a`).\n",
      " |      sorter : 1-D array_like, optional\n",
      " |          Optional array of integer indices that sort `self` into ascending\n",
      " |          order. They are typically the result of ``np.argsort``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indices : array of ints\n",
      " |          Array of insertion points with the same shape as `v`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_values\n",
      " |      numpy.searchsorted\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Binary search is used to find the required insertion points.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = pd.Series([1, 2, 3])\n",
      " |      >>> x\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      >>> x.searchsorted(4)\n",
      " |      array([3])\n",
      " |      >>> x.searchsorted([0, 4])\n",
      " |      array([0, 3])\n",
      " |      >>> x.searchsorted([1, 3], side='left')\n",
      " |      array([0, 2])\n",
      " |      >>> x.searchsorted([1, 3], side='right')\n",
      " |      array([1, 3])\n",
      " |      >>> x.searchsorted([1, 2], side='right', sorter=[0, 2, 1])\n",
      " |      array([1, 3])\n",
      " |  \n",
      " |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          degrees of freedom\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sem : scalar or Series (if level specified)\n",
      " |  \n",
      " |  set_value(self, label, value, takeable=False)\n",
      " |      Quickly set single value at passed label. If label is not contained, a\n",
      " |      new object is created with the label placed at the end of the result\n",
      " |      index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      label : object\n",
      " |          Partial indexing with MultiIndex not allowed\n",
      " |      value : object\n",
      " |          Scalar value\n",
      " |      takeable : interpret the index as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      series : Series\n",
      " |          If label is contained, will be reference to calling Series,\n",
      " |          otherwise a new object\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift index by desired number of periods with an optional time freq\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, optional\n",
      " |          Increment to use from datetools module or time rule (e.g. 'EOM').\n",
      " |          See Notes.\n",
      " |      axis : {0, 'index'}\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is specified then the index values are shifted but the data\n",
      " |      is not realigned. That is, use freq if you would like to extend the\n",
      " |      index when shifting and preserve the original data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : Series\n",
      " |  \n",
      " |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased skew over requested axis\n",
      " |      Normalized by N-1\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      skew : scalar or Series (if level specified)\n",
      " |  \n",
      " |  sort(self, axis=0, ascending=True, kind='quicksort', na_position='last', inplace=True)\n",
      " |      DEPRECATED: use :meth:`Series.sort_values(inplace=True)` for INPLACE sorting\n",
      " |      \n",
      " |      Sort values and index labels by value. This is an inplace sort by default.\n",
      " |      Series.order is the equivalent but returns a new Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int (can only be zero)\n",
      " |      ascending : boolean, default True\n",
      " |          Sort ascending. Passing False sorts descending\n",
      " |      kind : {'mergesort', 'quicksort', 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See np.sort for more\n",
      " |          information. 'mergesort' is the only stable algorithm\n",
      " |      na_position : {'first', 'last'} (optional, default='last')\n",
      " |          'first' puts NaNs at the beginning\n",
      " |          'last' puts NaNs at the end\n",
      " |      inplace : boolean, default True\n",
      " |          Do operation in place.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_values\n",
      " |  \n",
      " |  sort_index(self, axis=0, level=None, ascending=True, inplace=False, sort_remaining=True)\n",
      " |      Sort object by labels (along an axis)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : index to direct sorting\n",
      " |      level : int or level name or list of ints or list of level names\n",
      " |          if not None, sort on values in specified index level(s)\n",
      " |      ascending : boolean, default True\n",
      " |          Sort ascending vs. descending\n",
      " |      inplace : bool\n",
      " |          if True, perform operation in-place\n",
      " |      kind : {`quicksort`, `mergesort`, `heapsort`}\n",
      " |           Choice of sorting algorithm. See also ndarray.np.sort for more information.\n",
      " |           `mergesort` is the only stable algorithm. For DataFrames, this option is\n",
      " |           only applied when sorting on a single column or label.\n",
      " |      na_position : {'first', 'last'}\n",
      " |           `first` puts NaNs at the beginning, `last` puts NaNs at the end\n",
      " |      sort_remaining : bool\n",
      " |          if true and sorting by level and index is multilevel, sort by other levels\n",
      " |          too (in order) after sorting by specified level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted_obj : Series\n",
      " |  \n",
      " |  sort_values(self, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
      " |      Sort by the values along either axis\n",
      " |      \n",
      " |      .. versionadded:: 0.17.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : string name or list of names which refer to the axis items\n",
      " |      axis : index to direct sorting\n",
      " |      ascending : bool or list of bool\n",
      " |           Sort ascending vs. descending. Specify list for multiple sort orders.\n",
      " |           If this is a list of bools, must match the length of the by\n",
      " |      inplace : bool\n",
      " |           if True, perform operation in-place\n",
      " |      kind : {`quicksort`, `mergesort`, `heapsort`}\n",
      " |           Choice of sorting algorithm. See also ndarray.np.sort for more information.\n",
      " |           `mergesort` is the only stable algorithm. For DataFrames, this option is\n",
      " |           only applied when sorting on a single column or label.\n",
      " |      na_position : {'first', 'last'}\n",
      " |           `first` puts NaNs at the beginning, `last` puts NaNs at the end\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted_obj : Series\n",
      " |  \n",
      " |  sortlevel(self, level=0, ascending=True, sort_remaining=True)\n",
      " |      Sort Series with MultiIndex by chosen level. Data will be\n",
      " |      lexicographically sorted by the chosen level followed by the other\n",
      " |      levels (in order)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int or level name, default None\n",
      " |      ascending : bool, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted : Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index(level=...)\n",
      " |  \n",
      " |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased standard deviation over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          degrees of freedom\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      std : scalar or Series (if level specified)\n",
      " |  \n",
      " |  sub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Subtraction of series and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``series - other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rsub\n",
      " |  \n",
      " |  subtract = sub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Subtraction of series and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``series - other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rsub\n",
      " |  \n",
      " |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the sum of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sum : scalar or Series (if level specified)\n",
      " |  \n",
      " |  swaplevel(self, i, j, copy=True)\n",
      " |      Swap levels i and j in a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int, string (can be mixed)\n",
      " |          Level of index to be swapped. Can pass level name as string.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      swapped : Series\n",
      " |  \n",
      " |  take(self, indices, axis=0, convert=True, is_copy=False)\n",
      " |      return Series corresponding to requested indices\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : list / array of ints\n",
      " |      convert : translate negative to positive indices (default)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.take\n",
      " |  \n",
      " |  to_csv(self, path, index=True, sep=',', na_rep='', float_format=None, header=False, index_label=None, mode='w', nanRep=None, encoding=None, date_format=None, decimal='.')\n",
      " |      Write Series to a comma-separated values (csv) file\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string file path or file handle / StringIO. If None is provided\n",
      " |          the result is returned as a string.\n",
      " |      na_rep : string, default ''\n",
      " |          Missing data representation\n",
      " |      float_format : string, default None\n",
      " |          Format string for floating point numbers\n",
      " |      header : boolean, default False\n",
      " |          Write out series name\n",
      " |      index : boolean, default True\n",
      " |          Write row names (index)\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      mode : Python write mode, default 'w'\n",
      " |      sep : character, default \",\"\n",
      " |          Field delimiter for the output file.\n",
      " |      encoding : string, optional\n",
      " |          a string representing the encoding to use if the contents are\n",
      " |          non-ascii, for python versions prior to 3\n",
      " |      date_format: string, default None\n",
      " |          Format string for datetime objects.\n",
      " |      decimal: string, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for European data\n",
      " |  \n",
      " |  to_dict(self)\n",
      " |      Convert Series to {label -> value} dict\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value_dict : dict\n",
      " |  \n",
      " |  to_frame(self, name=None)\n",
      " |      Convert Series to DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object, default None\n",
      " |          The passed name should substitute for the series name (if it has\n",
      " |          one).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      data_frame : DataFrame\n",
      " |  \n",
      " |  to_period(self, freq=None, copy=True)\n",
      " |      Convert Series from DatetimeIndex to PeriodIndex with desired\n",
      " |      frequency (inferred from index if not passed)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ts : Series with PeriodIndex\n",
      " |  \n",
      " |  to_sparse(self, kind='block', fill_value=None)\n",
      " |      Convert Series to SparseSeries\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      kind : {'block', 'integer'}\n",
      " |      fill_value : float, defaults to NaN (missing)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sp : SparseSeries\n",
      " |  \n",
      " |  to_string(self, buf=None, na_rep='NaN', float_format=None, header=True, length=False, dtype=False, name=False, max_rows=None)\n",
      " |      Render a string representation of the Series\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : StringIO-like, optional\n",
      " |          buffer to write to\n",
      " |      na_rep : string, optional\n",
      " |          string representation of NAN to use, default 'NaN'\n",
      " |      float_format : one-parameter function, optional\n",
      " |          formatter function to apply to columns' elements if they are floats\n",
      " |          default None\n",
      " |      header: boolean, default True\n",
      " |          Add the Series header (index name)\n",
      " |      length : boolean, default False\n",
      " |          Add the Series length\n",
      " |      dtype : boolean, default False\n",
      " |          Add the Series dtype\n",
      " |      name : boolean, default False\n",
      " |          Add the Series name if not None\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to show before truncating. If None, show\n",
      " |          all.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      formatted : string (if not buffer passed)\n",
      " |  \n",
      " |  to_timestamp(self, freq=None, how='start', copy=True)\n",
      " |      Cast to datetimeindex of timestamps, at *beginning* of period\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default frequency of PeriodIndex\n",
      " |          Desired frequency\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ts : Series with DatetimeIndex\n",
      " |  \n",
      " |  tolist(self)\n",
      " |      Convert Series to a nested list\n",
      " |  \n",
      " |  truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rtruediv\n",
      " |  \n",
      " |  unstack(self, level=-1)\n",
      " |      Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.\n",
      " |      The level involved will automatically get sorted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, string, or list of these, default last level\n",
      " |          Level(s) to unstack, can pass level name\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s\n",
      " |      one  a   1.\n",
      " |      one  b   2.\n",
      " |      two  a   3.\n",
      " |      two  b   4.\n",
      " |      \n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a   b\n",
      " |      one  1.  2.\n",
      " |      two  3.  4.\n",
      " |      \n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a  1.   2.\n",
      " |      b  3.   4.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      unstacked : DataFrame\n",
      " |  \n",
      " |  update(self, other)\n",
      " |      Modify Series in place using non-NA values from passed\n",
      " |      Series. Aligns on index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |  \n",
      " |  valid lambda self, inplace=False, **kwargs\n",
      " |  \n",
      " |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          degrees of freedom\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      var : scalar or Series (if level specified)\n",
      " |  \n",
      " |  view(self, dtype=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_array(cls, arr, index=None, name=None, dtype=None, copy=False, fastpath=False) from __builtin__.type\n",
      " |  \n",
      " |  from_csv(cls, path, sep=',', parse_dates=True, header=None, index_col=0, encoding=None, infer_datetime_format=False) from __builtin__.type\n",
      " |      Read CSV file (DISCOURAGED, please use :func:`pandas.read_csv` instead).\n",
      " |      \n",
      " |      It is preferable to use the more powerful :func:`pandas.read_csv`\n",
      " |      for most general purposes, but ``from_csv`` makes for an easy\n",
      " |      roundtrip to and from a file (the exact counterpart of\n",
      " |      ``to_csv``), especially with a time Series.\n",
      " |      \n",
      " |      This method only differs from :func:`pandas.read_csv` in some defaults:\n",
      " |      \n",
      " |      - `index_col` is ``0`` instead of ``None`` (take first column as index\n",
      " |        by default)\n",
      " |      - `header` is ``None`` instead of ``0`` (the first row is not used as\n",
      " |        the column names)\n",
      " |      - `parse_dates` is ``True`` instead of ``False`` (try parsing the index\n",
      " |        as datetime by default)\n",
      " |      \n",
      " |      With :func:`pandas.read_csv`, the option ``squeeze=True`` can be used\n",
      " |      to return a Series like ``from_csv``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string file path or file handle / StringIO\n",
      " |      sep : string, default ','\n",
      " |          Field delimiter\n",
      " |      parse_dates : boolean, default True\n",
      " |          Parse dates. Different default from read_table\n",
      " |      header : int, default None\n",
      " |          Row to use as header (skip prior rows)\n",
      " |      index_col : int or sequence, default 0\n",
      " |          Column to use for index. If a sequence is given, a MultiIndex\n",
      " |          is used. Different default from read_table\n",
      " |      encoding : string, optional\n",
      " |          a string representing the encoding to use if the contents are\n",
      " |          non-ascii, for python versions prior to 3\n",
      " |      infer_datetime_format: boolean, default False\n",
      " |          If True and `parse_dates` is True for a column, try to infer the\n",
      " |          datetime format based on the first datetime string. If the format\n",
      " |          can be inferred, there often will be a large parsing speed-up.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.read_csv\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  axes\n",
      " |      Return a list of the row axis labels\n",
      " |  \n",
      " |  cat\n",
      " |      Accessor object for categorical properties of the Series values.\n",
      " |      \n",
      " |      Be aware that assigning to `categories` is a inplace operation, while all methods return\n",
      " |      new categorical data per default (but can be called with `inplace=True`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.cat.categories\n",
      " |      >>> s.cat.categories = list('abc')\n",
      " |      >>> s.cat.rename_categories(list('cab'))\n",
      " |      >>> s.cat.reorder_categories(list('cab'))\n",
      " |      >>> s.cat.add_categories(['d','e'])\n",
      " |      >>> s.cat.remove_categories(['d'])\n",
      " |      >>> s.cat.remove_unused_categories()\n",
      " |      >>> s.cat.set_categories(list('abcde'))\n",
      " |      >>> s.cat.as_ordered()\n",
      " |      >>> s.cat.as_unordered()\n",
      " |  \n",
      " |  dt\n",
      " |      Accessor object for datetimelike properties of the Series values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.dt.hour\n",
      " |      >>> s.dt.second\n",
      " |      >>> s.dt.quarter\n",
      " |      \n",
      " |      Returns a Series indexed like the original Series.\n",
      " |      Raises TypeError if the Series does not contain datetimelike values.\n",
      " |  \n",
      " |  dtype\n",
      " |      return the dtype object of the underlying data\n",
      " |  \n",
      " |  dtypes\n",
      " |      return the dtype object of the underlying data\n",
      " |  \n",
      " |  ftype\n",
      " |      return if the data is sparse|dense\n",
      " |  \n",
      " |  ftypes\n",
      " |      return if the data is sparse|dense\n",
      " |  \n",
      " |  imag\n",
      " |  \n",
      " |  index\n",
      " |  \n",
      " |  is_time_series\n",
      " |  \n",
      " |  plot\n",
      " |      Series plotting accessor and method\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.plot.line()\n",
      " |      >>> s.plot.bar()\n",
      " |      >>> s.plot.hist()\n",
      " |      \n",
      " |      Plotting methods can also be accessed by calling the accessor as a method\n",
      " |      with the ``kind`` argument:\n",
      " |      ``s.plot(kind='line')`` is equivalent to ``s.plot.line()``\n",
      " |  \n",
      " |  real\n",
      " |  \n",
      " |  values\n",
      " |      Return Series as ndarray or ndarray-like\n",
      " |      depending on the dtype\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      arr : numpy.ndarray or ndarray-like\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.Series([1, 2, 3]).values\n",
      " |      array([1, 2, 3])\n",
      " |      \n",
      " |      >>> pd.Series(list('aabc')).values\n",
      " |      array(['a', 'a', 'b', 'c'], dtype=object)\n",
      " |      \n",
      " |      >>> pd.Series(list('aabc')).astype('category').values\n",
      " |      [a, a, b, c]\n",
      " |      Categories (3, object): [a, b, c]\n",
      " |      \n",
      " |      Timezone aware datetime data is converted to UTC:\n",
      " |      \n",
      " |      >>> pd.Series(pd.date_range('20130101',periods=3,tz='US/Eastern')).values\n",
      " |      array(['2013-01-01T00:00:00.000000000-0500',\n",
      " |             '2013-01-02T00:00:00.000000000-0500',\n",
      " |             '2013-01-03T00:00:00.000000000-0500'], dtype='datetime64[ns]')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  factorize(self, sort=False, na_sentinel=-1)\n",
      " |      Encode the object as an enumerated type or categorical variable\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sort : boolean, default False\n",
      " |          Sort by values\n",
      " |      na_sentinel: int, default -1\n",
      " |          Value to mark \"not found\"\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : the indexer to the original array\n",
      " |      uniques : the unique Index\n",
      " |  \n",
      " |  item(self)\n",
      " |      return the first element of the underlying data as a python scalar\n",
      " |  \n",
      " |  nunique(self, dropna=True)\n",
      " |      Return number of unique elements in the object.\n",
      " |      \n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include NaN in the count.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nunique : int\n",
      " |  \n",
      " |  transpose(self)\n",
      " |      return the transpose, which is by definition self\n",
      " |  \n",
      " |  unique(self)\n",
      " |      Return array of unique values in the object. Significantly faster than\n",
      " |      numpy.unique. Includes NA values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      uniques : ndarray\n",
      " |  \n",
      " |  value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n",
      " |      Returns object containing counts of unique values.\n",
      " |      \n",
      " |      The resulting object will be in descending order so that the\n",
      " |      first element is the most frequently-occurring element.\n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      normalize : boolean, default False\n",
      " |          If True then the object returned will contain the relative\n",
      " |          frequencies of the unique values.\n",
      " |      sort : boolean, default True\n",
      " |          Sort by values\n",
      " |      ascending : boolean, default False\n",
      " |          Sort in ascending order\n",
      " |      bins : integer, optional\n",
      " |          Rather than count values, group them into half-open bins,\n",
      " |          a convenience for pd.cut, only works with numeric data\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include counts of NaN.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      counts : Series\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  T\n",
      " |      return the transpose, which is by definition self\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  base\n",
      " |      return the base object if the memory of the underlying data is shared\n",
      " |  \n",
      " |  data\n",
      " |      return the data pointer of the underlying data\n",
      " |  \n",
      " |  flags\n",
      " |      return the ndarray.flags for the underlying data\n",
      " |  \n",
      " |  hasnans\n",
      " |  \n",
      " |  itemsize\n",
      " |      return the size of the dtype of the item of the underlying data\n",
      " |  \n",
      " |  nbytes\n",
      " |      return the number of bytes in the underlying data\n",
      " |  \n",
      " |  ndim\n",
      " |      return the number of dimensions of the underlying data, by definition 1\n",
      " |  \n",
      " |  shape\n",
      " |      return a tuple of the shape of the underlying data\n",
      " |  \n",
      " |  size\n",
      " |      return the number of elements in the underlying data\n",
      " |  \n",
      " |  strides\n",
      " |      return the strides of the underlying data\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  __array_priority__ = 1000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.strings.StringAccessorMixin:\n",
      " |  \n",
      " |  str\n",
      " |      Vectorized string functions for Series and Index. NAs stay NA unless\n",
      " |      handled otherwise by a particular method. Patterned after Python's string\n",
      " |      methods, with some inspiration from R's stringr package.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.str.split('_')\n",
      " |      >>> s.str.replace('_', '')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __abs__(self)\n",
      " |  \n",
      " |  __bool__ = __nonzero__(self)\n",
      " |  \n",
      " |  __contains__(self, key)\n",
      " |      True if the key is in the info axis\n",
      " |  \n",
      " |  __delitem__(self, key)\n",
      " |      Delete item\n",
      " |  \n",
      " |  __finalize__(self, other, method=None, **kwargs)\n",
      " |      propagate metadata from other to self\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : optional, a passed method name ; possibly to take different\n",
      " |          types of propagation actions based on this\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |  \n",
      " |  __invert__(self)\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  abs(self)\n",
      " |      Return an object with absolute value taken. Only applicable to objects\n",
      " |      that are all numeric\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs: type of caller\n",
      " |  \n",
      " |  add_prefix(self, prefix)\n",
      " |      Concatenate prefix string with panel items names.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      with_prefix : type of caller\n",
      " |  \n",
      " |  add_suffix(self, suffix)\n",
      " |      Concatenate suffix string with panel items names\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      with_suffix : type of caller\n",
      " |  \n",
      " |  as_blocks(self, copy=True)\n",
      " |      Convert the frame to a dict of dtype -> Constructor Types that each has\n",
      " |      a homogeneous dtype.\n",
      " |      \n",
      " |      NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in\n",
      " |            as_matrix)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : boolean, default True\n",
      " |      \n",
      " |             .. versionadded: 0.16.1\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : a dict of dtype -> Constructor Types\n",
      " |  \n",
      " |  as_matrix(self, columns=None)\n",
      " |      Convert the frame to its Numpy-array representation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      columns: list, optional, default:None\n",
      " |          If None, return all columns, otherwise, returns specified columns.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : ndarray\n",
      " |          If the caller is heterogeneous and contains booleans or objects,\n",
      " |          the result will be of dtype=object. See Notes.\n",
      " |      \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Return is NOT a Numpy-matrix, rather, a Numpy-array.\n",
      " |      \n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |      \n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcase to\n",
      " |      int32.\n",
      " |      \n",
      " |      This method is provided for backwards compatibility. Generally,\n",
      " |      it is recommended to use '.values'.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.values\n",
      " |  \n",
      " |  asfreq(self, freq, method=None, how=None, normalize=False)\n",
      " |      Convert all TimeSeries inside to specified frequency using DateOffset\n",
      " |      objects. Optionally provide fill method to pad/backfill missing values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset object, or string\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use NEXT valid observation to fill method\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only, see PeriodIndex.asfreq\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : type of caller\n",
      " |  \n",
      " |  astype(self, dtype, copy=True, raise_on_error=True, **kwargs)\n",
      " |      Cast object to input numpy.dtype\n",
      " |      Return a copy when copy = True (be really careful with this!)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : numpy.dtype or Python type\n",
      " |      raise_on_error : raise on invalid input\n",
      " |      kwargs : keyword arguments to pass on to the constructor\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      casted : type of caller\n",
      " |  \n",
      " |  at_time(self, time, asof=False)\n",
      " |      Select values at particular time of day (e.g. 9:30AM)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_at_time : type of caller\n",
      " |  \n",
      " |  between_time(self, start_time, end_time, include_start=True, include_end=True)\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or string\n",
      " |      end_time : datetime.time or string\n",
      " |      include_start : boolean, default True\n",
      " |      include_end : boolean, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_between_time : type of caller\n",
      " |  \n",
      " |  bfill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for NDFrame.fillna(method='bfill')\n",
      " |  \n",
      " |  bool(self)\n",
      " |      Return the bool of a single element PandasObject\n",
      " |      This must be a boolean scalar value, either True or False\n",
      " |      \n",
      " |      Raise a ValueError if the PandasObject does not have exactly\n",
      " |      1 element, or that element is not boolean\n",
      " |  \n",
      " |  clip(self, lower=None, upper=None, out=None, axis=None)\n",
      " |      Trim values at input threshold(s)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float or array_like, default None\n",
      " |      upper : float or array_like, default None\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with lower and upper along the given axis.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |        0         1\n",
      " |      0  0.335232 -1.256177\n",
      " |      1 -1.367855  0.746646\n",
      " |      2  0.027753 -1.176076\n",
      " |      3  0.230930 -0.679613\n",
      " |      4  1.261967  0.570967\n",
      " |      >>> df.clip(-1.0, 0.5)\n",
      " |                0         1\n",
      " |      0  0.335232 -1.000000\n",
      " |      1 -1.000000  0.500000\n",
      " |      2  0.027753 -1.000000\n",
      " |      3  0.230930 -0.679613\n",
      " |      4  0.500000  0.500000\n",
      " |      >>> t\n",
      " |      0   -0.3\n",
      " |      1   -0.2\n",
      " |      2   -0.1\n",
      " |      3    0.0\n",
      " |      4    0.1\n",
      " |      dtype: float64\n",
      " |      >>> df.clip(t, t + 1, axis=0)\n",
      " |                0         1\n",
      " |      0  0.335232 -0.300000\n",
      " |      1 -0.200000  0.746646\n",
      " |      2  0.027753 -0.100000\n",
      " |      3  0.230930  0.000000\n",
      " |      4  1.100000  0.570967\n",
      " |  \n",
      " |  clip_lower(self, threshold, axis=None)\n",
      " |      Return copy of the input with values below given value(s) truncated\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      threshold : float or array_like\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with threshold along the given axis.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      clip\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |  \n",
      " |  clip_upper(self, threshold, axis=None)\n",
      " |      Return copy of input with values above given value(s) truncated\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      threshold : float or array_like\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with threshold along the given axis.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      clip\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |  \n",
      " |  consolidate(self, inplace=False)\n",
      " |      Compute NDFrame with \"consolidated\" internals (data of each dtype\n",
      " |      grouped together in a single ndarray). Mainly an internal API function,\n",
      " |      but available here to the savvy user\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      inplace : boolean, default False\n",
      " |          If False return new object, otherwise modify existing object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      consolidated : type of caller\n",
      " |  \n",
      " |  convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)\n",
      " |      Attempt to infer better dtype for object columns\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      convert_dates : boolean, default True\n",
      " |          If True, convert to date where possible. If 'coerce', force\n",
      " |          conversion, with unconvertible values becoming NaT.\n",
      " |      convert_numeric : boolean, default False\n",
      " |          If True, attempt to coerce to numbers (including strings), with\n",
      " |          unconvertible values becoming NaN.\n",
      " |      convert_timedeltas : boolean, default True\n",
      " |          If True, convert to timedelta where possible. If 'coerce', force\n",
      " |          conversion, with unconvertible values becoming NaT.\n",
      " |      copy : boolean, default True\n",
      " |          If True, return a copy even if no copy is necessary (e.g. no\n",
      " |          conversion was done). Note: This is meant for internal use, and\n",
      " |          should not be confused with inplace.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same as input object\n",
      " |  \n",
      " |  copy(self, deep=True)\n",
      " |      Make a copy of this object\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean or string, default True\n",
      " |          Make a deep copy, i.e. also copy data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      copy : type of caller\n",
      " |  \n",
      " |  describe(self, percentiles=None, include=None, exclude=None)\n",
      " |      Generate various summary statistics, excluding NaN values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : array-like, optional\n",
      " |          The percentiles to include in the output. Should all\n",
      " |          be in the interval [0, 1]. By default `percentiles` is\n",
      " |          [.25, .5, .75], returning the 25th, 50th, and 75th percentiles.\n",
      " |      include, exclude : list-like, 'all', or None (default)\n",
      " |          Specify the form of the returned result. Either:\n",
      " |      \n",
      " |          - None to both (default). The result will include only numeric-typed\n",
      " |            columns or, if none are, only categorical columns.\n",
      " |          - A list of dtypes or strings to be included/excluded.\n",
      " |            To select all numeric types use numpy numpy.number. To select\n",
      " |            categorical objects use type object. See also the select_dtypes\n",
      " |            documentation. eg. df.describe(include=['O'])\n",
      " |          - If include is the string 'all', the output column-set will\n",
      " |            match the input one.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      summary: NDFrame of summary statistics\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The output DataFrame index depends on the requested dtypes:\n",
      " |      \n",
      " |      For numeric dtypes, it will include: count, mean, std, min,\n",
      " |      max, and lower, 50, and upper percentiles.\n",
      " |      \n",
      " |      For object dtypes (e.g. timestamps or strings), the index\n",
      " |      will include the count, unique, most common, and frequency of the\n",
      " |      most common. Timestamps also include the first and last items.\n",
      " |      \n",
      " |      For mixed dtypes, the index will be the union of the corresponding\n",
      " |      output types. Non-applicable entries will be filled with NaN.\n",
      " |      Note that mixed-dtype outputs can only be returned from mixed-dtype\n",
      " |      inputs and appropriate use of the include/exclude arguments.\n",
      " |      \n",
      " |      If multiple values have the highest count, then the\n",
      " |      `count` and `most common` pair will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      The include, exclude arguments are ignored for Series.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.select_dtypes\n",
      " |  \n",
      " |  drop(self, labels, axis=0, level=None, inplace=False, errors='raise')\n",
      " |      Return new object with labels in requested axis removed\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |      axis : int or axis name\n",
      " |      level : int or level name, default None\n",
      " |          For MultiIndex\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and existing labels are dropped.\n",
      " |      \n",
      " |          .. versionadded:: 0.16.1\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dropped : type of caller\n",
      " |  \n",
      " |  equals(self, other)\n",
      " |      Determines if two NDFrame objects contain the same elements. NaNs in the\n",
      " |      same location are considered equal.\n",
      " |  \n",
      " |  ffill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for NDFrame.fillna(method='ffill')\n",
      " |  \n",
      " |  filter(self, items=None, like=None, regex=None, axis=None)\n",
      " |      Restrict the info axis to set of items or wildcard\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          List of info axis to restrict to (must not all be present)\n",
      " |      like : string\n",
      " |          Keep info axis where \"arg in col == True\"\n",
      " |      regex : string (regular expression)\n",
      " |          Keep info axis with re.search(regex, col) == True\n",
      " |      axis : int or None\n",
      " |          The axis to filter on. By default this is the info axis. The \"info\n",
      " |          axis\" is the axis that is used when indexing with ``[]``. For\n",
      " |          example, ``df = DataFrame({'a': [1, 2, 3, 4]]}); df['a']``. So,\n",
      " |          the ``DataFrame`` columns are the info axis.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Arguments are mutually exclusive, but this is not checked for\n",
      " |  \n",
      " |  first(self, offset)\n",
      " |      Convenience method for subsetting initial periods of time series data\n",
      " |      based on a date offset\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ts.last('10D') -> First 10 days\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (DataFrame column, Panel slice,\n",
      " |      etc.). Returns default value if not found\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : type of items contained in object\n",
      " |  \n",
      " |  get_dtype_counts(self)\n",
      " |      Return the counts of dtypes in this object\n",
      " |  \n",
      " |  get_ftype_counts(self)\n",
      " |      Return the counts of ftypes in this object\n",
      " |  \n",
      " |  groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False)\n",
      " |      Group series using mapper (dict or key function, apply given function\n",
      " |      to group, return result as series) or by a series of columns\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping function / list of functions, dict, Series, or tuple /\n",
      " |          list of column names.\n",
      " |          Called on each element of the object index to determine the groups.\n",
      " |          If a dict or Series is passed, the Series or dict VALUES will be\n",
      " |          used to determine the groups\n",
      " |      axis : int, default 0\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels\n",
      " |      as_index : boolean, default True\n",
      " |          For aggregated output, return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output\n",
      " |      sort : boolean, default True\n",
      " |          Sort group keys. Get better performance by turning this off.\n",
      " |          Note this does not influence the order of observations within each group.\n",
      " |          groupby preserves the order of rows within each group.\n",
      " |      group_keys : boolean, default True\n",
      " |          When calling apply, add group keys to index to identify pieces\n",
      " |      squeeze : boolean, default False\n",
      " |          reduce the dimensionality of the return type if possible,\n",
      " |          otherwise return a consistent type\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      DataFrame results\n",
      " |      \n",
      " |      >>> data.groupby(func, axis=0).mean()\n",
      " |      >>> data.groupby(['col1', 'col2'])['col3'].mean()\n",
      " |      \n",
      " |      DataFrame with hierarchical index\n",
      " |      \n",
      " |      >>> data.groupby(['col1', 'col2']).mean()\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      GroupBy object\n",
      " |  \n",
      " |  head(self, n=5)\n",
      " |      Returns first n rows\n",
      " |  \n",
      " |  interpolate(self, method='linear', axis=0, limit=None, inplace=False, limit_direction='forward', downcast=None, **kwargs)\n",
      " |      Interpolate values according to different methods.\n",
      " |      \n",
      " |      Please note that only ``method='linear'`` is supported for DataFrames/Series\n",
      " |      with a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'linear', 'time', 'index', 'values', 'nearest', 'zero',\n",
      " |                'slinear', 'quadratic', 'cubic', 'barycentric', 'krogh',\n",
      " |                'polynomial', 'spline' 'piecewise_polynomial', 'pchip'}\n",
      " |      \n",
      " |          * 'linear': ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |            default\n",
      " |          * 'time': interpolation works on daily and higher resolution\n",
      " |            data to interpolate given length of interval\n",
      " |          * 'index', 'values': use the actual numerical values of the index\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      " |            'barycentric', 'polynomial' is passed to\n",
      " |            ``scipy.interpolate.interp1d``. Both 'polynomial' and 'spline'\n",
      " |            require that you also specify an `order` (int),\n",
      " |            e.g. df.interpolate(method='polynomial', order=4).\n",
      " |            These use the actual numerical values of the index.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', and 'pchip' are all\n",
      " |            wrappers around the scipy interpolation methods of similar\n",
      " |            names. These use the actual numerical values of the index. See\n",
      " |            the scipy documentation for more on their behavior\n",
      " |            `here <http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__\n",
      " |            `and here <http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__\n",
      " |      \n",
      " |      axis : {0, 1}, default 0\n",
      " |          * 0: fill column-by-column\n",
      " |          * 1: fill row-by-row\n",
      " |      limit : int, default None.\n",
      " |          Maximum number of consecutive NaNs to fill.\n",
      " |      limit_direction : {'forward', 'backward', 'both'}, defaults to 'forward'\n",
      " |          If limit is specified, consecutive NaNs will be filled in this\n",
      " |          direction.\n",
      " |      \n",
      " |          .. versionadded:: 0.17.0\n",
      " |      \n",
      " |      inplace : bool, default False\n",
      " |          Update the NDFrame in place if possible.\n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |      kwargs : keyword arguments to pass on to the interpolating function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame of same shape interpolated at the NaNs\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex, replace, fillna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Filling in NaNs\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s.interpolate()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  isnull(self)\n",
      " |      Return a boolean same-sized object indicating if the values are null\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      notnull : boolean inverse of isnull\n",
      " |  \n",
      " |  iterkv(self, *args, **kwargs)\n",
      " |      iteritems alias used to get around 2to3. Deprecated\n",
      " |  \n",
      " |  last(self, offset)\n",
      " |      Convenience method for subsetting final periods of time series data\n",
      " |      based on a date offset\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ts.last('5M') -> Last 5 months\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |  \n",
      " |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)\n",
      " |      Return an object of same shape as self and whose corresponding\n",
      " |      entries are from self where cond is False and otherwise are from other.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame or array\n",
      " |      other : scalar or NDFrame\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      axis : alignment axis if needed, default None\n",
      " |      level : alignment level if needed, default None\n",
      " |      try_cast : boolean, default False\n",
      " |          try to cast the result back to the input type (if possible),\n",
      " |      raise_on_error : boolean, default True\n",
      " |          Whether to raise on invalid data types (e.g. trying to where on\n",
      " |          strings)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh : same type as caller\n",
      " |  \n",
      " |  notnull(self)\n",
      " |      Return a boolean same-sized object indicating if the values are\n",
      " |      not null\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      isnull : boolean inverse of notnull\n",
      " |  \n",
      " |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, **kwargs)\n",
      " |      Percent change over given number of periods.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change\n",
      " |      fill_method : str, default 'pad'\n",
      " |          How to handle NAs before computing percent changes\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping\n",
      " |      freq : DateOffset, timedelta, or offset alias string, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay())\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chg : NDFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      By default, the percentage change is calculated along the stat\n",
      " |      axis: 0, or ``Index``, for ``DataFrame`` and 1, or ``minor`` for\n",
      " |      ``Panel``. You can change this with the ``axis`` keyword argument.\n",
      " |  \n",
      " |  pipe(self, func, *args, **kwargs)\n",
      " |      Apply func(self, \\*args, \\*\\*kwargs)\n",
      " |      \n",
      " |      .. versionadded:: 0.16.2\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          function to apply to the NDFrame.\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the NDFrame.\n",
      " |      args : positional arguments passed into ``func``.\n",
      " |      kwargs : a dictionary of keyword arguments passed into ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of ``func``.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      on Series or DataFrames. Instead of writing\n",
      " |      \n",
      " |      >>> f(g(h(df), arg1=a), arg2=b, arg3=c)\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(f, arg2=b, arg3=c)\n",
      " |      ... )\n",
      " |      \n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe((f, 'arg2'), arg1=a, arg3=c)\n",
      " |      ...  )\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.apply\n",
      " |      pandas.DataFrame.applymap\n",
      " |      pandas.Series.map\n",
      " |  \n",
      " |  pop(self, item)\n",
      " |      Return item and drop from frame. Raise KeyError if not found.\n",
      " |  \n",
      " |  reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)\n",
      " |      return an object with matching indicies to myself\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object\n",
      " |      method : string or None\n",
      " |      copy : boolean, default True\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between labels of the other object and this\n",
      " |          object for inexact matches.\n",
      " |      \n",
      " |          .. versionadded:: 0.17.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Like calling s.reindex(index=other.index, columns=other.columns,\n",
      " |                             method=...)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : same as input\n",
      " |  \n",
      " |  rename_axis(self, mapper, axis=0, copy=True, inplace=False)\n",
      " |      Alter index and / or columns using input function or functions.\n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : dict-like or function, optional\n",
      " |      axis : int or string, default 0\n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data\n",
      " |      inplace : boolean, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : type of caller\n",
      " |  \n",
      " |  replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad', axis=None)\n",
      " |      Replace values given in 'to_replace' with 'value'.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, numeric, or None\n",
      " |      \n",
      " |          * str or regex:\n",
      " |      \n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                `value`\n",
      " |      \n",
      " |          * list of str, regex, or numeric:\n",
      " |      \n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                lists will be interpreted as regexs otherwise they will match\n",
      " |                directly. This doesn't matter much for `value` since there\n",
      " |                are only a few possible substitution regexes you can use.\n",
      " |              - str and regex rules apply as above.\n",
      " |      \n",
      " |          * dict:\n",
      " |      \n",
      " |              - Nested dictionaries, e.g., {'a': {'b': nan}}, are read as\n",
      " |                follows: look in column 'a' for the value 'b' and replace it\n",
      " |                with nan. You can nest regular expressions as well. Note that\n",
      " |                column names (the top-level dictionary keys in a nested\n",
      " |                dictionary) **cannot** be regular expressions.\n",
      " |              - Keys map to column names and values map to substitution\n",
      " |                values. You can treat this as a special case of passing two\n",
      " |                lists except that you are specifying the column to search in.\n",
      " |      \n",
      " |          * None:\n",
      " |      \n",
      " |              - This means that the ``regex`` argument must be a string,\n",
      " |                compiled regular expression, or list, dict, ndarray or Series\n",
      " |                of such elements. If `value` is also ``None`` then this\n",
      " |                **must** be a nested dictionary or ``Series``.\n",
      " |      \n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to use to fill holes (e.g. 0), alternately a dict of values\n",
      " |          specifying which value to use for each column (columns not in the\n",
      " |          dict will not be filled). Regular expressions, strings and lists or\n",
      " |          dicts of such objects are also allowed.\n",
      " |      inplace : boolean, default False\n",
      " |          If True, in place. Note: this will modify any\n",
      " |          other views on this object (e.g. a column form a DataFrame).\n",
      " |          Returns the caller if this is True.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      " |          string. Otherwise, `to_replace` must be ``None`` because this\n",
      " |          parameter will be interpreted as a regular expression or a list,\n",
      " |          dict, or array of regular expressions.\n",
      " |      method : string, optional, {'pad', 'ffill', 'bfill'}\n",
      " |          The method to use when for replacement, when ``to_replace`` is a\n",
      " |          ``list``.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      NDFrame.reindex\n",
      " |      NDFrame.asfreq\n",
      " |      NDFrame.fillna\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : NDFrame\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not ``None``.\n",
      " |      TypeError\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |            ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable into a\n",
      " |            regular expression or is a list, dict, ndarray, or Series.\n",
      " |      ValueError\n",
      " |          * If `to_replace` and `value` are ``list`` s or ``ndarray`` s, but\n",
      " |            they are not the same length.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |        rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |        cannot provide, for example, a regular expression matching floating\n",
      " |        point numbers and expect the columns in your frame that have a\n",
      " |        numeric dtype to be matched. However, if those floating point numbers\n",
      " |        *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |        and play with this method to gain intuition about how it works.\n",
      " |  \n",
      " |  resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention='start', kind=None, loffset=None, limit=None, base=0)\n",
      " |      Convenience method for frequency conversion and resampling of regular\n",
      " |      time-series data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : string\n",
      " |          the offset string or object representing target conversion\n",
      " |      how : string\n",
      " |          method for down- or re-sampling, default to 'mean' for\n",
      " |          downsampling\n",
      " |      axis : int, optional, default 0\n",
      " |      fill_method : string, default None\n",
      " |          fill_method for upsampling\n",
      " |      closed : {'right', 'left'}\n",
      " |          Which side of bin interval is closed\n",
      " |      label : {'right', 'left'}\n",
      " |          Which bin edge label to label bucket with\n",
      " |      convention : {'start', 'end', 's', 'e'}\n",
      " |      kind : \"period\"/\"timestamp\"\n",
      " |      loffset : timedelta\n",
      " |          Adjust the resampled time labels\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to when reindexing with fill_method\n",
      " |      base : int, default 0\n",
      " |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      " |          aggregated intervals. For example, for '5min' frequency, base could\n",
      " |          range from 0 through 4. Defaults to 0\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Start by creating a series with 9 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> series = pd.Series(range(9), index=index)\n",
      " |      >>> series\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      2000-01-01 00:03:00    3\n",
      " |      2000-01-01 00:04:00    4\n",
      " |      2000-01-01 00:05:00    5\n",
      " |      2000-01-01 00:06:00    6\n",
      " |      2000-01-01 00:07:00    7\n",
      " |      2000-01-01 00:08:00    8\n",
      " |      Freq: T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and sum the values\n",
      " |      of the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> series.resample('3T', how='sum')\n",
      " |      2000-01-01 00:00:00     3\n",
      " |      2000-01-01 00:03:00    12\n",
      " |      2000-01-01 00:06:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but label each\n",
      " |      bin using the right edge instead of the left. Please note that the\n",
      " |      value in the bucket used as the label is not included in the bucket,\n",
      " |      which it labels. For example, in the original series the\n",
      " |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      " |      value in the resampled bucket with the label``2000-01-01 00:03:00``\n",
      " |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      " |      To include this value close the right side of the bin interval as\n",
      " |      illustrated in the example below this one.\n",
      " |      \n",
      " |      >>> series.resample('3T', how='sum', label='right')\n",
      " |      2000-01-01 00:03:00     3\n",
      " |      2000-01-01 00:06:00    12\n",
      " |      2000-01-01 00:09:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> series.resample('3T', how='sum', label='right', closed='right')\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:03:00     6\n",
      " |      2000-01-01 00:06:00    15\n",
      " |      2000-01-01 00:09:00    15\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> series.resample('30S')[0:5] #select first 5 rows\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:00:30   NaN\n",
      " |      2000-01-01 00:01:00     1\n",
      " |      2000-01-01 00:01:30   NaN\n",
      " |      2000-01-01 00:02:00     2\n",
      " |      Freq: 30S, dtype: float64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      " |      values using the ``pad`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S', fill_method='pad')[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the\n",
      " |      ``NaN`` values using the ``bfill`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S', fill_method='bfill')[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    1\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    2\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Pass a custom function to ``how``.\n",
      " |      \n",
      " |      >>> def custom_resampler(array_like):\n",
      " |      ...     return np.sum(array_like)+5\n",
      " |      \n",
      " |      >>> series.resample('3T', how=custom_resampler)\n",
      " |      2000-01-01 00:00:00     8\n",
      " |      2000-01-01 00:03:00    17\n",
      " |      2000-01-01 00:06:00    26\n",
      " |      Freq: 3T, dtype: int64\n",
      " |  \n",
      " |  sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)\n",
      " |      Returns a random sample of items from an axis of object.\n",
      " |      \n",
      " |      .. versionadded:: 0.16.1\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items from axis to return. Cannot be used with `frac`.\n",
      " |          Default = 1 if `frac` = None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of axis items to return. Cannot be used with `n`.\n",
      " |      replace : boolean, optional\n",
      " |          Sample with or without replacement. Default = False.\n",
      " |      weights : str or ndarray-like, optional\n",
      " |          Default 'None' results in equal probability weighting.\n",
      " |          If passed a Series, will align with target object on index. Index\n",
      " |          values in weights not found in sampled object will be ignored and\n",
      " |          index values in sampled object not in weights will be assigned\n",
      " |          weights of zero.\n",
      " |          If called on a DataFrame, will accept the name of a column\n",
      " |          when axis = 0.\n",
      " |          Unless weights are a Series, weights must be same length as axis\n",
      " |          being sampled.\n",
      " |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      " |          Missing values in the weights column will be treated as zero.\n",
      " |          inf and -inf values not allowed.\n",
      " |      random_state : int or numpy.random.RandomState, optional\n",
      " |          Seed for the random number generator (if int), or numpy RandomState\n",
      " |          object.\n",
      " |      axis : int or string, optional\n",
      " |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      " |          for given data type (0 for Series and DataFrames, 1 for Panels).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A new object of same type as caller.\n",
      " |  \n",
      " |  select(self, crit, axis=0)\n",
      " |      Return data corresponding to axis labels matching criteria\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      crit : function\n",
      " |          To be called on each index (label). Should return True or False\n",
      " |      axis : int\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      selection : type of caller\n",
      " |  \n",
      " |  set_axis(self, axis, labels)\n",
      " |      public verson of axis assignment\n",
      " |  \n",
      " |  slice_shift(self, periods=1, axis=0)\n",
      " |      Equivalent to `shift` without copying data. The shifted data will\n",
      " |      not include the dropped periods and the shifted axis will be smaller\n",
      " |      than the original.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      " |      later during alignment.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : same type as caller\n",
      " |  \n",
      " |  squeeze(self)\n",
      " |      squeeze length 1 dimensions\n",
      " |  \n",
      " |  swapaxes(self, axis1, axis2, copy=True)\n",
      " |      Interchange axes and swap values axes appropriately\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : same as input\n",
      " |  \n",
      " |  tail(self, n=5)\n",
      " |      Returns last n rows\n",
      " |  \n",
      " |  to_clipboard(self, excel=None, sep=None, **kwargs)\n",
      " |      Attempt to write text representation of object to the system clipboard\n",
      " |      This can be pasted into Excel, for example.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : boolean, defaults to True\n",
      " |              if True, use the provided separator, writing in a csv\n",
      " |              format for allowing easy pasting into excel.\n",
      " |              if False, write a string representation of the object\n",
      " |              to the clipboard\n",
      " |      sep : optional, defaults to tab\n",
      " |      other keywords are passed to to_csv\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform\n",
      " |        - Linux: xclip, or xsel (with gtk or PyQt4 modules)\n",
      " |        - Windows: none\n",
      " |        - OS X: none\n",
      " |  \n",
      " |  to_dense(self)\n",
      " |      Return dense representation of NDFrame (as opposed to sparse)\n",
      " |  \n",
      " |  to_hdf(self, path_or_buf, key, **kwargs)\n",
      " |      activate the HDFStore\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : the path (string) or HDFStore object\n",
      " |      key : string\n",
      " |          indentifier for the group in the store\n",
      " |      mode : optional, {'a', 'w', 'r', 'r+'}, default 'a'\n",
      " |      \n",
      " |        ``'r'``\n",
      " |            Read-only; no data can be modified.\n",
      " |        ``'w'``\n",
      " |            Write; a new file is created (an existing file with the same\n",
      " |            name would be deleted).\n",
      " |        ``'a'``\n",
      " |            Append; an existing file is opened for reading and writing,\n",
      " |            and if the file does not exist it is created.\n",
      " |        ``'r+'``\n",
      " |            It is similar to ``'a'``, but the file must already exist.\n",
      " |      format   : 'fixed(f)|table(t)', default is 'fixed'\n",
      " |          fixed(f) : Fixed format\n",
      " |                     Fast writing/reading. Not-appendable, nor searchable\n",
      " |          table(t) : Table format\n",
      " |                     Write as a PyTables Table structure which may perform\n",
      " |                     worse but allow more flexible operations like searching\n",
      " |                     / selecting subsets of the data\n",
      " |      append   : boolean, default False\n",
      " |          For Table formats, append the input data to the existing\n",
      " |      complevel : int, 1-9, default 0\n",
      " |          If a complib is specified compression will be applied\n",
      " |          where possible\n",
      " |      complib : {'zlib', 'bzip2', 'lzo', 'blosc', None}, default None\n",
      " |          If complevel is > 0 apply compression to objects written\n",
      " |          in the store wherever possible\n",
      " |      fletcher32 : bool, default False\n",
      " |          If applying compression use the fletcher32 checksum\n",
      " |      dropna : boolean, default False.\n",
      " |          If true, ALL nan rows will not be written to store.\n",
      " |  \n",
      " |  to_json(self, path_or_buf=None, orient=None, date_format='epoch', double_precision=10, force_ascii=True, date_unit='ms', default_handler=None)\n",
      " |      Convert the object to a JSON string.\n",
      " |      \n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : the path or buffer to write the result string\n",
      " |          if this is None, return a StringIO of the converted string\n",
      " |      orient : string\n",
      " |      \n",
      " |          * Series\n",
      " |      \n",
      " |            - default is 'index'\n",
      " |            - allowed values are: {'split','records','index'}\n",
      " |      \n",
      " |          * DataFrame\n",
      " |      \n",
      " |            - default is 'columns'\n",
      " |            - allowed values are:\n",
      " |              {'split','records','index','columns','values'}\n",
      " |      \n",
      " |          * The format of the JSON string\n",
      " |      \n",
      " |            - split : dict like\n",
      " |              {index -> [index], columns -> [columns], data -> [values]}\n",
      " |            - records : list like\n",
      " |              [{column -> value}, ... , {column -> value}]\n",
      " |            - index : dict like {index -> {column -> value}}\n",
      " |            - columns : dict like {column -> {index -> value}}\n",
      " |            - values : just the values array\n",
      " |      \n",
      " |      date_format : {'epoch', 'iso'}\n",
      " |          Type of date conversion. `epoch` = epoch milliseconds,\n",
      " |          `iso`` = ISO8601, default is epoch.\n",
      " |      double_precision : The number of decimal places to use when encoding\n",
      " |          floating point values, default 10.\n",
      " |      force_ascii : force encoded string to be ASCII, default True.\n",
      " |      date_unit : string, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object with filtered info axis\n",
      " |  \n",
      " |  to_msgpack(self, path_or_buf=None, **kwargs)\n",
      " |      msgpack (serialize) object to input file path\n",
      " |      \n",
      " |      THIS IS AN EXPERIMENTAL LIBRARY and the storage format\n",
      " |      may not be stable until a future release.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string File path, buffer-like, or None\n",
      " |          if None, return generated string\n",
      " |      append : boolean whether to append to an existing msgpack\n",
      " |          (default is False)\n",
      " |      compress : type of compressor (zlib or blosc), default to None (no\n",
      " |          compression)\n",
      " |  \n",
      " |  to_pickle(self, path)\n",
      " |      Pickle (serialize) object to input file path\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string\n",
      " |          File path\n",
      " |  \n",
      " |  to_sql(self, name, con, flavor='sqlite', schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None)\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : string\n",
      " |          Name of SQL table\n",
      " |      con : SQLAlchemy engine or DBAPI2 connection (legacy mode)\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library.\n",
      " |          If a DBAPI2 object, only sqlite3 is supported.\n",
      " |      flavor : {'sqlite', 'mysql'}, default 'sqlite'\n",
      " |          The flavor of SQL to use. Ignored when using SQLAlchemy engine.\n",
      " |          'mysql' is deprecated and will be removed in future versions, but it\n",
      " |          will be further supported through SQLAlchemy engines.\n",
      " |      schema : string, default None\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          - fail: If table exists, do nothing.\n",
      " |          - replace: If table exists, drop it, recreate it, and insert data.\n",
      " |          - append: If table exists, insert data. Create if does not exist.\n",
      " |      index : boolean, default True\n",
      " |          Write DataFrame index as a column.\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, default None\n",
      " |          If not None, then rows will be written in batches of this size at a\n",
      " |          time.  If None, all rows will be written at once.\n",
      " |      dtype : dict of column name to SQL type, default None\n",
      " |          Optional specifying the datatype for columns. The SQL type should\n",
      " |          be a SQLAlchemy type, or a string for sqlite3 fallback connection.\n",
      " |  \n",
      " |  truncate(self, before=None, after=None, axis=None, copy=True)\n",
      " |      Truncates a sorted NDFrame before and/or after some particular\n",
      " |      dates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date\n",
      " |          Truncate before date\n",
      " |      after : date\n",
      " |          Truncate after date\n",
      " |      axis : the truncation axis, defaults to the stat axis\n",
      " |      copy : boolean, default is True,\n",
      " |          return a copy of the truncated section\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      truncated : type of caller\n",
      " |  \n",
      " |  tshift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift the time index, using the index's frequency if available\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, default None\n",
      " |          Increment to use from datetools module or time rule (e.g. 'EOM')\n",
      " |      axis : int or basestring\n",
      " |          Corresponds to the axis that contains the Index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : NDFrame\n",
      " |  \n",
      " |  tz_convert(self, tz, axis=0, level=None, copy=True)\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the axis is tz-naive.\n",
      " |  \n",
      " |  tz_localize(*args, **kwargs)\n",
      " |      Localize tz-naive TimeSeries to target time zone\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous times\n",
      " |      infer_dst : boolean, default False (DEPRECATED)\n",
      " |          Attempt to infer fall dst-transition hours based on order\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the TimeSeries is tz-aware and tz is not None.\n",
      " |  \n",
      " |  where(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)\n",
      " |      Return an object of same shape as self and whose corresponding\n",
      " |      entries are from self where cond is True and otherwise are from other.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame or array\n",
      " |      other : scalar or NDFrame\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      axis : alignment axis if needed, default None\n",
      " |      level : alignment level if needed, default None\n",
      " |      try_cast : boolean, default False\n",
      " |          try to cast the result back to the input type (if possible),\n",
      " |      raise_on_error : boolean, default True\n",
      " |          Whether to raise on invalid data types (e.g. trying to where on\n",
      " |          strings)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh : same type as caller\n",
      " |  \n",
      " |  xs(self, key, axis=0, level=None, copy=None, drop_level=True)\n",
      " |      Returns a cross-section (row(s) or column(s)) from the Series/DataFrame.\n",
      " |      Defaults to cross-section on the rows (axis=0).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |          Some label contained in the index, or partially in a MultiIndex\n",
      " |      axis : int, default 0\n",
      " |          Axis to retrieve cross-section on\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      copy : boolean [deprecated]\n",
      " |          Whether to make a copy of the data\n",
      " |      drop_level : boolean, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      a  4  5  2\n",
      " |      b  4  0  9\n",
      " |      c  9  7  3\n",
      " |      >>> df.xs('a')\n",
      " |      A    4\n",
      " |      B    5\n",
      " |      C    2\n",
      " |      Name: a\n",
      " |      >>> df.xs('C', axis=1)\n",
      " |      a    2\n",
      " |      b    9\n",
      " |      c    3\n",
      " |      Name: C\n",
      " |      \n",
      " |      >>> df\n",
      " |                          A  B  C  D\n",
      " |      first second third\n",
      " |      bar   one    1      4  1  8  9\n",
      " |            two    1      7  5  5  0\n",
      " |      baz   one    1      6  6  8  0\n",
      " |            three  2      5  3  5  3\n",
      " |      >>> df.xs(('baz', 'three'))\n",
      " |             A  B  C  D\n",
      " |      third\n",
      " |      2      5  3  5  3\n",
      " |      >>> df.xs('one', level=1)\n",
      " |                   A  B  C  D\n",
      " |      first third\n",
      " |      bar   1      4  1  8  9\n",
      " |      baz   1      6  6  8  0\n",
      " |      >>> df.xs(('baz', 2), level=[0, 'third'])\n",
      " |              A  B  C  D\n",
      " |      second\n",
      " |      three   5  3  5  3\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      xs : Series or DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      xs is only for getting, not setting values.\n",
      " |      \n",
      " |      MultiIndex Slicers is a generic way to get/set values on any level or levels\n",
      " |      it is a superset of xs functionality, see :ref:`MultiIndex Slicers <advanced.mi_slicers>`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  at\n",
      " |      Fast label-based scalar accessor\n",
      " |      \n",
      " |      Similarly to ``loc``, ``at`` provides **label** based scalar lookups.\n",
      " |      You can also set using these indexers.\n",
      " |  \n",
      " |  blocks\n",
      " |      Internal property, property synonym for as_blocks()\n",
      " |  \n",
      " |  empty\n",
      " |      True if NDFrame is entirely empty [no items]\n",
      " |  \n",
      " |  iat\n",
      " |      Fast integer location scalar accessor.\n",
      " |      \n",
      " |      Similarly to ``iloc``, ``iat`` provides **integer** based lookups.\n",
      " |      You can also set using these indexers.\n",
      " |  \n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |      \n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      \n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |      \n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`\n",
      " |  \n",
      " |  ix\n",
      " |      A primarily label-location based indexer, with integer position\n",
      " |      fallback.\n",
      " |      \n",
      " |      ``.ix[]`` supports mixed integer and label based access. It is\n",
      " |      primarily label based, but will fall back to integer positional\n",
      " |      access unless the corresponding axis is of integer type.\n",
      " |      \n",
      " |      ``.ix`` is the most general indexer and will support any of the\n",
      " |      inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n",
      " |      point label schemes. ``.ix`` is exceptionally useful when dealing\n",
      " |      with mixed positional and label based hierachical indexes.\n",
      " |      \n",
      " |      However, when an axis is integer based, ONLY label based access\n",
      " |      and not positional access is supported. Thus, in such cases, it's\n",
      " |      usually better to be explicit and use ``.iloc`` or ``.loc``.\n",
      " |      \n",
      " |      See more at :ref:`Advanced Indexing <advanced>`.\n",
      " |  \n",
      " |  loc\n",
      " |      Purely label-location based indexer for selection by label.\n",
      " |      \n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'`` (note that contrary\n",
      " |        to usual python slices, **both** the start and the stop are included!).\n",
      " |      - A boolean array.\n",
      " |      \n",
      " |      ``.loc`` will raise a ``KeyError`` when the items are not found.\n",
      " |      \n",
      " |      See more at :ref:`Selection by Label <indexing.label>`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  is_copy = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion\n",
      " |      Only provide 'public' methods\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by bytes(obj) in py3 only.\n",
      " |      Yields a bytestring in both py2/py3.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string representation for a particular Object\n",
      " |      \n",
      " |      Invoked by str(df) in both py2/py3.\n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-06 00:00:00+00:00   -0.959711\n",
       "2012-03-07 00:00:00+00:00    0.526086\n",
       "2012-03-08 00:00:00+00:00   -0.521024\n",
       "2012-03-09 00:00:00+00:00    0.654200\n",
       "2012-03-10 00:00:00+00:00    0.886755\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_utc = ts.tz_localize('UTC')\n",
    "ts_utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-05 19:00:00-05:00   -0.959711\n",
       "2012-03-06 19:00:00-05:00    0.526086\n",
       "2012-03-07 19:00:00-05:00   -0.521024\n",
       "2012-03-08 19:00:00-05:00    0.654200\n",
       "2012-03-09 19:00:00-05:00    0.886755\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_utc.tz_convert('US/Eastern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-01-31   -0.203995\n",
       "2012-02-29    1.913204\n",
       "2012-03-31    0.879465\n",
       "2012-04-30    1.461316\n",
       "2012-05-31    1.374759\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = pd.date_range('1/1/2012', periods=5, freq='M')\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-01   -0.203995\n",
       "2012-02    1.913204\n",
       "2012-03    0.879465\n",
       "2012-04    1.461316\n",
       "2012-05    1.374759\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = ts.to_period()\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-01-01   -0.203995\n",
       "2012-02-01    1.913204\n",
       "2012-03-01    0.879465\n",
       "2012-04-01    1.461316\n",
       "2012-05-01    1.374759\n",
       "Freq: MS, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1990Q1    0.767647\n",
       "1990Q2    0.394950\n",
       "1990Q3   -1.337019\n",
       "1990Q4   -0.852320\n",
       "1991Q1    1.366757\n",
       "1991Q2   -0.327469\n",
       "1991Q3    0.357701\n",
       "1991Q4    0.247618\n",
       "1992Q1    1.760254\n",
       "1992Q2   -0.991463\n",
       "1992Q3    0.317794\n",
       "1992Q4   -0.866047\n",
       "1993Q1   -1.245516\n",
       "1993Q2    0.990503\n",
       "1993Q3    0.489677\n",
       "1993Q4   -0.910733\n",
       "1994Q1   -0.317702\n",
       "1994Q2   -1.840909\n",
       "1994Q3    1.237823\n",
       "1994Q4    0.469113\n",
       "1995Q1   -0.826911\n",
       "1995Q2   -0.959940\n",
       "1995Q3   -1.219522\n",
       "1995Q4   -2.157032\n",
       "1996Q1   -0.853892\n",
       "1996Q2    0.847379\n",
       "1996Q3    1.581184\n",
       "1996Q4    0.991717\n",
       "1997Q1   -0.379610\n",
       "1997Q2    0.837162\n",
       "1997Q3    0.020313\n",
       "1997Q4   -0.959233\n",
       "1998Q1   -0.654387\n",
       "1998Q2    0.552624\n",
       "1998Q3   -0.159892\n",
       "1998Q4   -0.625179\n",
       "1999Q1   -0.885246\n",
       "1999Q2   -0.829367\n",
       "1999Q3   -1.812030\n",
       "1999Q4   -0.936392\n",
       "2000Q1    0.411535\n",
       "2000Q2   -1.101120\n",
       "2000Q3    0.804290\n",
       "2000Q4   -1.009512\n",
       "Freq: Q-NOV, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prng = pd.period_range('1990Q1', '2000Q4', freq='Q-NOV')\n",
    "ts = pd.Series(np.random.randn(len(prng)), prng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1990-03-01 09:00    0.767647\n",
       "1990-06-01 09:00    0.394950\n",
       "1990-09-01 09:00   -1.337019\n",
       "1990-12-01 09:00   -0.852320\n",
       "1991-03-01 09:00    1.366757\n",
       "1991-06-01 09:00   -0.327469\n",
       "1991-09-01 09:00    0.357701\n",
       "1991-12-01 09:00    0.247618\n",
       "1992-03-01 09:00    1.760254\n",
       "1992-06-01 09:00   -0.991463\n",
       "1992-09-01 09:00    0.317794\n",
       "1992-12-01 09:00   -0.866047\n",
       "1993-03-01 09:00   -1.245516\n",
       "1993-06-01 09:00    0.990503\n",
       "1993-09-01 09:00    0.489677\n",
       "1993-12-01 09:00   -0.910733\n",
       "1994-03-01 09:00   -0.317702\n",
       "1994-06-01 09:00   -1.840909\n",
       "1994-09-01 09:00    1.237823\n",
       "1994-12-01 09:00    0.469113\n",
       "1995-03-01 09:00   -0.826911\n",
       "1995-06-01 09:00   -0.959940\n",
       "1995-09-01 09:00   -1.219522\n",
       "1995-12-01 09:00   -2.157032\n",
       "1996-03-01 09:00   -0.853892\n",
       "1996-06-01 09:00    0.847379\n",
       "1996-09-01 09:00    1.581184\n",
       "1996-12-01 09:00    0.991717\n",
       "1997-03-01 09:00   -0.379610\n",
       "1997-06-01 09:00    0.837162\n",
       "1997-09-01 09:00    0.020313\n",
       "1997-12-01 09:00   -0.959233\n",
       "1998-03-01 09:00   -0.654387\n",
       "1998-06-01 09:00    0.552624\n",
       "1998-09-01 09:00   -0.159892\n",
       "1998-12-01 09:00   -0.625179\n",
       "1999-03-01 09:00   -0.885246\n",
       "1999-06-01 09:00   -0.829367\n",
       "1999-09-01 09:00   -1.812030\n",
       "1999-12-01 09:00   -0.936392\n",
       "2000-03-01 09:00    0.411535\n",
       "2000-06-01 09:00   -1.101120\n",
       "2000-09-01 09:00    0.804290\n",
       "2000-12-01 09:00   -1.009512\n",
       "Freq: H, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.index = (prng.asfreq('M', 'e') + 1).asfreq('H', 's') + 9\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1990-03-01 09:00    0.767647\n",
       "1990-06-01 09:00    0.394950\n",
       "1990-09-01 09:00   -1.337019\n",
       "1990-12-01 09:00   -0.852320\n",
       "1991-03-01 09:00    1.366757\n",
       "Freq: H, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id raw_grade\n",
       "0   1         a\n",
       "1   2         b\n",
       "2   3         b\n",
       "3   4         a\n",
       "4   5         a\n",
       "5   6         e"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"id\":[1,2,3,4,5,6], \"raw_grade\":['a', 'b', 'b', 'a', 'a', 'e']})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a\n",
       "1    b\n",
       "2    b\n",
       "3    a\n",
       "4    a\n",
       "5    e\n",
       "Name: grade, dtype: category\n",
       "Categories (3, object): [a, b, e]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"grade\"] = df[\"raw_grade\"].astype(\"category\")\n",
    "df[\"grade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"grade\"].cat.categories = [\"very good\", \"good\", \"very bad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    very good\n",
       "1         good\n",
       "2         good\n",
       "3    very good\n",
       "4    very good\n",
       "5     very bad\n",
       "Name: grade, dtype: category\n",
       "Categories (5, object): [very bad, bad, medium, good, very good]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"grade\"] = df[\"grade\"].cat.set_categories([\"very bad\", \"bad\", \"medium\", \"good\", \"very good\"])\n",
    "df[\"grade\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_grade</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>e</td>\n",
       "      <td>very bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id raw_grade      grade\n",
       "5   6         e   very bad\n",
       "1   2         b       good\n",
       "2   3         b       good\n",
       "0   1         a  very good\n",
       "3   4         a  very good\n",
       "4   5         a  very good"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"grade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grade\n",
       "very bad     1\n",
       "bad          0\n",
       "medium       0\n",
       "good         2\n",
       "very good    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"grade\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1177af650>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEMCAYAAADQ553CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXl8FPX5xz9POHOQg1wEApFL5FARBUVqjeKFVqVCqVfV\nqr96H9Vaj7YS1Fq1tFpvqf4sWhWt/ipWQRQ1XoBCxcplQG4CCciRgwAhyff3x7Pfzuxkd7PH7M7s\n7PN+vfKa2dnZme9mdj/7zPN9DlJKQRAEQfAOaU4PQBAEQbAXEXZBEASPIcIuCILgMUTYBUEQPIYI\nuyAIgscQYRcEQfAYMQs7EXUjoi+IaCkRLSOiqb7teUT0HhFVEdE8IsqJfbiCIAhCR5AdcexElKGU\naiKiTgA+B3AjgEkAdiqlHiKi2wHkKaXuiPlkgiAIQkhsccUopZp8q90AdAagAJwLYKZv+0wAE+04\nlyAIghAaW4SdiNKIaCmAGgDvK6UWAyhWStUCgFKqBkCRHecSBEEQQmOXxd6mlDoKQCmAMUQ0HGy1\n++1mx7kEQRCE0HS282BKqXoiqgRwBoBaIipWStUSUS8A2wO9hohE8AVBEKJAKUWBttsRFVOgI16I\nKB3AqQBWAXgLwGW+3S4FMDvE4ML6mzp1qi37RLqvU/ul6rndvl8yjDEZ3ku4+3rpPds5xlDYYbGX\nAJhJRGngH4pXlVJziGgRgNeI6HIAGwFMifVE5eXltuwT6b5O7ee1czt13mT433jpvUSCnd9pL12/\nSPe1Yku4YywQkXJ6DEJiqKioQEVFhdPDEOKMXOfEQERQ8XLFCEK4xMPiE9yHXGfnEYtdEAQhCRGL\nXRAEIYUQYRcEQfAYIuyCIAgeQ4RdEATBY4iwC4IgeAwRdkEQBI8hwi4IguAxRNgFQRA8hgi7IAiC\nxxBhFwRB8Bgi7IIgCB5DhF0QBMFjiLALgiB4DBF2QRAEjyHCLgiC4DFE2AVBEDyGCLsgCILHEGEX\nBEHwGCLsgiAIHkOEXUgIq1YBRx7p9CgEITUQYRcSwrx5wDffOD0KQUgNRNiFhLBrFy+VcnYcgpAK\niLALCWHvXl7ecouz4xCEVECEXUgIjY28fOQRZ8chCKmACLuQEBoanB6BIKQOIuxCQmhsBJ59ltfF\nzy4I8SVmYSeiUiL6kIhWENEyIrrRtz2PiN4joioimkdEObEPV0hWGhuB/v2B9HSgqcnp0QiCt7HD\nYm8BcItSajiAsQCuI6LDANwBYL5SagiADwHcacO5hCSloQHIygL27QOOO87p0QiCt4lZ2JVSNUqp\nr33rjQBWASgFcC6Amb7dZgKYGOu5hOSloQHo0YPXly8HmpudHY8geBlbfexEdAiAkQAWAShWStUC\nLP4Aiuw8l5A8tLYCmzYB/foBu3cDJSXA6tVOj0oQvEtnuw5ERFkAXgdwk1KqkYisU2QyZZaifPcd\nUFgIZGby48GDgR07nB2TIHgZW4SdiDqDRf1FpdRs3+ZaIipWStUSUS8A24O9vqKi4r/r5eXlKC8v\nt2NYQpTU1gJPPgn06gVcfTVAFNvxXnwRmGhyxBUWirALQqRUVlaisrIyrH1J2RB7RkQvAPheKXWL\naduDAHYppR4kotsB5Cml7gjwWmXHGAT7+MMfgLvu4vUdO4CCguiPtWQJMHYs8OGHwAkn8LZrrgEO\nPxy49trYxyoIqQoRQSkV0OyyI9xxHICLAJxMREuJ6CsiOgPAgwBOJaIqAOMBPBDruYT4ohQweTKw\nbBlwxBG8LdbEotGjgZYWYNQoY1tBgVjsghBPYnbFKKU+B9ApyNOnxHp8IXFs2AC88QbQtSuwaBEw\nZUrswt6pE0+eav86wK6YNWtiO64gCMGxbfJUSG6WLGHrGuBQxBEjgKIioL7e2OfgQaBLl8iO+6Mf\nAaWl/tsKCoAFC2IbryAIwZGSAgIA4PXXeVlYyMsuXYDsbEPY589nS/6zzyI77oEDwJln+m8rLAS+\n/z628QqCEBwRdgEAcMghvDzmGGNbdrbhijn1VF4uWhTZcc2JSZqCAmB70BgpQRBiRVwxAgCgrQ24\n6CKOXPngA96WlcUWuzlLdOfOwK8/eBBIS2OfOgD85jdAcTELe3a2/76DBnFse0sL0Fk+gYJgO2Kx\nC/jgA6CqioX4qqvYfQIAGRlc20Vb7Q89xPtWV7c/xsCBwHXXGY/vvx+46SZuh2e12Hv0AHr3lglU\nQYgXIuwCTjkFePRRrrxoRgt7fT1QVsYlARYvBu6913+/zz4DNm8G9uwJfPz8/PbbysqALVuMxwcO\ncESOIAixI8Iu/JeMjPaPm5pY2LOzOdEIAPr0MfbZvt1IPNq5k1068+f7H8fqigHYYt+61Xj85psc\nQ3/wYOzvQxBSHfFwpjjmpF+rxZ6ezolEWtj79QMefNA/ouWrr3iZn8+CPnMmsHat/3EClSTo08ff\npbNpEy+7dpVGHIIQK2KxpzjmidFAFrt2xWiru0cP9rlffz0/t2MHcOGFwAO+vOJVq9hyP+OM0Oe1\nWux1dcZ6a2v070cQBBH2lGfvXmO9I1cMYMS2P/EEW+aXXML+8XHj+PktW/iY2q8+bVrg8/bpYwj7\nm2/63wXU1MT+vgQhlRFhT3HMwj5ypP9zwYRdT5Jqf/h33wFDhwKVlcDGjXzMc89ly/7uuwOft3dv\nwxXz4x8Dzz3HFSWPOcZ/UlUQhMgRYU9xmpq4Pvqzz3IZATOBXDEFBcCcObyuBfjFF3l5xBFcKmDe\nPK4Nk5UV/LxWV0xLC7+mqEgKhAlCrMjkaYqzdy8L6hVXtH8uO5s7HpmFfdgw4/m1a4EBA7gELwDk\n5fkfMxQlJVz3va3N2JaRwT8cZsEXBCFyxGJPcUKJcHExhzPW1wM5ObxNLwFg+vT2MerPPsvLjoS9\na1cgN9ffn56ZyXVkrroKuPnmyN6HIAgGIuwpzllnAZ9/Hvi5oiK2qs0WO2CIbnW1v8UNsCUOdCzs\nALtjzA1h0tL4nADwl7+ENXxBEAIgwp7ihKq3npfHE6Uff+wv7Lpg2LRpwO23+7/m6KOBIUMMgQ/F\nqlVcn0ZXlGxuBn7xC+Cpp4Bu3di/LwhC5NjSGi+mAUhrPEc54QSu66KzR6088ABw553Ae+8ZFR5b\nW9mS7907tnOnpXEy0pAhwOzZPImb5jM1Bgzgcw4aFNs5BMGrxLU1npDc1Ne3L9JlZsIEXpot9k6d\nYhd1gJtw6GMPGWKIOsAuGSntKwjRIcKe4lj951a0myTUPtHy5pvs1gn0w5KZyaGYgiBEjgh7itOR\nsBcU8DJUTHq0pKUBvXoFPr9OjhIEIXJE2FOYxYuBxsbQwt61K7teevaMzxiKiwNb7CLsghA9kqCU\norS2Aj/5Ccedd+0aet+WlviNo7g4cIPsjAzg3Xd5bOedF7/zC4IXEYs9RVmyhN0rP/uZs+MoLQ18\nN5CRwSWAJ00CZsxI/LgSyZ//HLzloCBEgwh7irJ6dfuiX05w663Ar3/dfru5hvuvfpW48TjBrbcC\n//yn06MQvIS4YlKUhobQYY6JwloqWKMbeADA6NGJGYuTpImJJdiIfJxSFLcIezD0hO6NNwbvpeoF\ndOlj3UFKEOxAhD1F6SgxyWlefRX49FPgppu8m6iklFGiOFhDEkGIBhH2FGL/fvZda0Fxs7Dn5AA/\n+AFnuG7f7s0+qOef798YXBDsQoQ9hVi9mpdVVcBf/2q4AdxM9+78Z+6J6hWWLjXWiTisdPlyrs8z\nf75z4xKSH1uEnYieI6JaIvrGtC2PiN4joioimkdEOaGOIcSXqirgT3/i9X/9i5fWWupupb4eGD/e\n6VHYz6GH8rK0lGvT19UBN9zARdd0wTVBiAa7LPbnAZxu2XYHgPlKqSEAPgRwp03nCsmWLfFNqElG\nHn8cOOww4IUX+HF1NXDllcDllzs7rkjwWru8gwc5j+DxxzmnIDcXeOcdYN06Y59bbgEWLnRujELy\nYouwK6U+A7DbsvlcADN96zMBTLTjXB3Rty/w0EOJOFPycMMN/o+rq8NrhOEWXnoJGDfO6VEEZ+9e\nzpINly+/5Izaujqgf3/Ovs3LAy691D865uGHjb/9++0ft+Bd4uljL1JK1QKAUqoGQFEcz+XH8uWJ\nOlNysmJFfIp6xYusLBZPt/LCC0Z543DYuJGXwVoOfvedsf6Pf7DlfsstsY9TSB0SmaAUNK6hoqLi\nv+vl5eUoLy+P6URenGizi/x87lzUrZvTIwmfzEwuVuZWunePbP/6el5u3WrE63//vfH8gAHtX/PU\nU8ATT/hn5AqpRWVlJSrNvSRDEE9hryWiYqVULRH1AhA0Gtks7LHQ2spLL4bGxcqVV3LBrzFjgLlz\n3S2UVjIz3W2xp6fzsq0tvAzSK6/k5YYNhqU+ZgywbBlwwQUs3jU1bKDMnQtccQWHpi5cCAwbxv54\nIfWwGr3TQiQ/2OmKId+f5i0Al/nWLwUw28ZzBURb6l7OVIyGHj04IqatzWgWra3GZMDtwq7DRnft\n6njf/fvZv37EEfxYC/uzz/L1efllflxczFEzN91kuM3GjWNfvCB0hF3hji8DWADgUCLaREQ/B/AA\ngFOJqArAeN/juKLrd0ulPIO2NhbFrCy2BB95hLfrzkjJgNt97Hps4cSeV1VxH1dtdZvnOkK5WY49\nNvrxCamHLa4YpdSFQZ46xY7jh8u+fWydmv2Vqc7u3ezH1S6C3FzelkyTp25vutHUxBmyzz/P2aSh\nWL4cGDGCm4ED3MQkHB591BD3lhags5TvE0LgiczTVauADz9kYe/bl2+Jb7rJ6VE5T10dp+MXF/tv\nz81NLmHo3t3d4X579wLHHw+sX9/xvlrY29oiO4f5Grr57kVwB54Q9rvu4szE/fuNMrCPPpraiUp1\ndUBZGfD3vxt+9WQlPZ1/tN1KUxPQr194d4pa2CO9AyktNdZF2IWO8ISwH3IIL5ctYxF49VV+7LVs\nxY5obeU/pYDNm1nc77+/49Z3bqdLF/6R1lFPbqOpiYt51dd3XH+nqoqzgCOtWGl22TQ1SeSXEBpP\nCLueLP3gA75tnzKF47U//JCTcd55x9nxJYrOnflvxgwuraD5y1+cG5MdEPF1PXDA6ZEEZu9entvJ\nywsdGaMUX5e+fYHDDwdGjYrsPM3N/Lo775SqkEJoksjTGpwdO4BevYBXXjG27dzJLccAnqhKJQtn\n0SJ/C2/4cOfGYhfaHROs45KTNDVxSGZBAbtjrHMamt27+e4pKwuYPTvyz2SXLnyerVuBbdtiH7fg\nXTxhsW/f3j777403gLFjUzPud9Ei4OmnnR6Fvbh5AnXvXv7BKSwM7WevrjYs7c6dWagjJTPTeF0y\nJZkJicUTwr5jR/sJwh49uP2bxq238fHg22+Bf//b6VHYS/fuHP3kRqwWezC2bPGfBI2GzEzD9XjW\nWbEdS/AuSe+KUYot9i+/ZDHTt7dZWexz11x5JRdf+uQTZ8ZphoijI+x0kXg9AmjdOq5R7kaXWlMT\nW+y69O6kSYH3M1vs0ZKZafx4uOGzLLiTpBf2xka+re3Vy9+CsbZ9+/vfeamUOwoprVplr7D/7W/t\nt/35z8AXX9h3DiEwe/ey4I4cCdx7b/D95s6NfMLUihb2008Pr4SBkJokvStm+/bA6fHB+nlu3Rrf\n8YRLc7M9xzl4EJg+nSNh9MTipZdybZhf/hKYNcue87iFV15xn6Bpi33yZCPxq1cv/9rq33/Pd5Cx\nJs5lZPDd2ejR3m3yLcRO0gt7IP86YIjcG2/wl0zjdK32NWt4aVeSyXffAbfdBixeDJziK+AwY4b3\n6ne/9x4vL7wQePFFZ8diRZdtyM9nAVeKI7G++cbYZ/16YODA2Es56AYp/fqlXp6GED5JL+zBLPbC\nQm45dt55wIIFvO2ss5wX9qFDeWmXtWVOY9cRQNFEW7gdcw/Qqqr4nqutjd114fz41tTw/sXFXOO+\ne3ejcqZ5wr6hwai9Hgta2AsL+U5hxYrYjyl4j6QX9mAWOwAcfTQve/bk5YQJzn8RdPbkb39rT7Gy\nDRuM96+/9G6YQ4gn8Q571B2OwgknrKriH2v9Py8oMCxpcxmE+vrg7sFI0NdY35GOGBH7MQXvkfTC\nHsxiN5OTA6xezf0lnU7sOPFEY/3zz2M/Xm0tcNRRvJ4qPtd4h66uXMnLcCx2a5G1ggL+sQX8y0fb\nZbEPHMjLww83tnk9IkqInKQX9h07wqstPngw7+e0X7KoiFucAeFVAwzFpk3AP/8JDBnCj885hzvw\neBVdejhRwq5FNBTbt/vfMZqF/auvjO12Weynn85zDCUl/scWBDNJL+zWL1Yoioqct2qbmrhWyOOP\nx55wU1bGhc9GjOAmDz/7mdGBx4v885/A2WezsB88yJE/8SASH77VsOjUCXjA11Jm4UKeSH3nHRZ5\nOyz2rl2Biy/23yY9fgUrSS/s4VrsgCHskdbCthMd8zx0aGzCrq39sjJuwDB+vD3jczPnnANcdx0L\ne1UV8KtfxSdhyXxXd+yxoUvsWud4Pv4YWLuW76K2bOGaMD/6EfC//xu8hkysiLALVpJe2COx2NPT\n+UfAHF+caLSwl5ZyREW0PPUULzdsMPpnpgLdurGw64nnePS3NfvGv/zSyH1YsIDrD5mxzvEsWsTL\nIUPYup4zx3hu9Gh7x3n22TxpK64YwUrSC3skFjvAtbCdrDmihT0rK7YiTs3NnFmaamhhr67mx/Fw\nrVkToPSPx9y5hnBrrJ8/7Zfv04ddbgsXchlpIPasUytvvQVMnGi02RMETVILu1KRC3usLpBYaG3l\nBhh9+sQm7Pv2cY31eN3au5lECLu1Gbq+OwjkwrO6YnSV0fx8vitbvhw46STeR4cq2kn//rFPwgve\nI6mFvb6eb3fT08N/jZPCXlnJTY/z8vhLvndvex9xc3PHUR/r1vEykh80r6CFXbtH7BZ2pdhi//Zb\nY5sW9kD+/GDhtj/4AVvsAFBeHj+resAA4Pbbgc8+i8/xheQkqYU9VHJSMMrK2Gp2grfeAi6/nNc7\ndWKRsvbyPOkk4IwzQh9n2zaOhzdnY6YKWti3beP8BLuFvaGBrW4dQgoYk6lWYW9t5XIC+fn+27dv\n57DE3r35sfV5O9F5Ef/5T/zOkWxMmwZ8+qnTo3CWpBb2cJKTrPTuDcybxyKbaGpquMaHxuyOufde\nbsq9YEHHk7tbtxrWYKqhW+Rt3crVFO0W9p07jUzlOXOAu+82LHZrDsSuXVyqt7OlRqr+TOrj5Oba\nO0YzI0bwj4jXs40joaIC+OEP4zOxniwktbBHY7HrxA4nasbU1PgXJDML++9/D/zhD7xu3gdon0Jf\nWxv5+/YK2dkc3rdxIwt7LJFFgdi1y7CwJ0zgz8v337N//bnneLsuSNaRYdGtGy/jXbvnmGP85wWa\nm4GpU+N7Tjexdq2xvmmT8X9/5hlnxuMGXCHs0VobtbWRW+x6f3PmXqKoqfGf8MzPb29xZmcbYrVn\nD88fpKcD//d/xj5m8Uk1srOBQw9ld9qxx9rvVtu50/9/q9vd6foxAFvIQMeGhdWSjxc9e/pH8sye\nDdxzj38HMa9SUwMMGsRusqYmdrVmZgJjxnASYKriCmEHoks0mT8fOO64yF6TlgZcfbUz/TOtFvvg\nwcDXXwOvvmps69+fJ4X37OFJVj3OSZOMSVOr+KQaOTm8HDbMX3DtYNcuw4UC8DXYtYutQqsR0VFE\n1siR9o4tGFZh14XunJpLShTLlgHXXMPrM2YAP/0pr+/aBZx8MieI2dX3INlwjbBbQ8zCYfVqvg2N\nlO7d209adsTSpTxBFW0RsX37WKTN/tYhQ9i3fv75RiTMIYewsC9d2v4YEyawuFvFJ9XQX9ayMs5A\ntbPxhvVHMyODr93u3ey31bS1deyKOfroxLTyy8/3//5o18TmzTzBS+RstnW8eOIJ4M03ef2224C3\n3zae++1veZkKdy2BcI2wr14d+WvME12REE3H+1Gj2AK78MLIzwew26hXL3+306GHtu/otHmz0ajB\nzEUX8f/owQejf99eQf8I5uZyzZj8fE4EsgPrj6YWdn0HZd4vmjmeeNCzJ9ejue02/uxUVvKd7ObN\nhrDt3u3oEOPCmjU8wT1sWHsB1zkD06cnflxuIO7CTkRnENG3RLSaiG4Ptt+//x35saN1SaSnG8Le\n3MxCH8qiMceVh6obEoz164GHHmqfUKSbbmhf7JQpfAuZnc0uGjN//CPXIXnlFfb5prIr5uDB9tue\necaeqo/Wz1R6Ol/z3bv977ZqayNPjosX+odo+nS+26urA047jYVd+5mdLn5nNxdeCHz4If+w6u9R\nIHRBtlQjrsJORGkAHgdwOoDhAC4gosOs+w0bFnkv0sZGtqSiyebTrphly4y46FCuGXORpWgmegcO\n5Nou5lZpAHDkkcCttwJnnsmPZ81iAc/OBp5+mq2RQw/l50pK2BVQWMgRPalssf/jH0ZCzq238nLm\nTP7RixXrj2ZGBgv7nj0s7H//O/8Q19REF24bD8yfhRUr+PPdty+Hzv7ud7zdS8JeVWVc6549/ecy\nTjyRO6eZmT8/cWNzC/G22McAWKOU2qiUOghgFoBzrTv17h15ev2TT/IyGqHVFru5eFaopgp1dVwG\noLycE4siRftZdUMMDRFbWVddxX52/V50SN+IETzB2qeP8Rot9KlssQ8eDIwbx+vTpwMPP8zrdsRy\nV1f7/7/NrpjcXHaJTZ7Mwu4WV4z5x2XcOB5X377+gvbCC4kfV7z44AM2igB2j911l6EfZWVG5zTN\na68ldnxuIN7C3geAeW5+i2+bH8XFkTd33rABeOyx6AYVyMduPn9Vlb9Psr6ev8DPPBN5arjZxfPB\nB4H3OfNMf2tTN2TIz+dm3Ob5B+0O0K3RBOCmm4AbbrBnErW62sgYBQK7Ynr1cpcrJi2NP2fmsVgT\n2KKZw3Ire/ZwMT+AjaC0NL5zf+wx4I47jP303Vw0xliy44rJ006dIrPY6+vZtdG/f3TnS0/3P19p\nKZdn1Rx2GHDJJcbjujoOsevTh7/45kiHt95iF0owzPHn4Yqx/iBmZLCryPw67TKSTEMDIha1WIW9\noYFdgqWlxrZu3XgeZudOY/K0uJg/B7qgmxsg8v9Bsgp7pK5ON1NXx60Bp041umoBwPXX+/vbp0/n\n5iy6YFwqEe8UimoApiR6lPq2+bFvXwWWLuVU4PLycpSXl4c8qLaaTzklukGNHMmp4potW9gVouNg\nASNmHOCiYf37s1WQmcm34TrB6ZJL+IN2/vmBzxVNmFmo2NszzrCnxZrX6Nkz9kblH3/M0STm/y8R\n/5B/+il/PgG22GfNMgq6uYUBA4yaMfo9/PKX3JBk4ECeS9JZmclMXR2HBesY9lDk5nqnEUllZSUq\nKyvD2jfeFvtiAIOIqIyIugI4H0C7Ki3XXVeB3r0rUFFR0aGoA2xZHXVU9B/S4cONuh9btgTex1wX\nZNEirtYHAMcf719gqK6O7wBaWwOXT9UWtvkWsSNC3b1cfTX3vBT8sSbpmNPMw6WxkXuWWhk2zD8H\nobiYBXTQoOjGGi9uvpmX779vbDtwgH+Axo0D/vUvZ8YVK/36cQSMRt9Bh0NurndqxpSXl6OiouK/\nf6GIq7ArpVoBXA/gPQArAMxSSrUrmhtpbfKGBn5NtJhvW4PdSpujZNauNSYtR440LEOzS+aRR9hi\nsrJrF3DFFUYdmHCQjjiRYxb23/2ORbelJbJjNDUFdpdddBEvtZjosFU3TJyaGTuWKxua72T1neXR\nR4fu5bppk3uTeTZv9s9T2LMnNYU9EuLuY1dKvauUGqKUGqyUChhVWlbGzX7vuafj47W1cbhbrO4I\n8y30ySe3f16L9vr1/KHS/vxBg4DvvuP1r74yoiZ+9avA59m5k99fJJSUuOsWPxkwC/t99/Ey0izh\nYMKujQiroLut0UmXLv4uxj17jDvFgQM5GzOYIA4dykl4H33kTiHs1o0TsAYNYos93IqZIuwOUlDA\n4YsffdTxvmvXcipxa2ts59SdbgDg5ZfbW1/aN75wIYfXaQu/b1923yjF5QysCUu//jXw+uuGtRhN\nwa533zV+PITw0Gn15vmJSHvb7t0bWNi1MOhEMh194jZht5KTY4xZ1/gPdjfYpQt/5k4+mY2KSKPU\n4k3XrhzgsHZtZK6Y7Gz2BsSqF8mGK4Qd4E7uX3zRcWSDDlO09p6MlK5djfUePdp/4LXFXlMDnHWW\nEYWSk8O3rGZrcMEC4Mc/5vVt24Cf/MSIsokm/T8nJ7UTkKIhP5/nRRobWZgmTuy4pG9rq+F+eOkl\nfm0gYb/mGr5L1Oi5nWRqIm7uAxAI64+UW8IjtUvUHJ4cibCnpQX+fre0GHX2vYhrhL2khC9ifj6L\naKAiWIDhi7/sstjOZxb29HSj7KeOKtAWu7UiY3Y2j83smx87lsMan3/e+AHQFkIql9hNJDk5LMpr\n1/LdWE4OC0B9fXAX39NP8/U8cAC4+GLOZg0k7IWFnJRk5osvuNuVF2hu9jdUunXjOiwNDcDnnzs3\nLsC4W7r9duCTT3i9ujp8YQcCu2P++Ed35CDEC9cIu7V29euvB96vsZEnhx55JLbzTZ9uxJ8Tcezy\nI48Y6cnNzdyVfuNGfxHPzvY/jjkssqTEKJWqLYxUL9iVSA47jH9009MNYX/zTY53DnQrrq/Ryy/z\n8pNPwi9RMWZM8uUSbNrkH6Ov0YW0NGecYRSc+8EPOBbcKYIFVUQSPBFI2L1srQMuEnbASA0Hgpfx\nbWyMLSJGc9hh/nHrffsCixf773PmmZyOfOyxxjazsM+d658klZdnJEPoD5JY7ImjuJh/WNPTjS+z\nziAO5DPesYNdFPffz4/b2ryd0ZudHdjHvnEjMHq08XjCBI780m6Q885LzPgCEUzY0yJQrkDCrudi\nvOp7d5Ww33wz+zqB4Kn7c+ZEdlHDpVevwHHogH+8sjl23no7mJlpjFt/kMRiTxx5eexS0K6Y9euN\nOZtAwr51K9f/MU9Ujx+fkKE6gg4rtorZli1syc+YwcECp5zCrkWzcRWsHEa8aWzkLFOdjBRNpq9V\n2FtajKqWLpbFAAAWwElEQVSXbg3xjBVXCTsAnHsucPnlXLY20OTXs8/6p+nbRWamf7KSrh749NP+\nt9zmdauwZ2QYFtGePWwV7N8vmaKJIi+PxTo9nddffNGwxrWLrKGBq3oC/CMwfDiv9+/PVmtHk4zJ\nTKdObMBYI662bWM34v/8D2feDhzId7QzZxr7nHJK+2beiaCxkcX83nv58fHHR36Mnj39az99+62x\n7rboH7twnbBnZvLExoYN7N974w3e3twMPPoorz/4oP3nTU/3t1C0r/3ss9vvqyearP528238nj1G\n04Zk88UmK2aLffJkFigddnrssZy9+OijHM2ilL+wX3SRf70gr9KpE4u2uXa9rlxpJpBlHKxsRjzR\nrtf8fHaVPf985IX4evb0/24ffjgvBw+OvKpssuA6YQf4Qlx/PUc4TJ7Mk1/XXMNV/ADgxhvtP6cW\n5bPO4tnyzEy+OzBHxGh69eIJJXPRJfMxAEPYxb+eOHJzDYu9R4/2KfQPPGDceq9YwX8jRvDjQNfZ\ni+igA/PkYaDwQavRYn1NoliyxAg9JuLvZaQZv9ZyE8OGsSsmM1Ms9oTzi18Y6wsX+oumObnILvTx\np041mhJccUVwf/7Eie2fS0/nZefO/CW4917xryeSfv342unrMHSo/xf3/feBefN4Xc/l9O3LGZde\n9q2bOe88tlgXL+Yomc8/DyzsOjpIV4W85Zb4fO864qGHAkfyRIJV2Pfu5QnirKzwhb2pKbkaY7tW\n2IcPZytdhxzGu6ayFnZrudNI0CGbZWUcTTNrlvfDqtzE4MG8NItURgYL97PPcjs13XJw2TIOeU1L\n47aMur53KtC5MyfUlZWxuzOUsJeUAL//PVcxTXTfVB2lFE6pkVBYm33r6qyZmeG7Yi6/3H21gUIR\n77K9UZOWxmUGGho4hLCxEbjgguhL9YaLHRdv6FCjuqC5s70QX/r3ZxHSVQ41up+ujnoqKuLmz7EK\nRrJinfMJJOy33GL8UN51F/u1Y6m5cvAg3w3fcUdgN08gamtZfMPdPxhmi72lhcfSvTvfvc2b51/M\nLxhpafx/sivcOt641mLX6Nul554DzjmHfznjgf5FjzWUsl8/jsdfvZqjCGbMiH1sQnh07swiFCwW\nXX+BtUth1KjEjMttLFliRJzppjNWYT/kEO5KpcnNZYs9HBEMxNKlXOE0klIFO3fakx1qFvZ9+/jz\nQRRZo54uXXj56af82mDlvt2C64XdbF3EM2wwWEJUpGzcyHHvgwcHru0tOMett3JFTq9GQoQLESdz\nVVVxaY3c3I5dnd26sbhZi96Fiy7IFsn/XkeVxYrZFbNvnzEHs2QJ3w2E82N14AC7b5Yv58dOhH5G\nguuFHeCiWoB/fRe7mToVmD07fscXnKdnT27QYg71S2Wysti9EK4BkpcXvTtGC3tHk5Xr1vnXWbJD\n2M0We1OTIex5ef6F4ELR3MwuPH2ceCRJ2onLh8e89hpPfh1zTPzOUVrKrh7B+zz3HPD2206Pwnm0\nr1i7GTpCu2PMDB3KfX+tXHyxf+s6LYgdWewDBxruS7uEPTOT/er79xuuGIDvXAoKwrtbP3CA3UL6\nB8rciMeNJIWwAxx6KM0nBDv46U85XyHV0ZEv4c41WFPz163jLE5rjSWAw0nNLRy1pR5OeGFVFYvu\n/Pn2CDuRYbWbXTEAC7s1cm3u3Pa9ipubWdg3buTHIuyCILiSTp04vPeJJ8LbPy+PLfa2Np58feop\nnrAO1kPBXLG1qYnvDMIRdl0yZMkS+/JA8vODC7vZYj/2WC7+t3Kl/+sPHOB9xWIXBMH1bNoUfvie\nttgXLOCSG9OnA5MmBRd284SsjnAJZ/JU1/VZs8Y+YdcWu7X9YUGBkZAIGGUlZs3iO5lvvuHH+/fz\n+PXYRNgFQfAEWhxraox6LUcdxT72pUvbR5doi72ykms+FRZGnsJvp7A/9hgXQDNb7IcdFjho4qWX\n+D0deSRw2mnsbjKHXkYbHZQoRNgFQQiLoiIWdLNPesoUFrlRo9oXUdMW+4oVxusjDTW1a15t0iRu\n3nPttf5h0+PHs+vHOim8YYOx/v77vDQLu1jsgiB4guJif2EfNYqTfMaO9d9PP69dPGvW8DKSJtm/\n+x0v7SrOdsIJxro5k3XsWI7EMbtjNLrCq0YsdkEQPIe22HVyjo4c0RawTibU2aVaCOfO5WWnTuEL\n++mn8zKW2k1mzMexligoLOSQanNW7Jtv8uStOTtVlzbu0sW+hMZ4IcIuCEJYlJVxjZ1HH+XSDTp+\nXfvSdQ/Z+noWS23V6uXQoR27Yjp14n20+FrrxEeLrrgKBBb2u+/m2PuRI7ni5bnn8lj69TOaluu7\nhxEj/Jt/uxHXFgETBMFdmBten3CCYQVrl4v2Ozc0sAhq67ypia38//yHJ1KD0dpqVHQcPpzb8dnZ\npEb7663HHDiQlwcOcLy6+cfkvfdY4M0RPscdZ8SzuxWx2AVBCIuuXYETT+R1cxmCyy7jpRb2+noW\ndm2p69jxQGVy160z6q80N/M5iDhl/+ST7R2/LgNgdQfppvYHDvBdh7nufNeu/qL+3HNcwliHPboV\nsdgFQQibn/wE+Phjf2GfMIHFUbtitMW+eDGHQO7fz8KelcWRM6+8wi0n6+sNa1kpFlZzs/h4UFPT\nvpKlbpW3bx+PwRwOaeXyy/nHae1avrtwa80Ylw5LEAQ3ot0u1miV9PTAFvv+/Wz1pqUZr7nwQq5+\narZ6W1oMiz2eFBe37wSVmQm88AIna9XWhhZ2gP8HubncJ8KtxCTsRDSZiJYTUSsRjbI8dycRrSGi\nVUR0WmzDFATBDWir3CqO3bv7C3tBAYt1Q4OR6Wnu/1tTw373CRM48mTtWr4TcKrx+wUXGOtWiz4Q\nJSVGTXs3EqvFvgzAjwF8bN5IREMBTAEwFMAEAE8SOXXJBEGwi2Cuh/R0w6fe0MCRJ5mZHImiLWAi\n/w5l27fz49JSFvYpU5yrc965sxGPH45S6dBPtxKTsCulqpRSawBY/xXnApillGpRSm0AsAbAmFjO\nJQiC81x2GbBqVfvt/fsbiUj19SzsDQ28v7k2i1kMly9n90xOTuBjJppPPgnfvVJcHDipyS3Ey8fe\nB4B53rjat00QhCSmS5fAjb9HjeJG4d9/zwW0dNLS4sXti4zpOPKHH+YY8ZwcYOvW+I47HDp3Bnr3\nDm9fnYXrVjoUdiJ6n4i+Mf0t8y3PTsQABUFwP7m5bKHPmcOPs7ONzmfWei91ddyxDABGj+bXbt3K\nfVZ1E3i343Zh7zDcUSl1ahTHrQZgTgYu9W0LSEVFxX/Xy8vLUV5eHsUpBUFwCh0Vo7NQu3ThNH2i\nwD1FTzsNmDaNqy7m5HB53IEDgQEDEjvuaCkqal/0LN5UVlaiMlSGlwk749jNfva3ALxERA+DXTCD\nAAT9N5iFXRCE5CMjg4VdT36awyED+aKPP95wv5SVAfffb39CUjxxwsduNXqnTZsWdN9Ywx0nEtFm\nAMcBeJuI5gKAUmolgNcArAQwB8C1SoXTC1wQhGRER8Vs3Qrcd59heZ92GnD00YFfU1LCy5//nJdf\nfx3/cdpFLI29EwE5rbdEJJovCElOczOHN44fzzXPI20Mr0MMk0UKVq4EJk9u30IvkRARlFIBgzMl\n81QQhJjp0oUTkhYsAMZEEdhsrnWeDJgzbd2I1IoRBCFmtMXdu3d0zTEWLnS3UFoxZ9q6ERF2QRBs\nY/z46F6ni4ElC2632MUVIwiCbUyc6PQIEoPbhV0sdkEQbGH3bvs6Hrmdrl15TqG11b9eu1sQi10Q\nBFtIFVEHeE7BarW3tABLlzo3JjMi7IIgCFFgFfYnnuCaOW5AhF0QBCEKzKWKAS545hZE2AVBEKIg\nPx/Ytct47KbJVBF2QRCEKCgq8q8X09zs3FisiLALgiBEQWGhv7Dv3cvLgwedGY8ZEXZBEIQosFrs\nu3fzUgu8k4iwC4IgREFRETB7NtDWxo+1sDc2OjcmjQi7IAhCFBQVAZ9+CjzzDLBiBU+k9u5tCLyT\niLALgiBEge4Wde213LS7qQkYPhzYssXRYQEQYRcEQYiKfv2M9dJSzrwtKwM2b3ZuTBoRdkEQhCg4\n6STu1woAb7/NJQVKS0XYBUEQkpr0dF62tAB33sm16GtrnR0TIMIuCIIQNV99Bfz1r7x+220s7DU1\nzo4JEGEXBEGImpISYOhQXk9LA4qLxWIXBEFIesaNM5pwh2uxl5TEt2iYCLsgCIJNaItdC30wamqA\njz6K3zhE2AVBEGwiPR3o1g3Ys6fj6Jj6+vbbevcGKitjH4cIuyAIgo0UFwMPPOAf5x6IHTvab9u2\nDfjgg9jHIMIuCIJgI7m5wKuv8vq4ccD69f7P69oyn34a+PV2FBGTZtaCIAg2sns3sHEjry9YAAwY\nYPjc9+4FVq7k9erqwK+3Q9jFYhcEQbARXco3K8vYtmED8POfA6eeCowZw9uamoADB9q/vqPqkG1t\nwNy5ofcRi10QBMFG9u/nZc+ehkj378/L3Fxjv4ICYOdOnjA1E8yS13zxBXDmmaH3icliJ6KHiGgV\nEX1NRG8QUbbpuTuJaI3v+dNiOY8gCEKyoFvk9ezZ/rk9e3j5+uss7NXVwN/+5r+P1Sdv5aOPgNNP\nD71PrK6Y9wAMV0qNBLAGwJ0AQETDAEwBMBTABABPEhHFeC5BEATX8+qrLNw9ewLHHRd4n+Jibq03\ndy67aPbvB1pb+bnt20PHwX/9NfCzn4UeQ0zCrpSar5TyzfFiEYBS3/o5AGYppVqUUhvAoj8mlnMJ\ngiAkA1OmAJMmsbAXFgJTp/L2iRN52asXcMwxbLF//TVvW7aM/e3p6UCnTkBDQ/Dj19RwFclQ2Olj\nvxzAK771PgAWmp6r9m0TBEFICfLy2AqvqOAJz1NOYUt96lSge3cW/Vd8ivnRRxw9k57Or6utBbKz\nAx+3vt4oFxyMDoWdiN4HUGzeBEAB+I1S6l++fX4D4KBS6pUAhxAEQUg58vMNl8o99/Dyhz80ni8o\n4NDIm2/m59PSuCtTcTFb5YMHBz5uXV1w0dd0KOxKqVNDPU9ElwE4E8DJps3VAPqaHpf6tgWkoqLi\nv+vl5eUoLy/vaFiCIAiu5vrrQz+vhXvqVI5tv+02fjxuXOAKkZWVlaisrERNDfD006GPTaqjajWh\nXkx0BoA/AfihUmqnafswAC8BOBbsgnkfwGAV4GREFGizIAiCp6mvB/78Z3bVTJ4MvPEGb7/6amDE\nCOC669q/Zt8+ICODJ1u7dycopQIGpcQaFfMYgCwA7xPRV0T0JAAopVYCeA3ASgBzAFwr6i0IgmCQ\nnc2iDgC7dhnbc3OBJ54I/Jqbb+Zlt26hjx2TxW4HYrELgpDqDB/O7pjPP2drfPx4zkzVrfcAds+M\nHcuhjtOmAUTBLXbJPBUEQXCYGTN4wvT44/nxkUcCy5cDo0fz44MHOUwSAM46q+PjibALgiA4zLhx\n/o979/Yv66sFH+BwyI6QImCCIAguIzubwxo1S5YY6yLsgiAISUh2ttFhaetW/+fMhcSCIcIuCILg\nMrKzgbVrOWN15Ej/5zqH4UAXH7sgCILLyMkB7r4bGDTI8LV37Rq4fnsgxGIXBEFwGbpkgDkD1exz\n7wgRdkEQBJdRWMjLNJNCd+8e/utF2AVBEFxGSQkvf/tbXm7bFtnrRdgFQRBchrUsr05OChcRdkEQ\nBJcxaFBsrxdhFwRBcBnZ2cBLL0X/ehF2QRAEF2KNX48Eqe4oCILgUkpKuDhYIImU6o6CIAhJyKxZ\nwLp1kb9OLHZBEIQkJJTFLj52QRAEjyHCLgiC4DFE2AVBEDyGCLsgCILHEGEXBEHwGCLsgiAIHkOE\nXRAEwWOIsAuCIHgMEXZBEASPIcIuCILgMUTYBUEQPIYIuyAIgseISdiJ6B4i+g8RLSWid4mol+m5\nO4loDRGtIqLTYh+qIAiCEA6xWuwPKaWOVEodBeAdAFMBgIiGAZgCYCiACQCeJKKAVciE1KGystLp\nIQgJQK6z88Qk7EqpRtPDTABtvvVzAMxSSrUopTYAWANgTCznEpIf+cKnBnKdnSdmHzsR3UdEmwBc\nCOBu3+Y+ADabdqv2bYuJcD4wkXyowt3Xqf28dm6nzpsM/xsvvZdIsPM77aXrF+m+VjoUdiJ6n4i+\nMf0t8y3PBgCl1G+VUv0AvATghqhHEgYi7Ml9bqfOmwz/Gy+9l0gQYbdnXyu2dVAior4A3lFKHUFE\ndwBQSqkHfc+9C2CqUuqLAK+T9kmCIAhREJeep0Q0SCn1ne/hRADf+tbfAvASET0MdsEMAvBlJAMT\nBEEQoiPWZtYPENGh4EnTjQCuBgCl1Eoieg3ASgAHAVwrjU0FQRASg+PNrAVBEAR7SVjmKRE1JOpc\nbqOj905EHxHRqESNJ96k6rWW65waJMN1TmRJgVS+NUi1955q71eTau871d6vxvXvO6G1Yogog4jm\nE9ESXymCc3zby4hoJRHNIKLlvvIE3RI5tjhDRHQiEf3LtOExIrrEyUHFkxS91nKd5Tq7gkQXAdsP\nYKJS6hgAJwP4k+m5QQAeU0qNAFAHYFKCxxZvFJLgl95GUvVay3U2kOvsELFGxUQKgSNpTgBH0vQm\noiLfc+uVUst86/8GcEiCxybYi1zr1ECuswtJpLATgIsB5AM4SinVRkTrAXT3PX/AtG+rabtXaAHQ\nyfTYa+/PTCpfa7nOcp0dJ9GumGwA230fgJMAlJme83KikgLH+Q8joi5ElAtgvMNjijepeK3lOst1\ndgUJsdiJqBPYF/cSgLeJ6D8AlgBYZdrNtf6qWPC99wNKqWpf0tZyAOsBfGXazTPvPVWvtVxnuc6m\n3Rx/3wlJUCKiIwE8o5Q6Lu4ncxmp9t5T7f1qUu19p9r71STL+467K4aIrgL/qv8m3udyG6n23lPt\n/WpS7X2n2vvVJNP7lpICgiAIHkOaWQuCIHgM24WdiEqJ6EMiWuFrynGjb3seEb1HRFVENI+Ickyv\nCdj4mohG+Zp6rCaiR+weqxAbNl/r+4hoExHVO/FehODYdZ2JKJ2I3vZtW0ZE9zv1njyPUsrWPwC9\nAIz0rWcBqAJwGIAHAfzat/12AA/41ocBWAqO0DkEwHcwXERfABjtW58D4HS7xyt/rrnWYwAUA6h3\n+n3JX3yuM4B0ACf69ukM4BP5Tsfnz3aLXSlVo5T62rfeCA5/KgVwLoCZvt1mghtzAEEaXxNRLwA9\nlFKLffu9YHqN4ALsuta+13+plKpN4PCFMLHrOiul9imlPvYdpwUcIliasDeSQsTVx05EhwAYCWAR\ngGL9xVVK1QDQacfBGl/3AbDFtH0LbGiILcSHGK+1kCTYdZ19ST1nA/ggviNOTeIm7ESUBeB1ADf5\nfuWt4TcSjuMR5FqnBnZdZ1+Sz8sAHvFZ9ILNxEXYiagz+APwolJqtm9zLREV+57vBWC7b3s1gL6m\nl5f6tgXbLrgIm6614HJsvs4zAFQppR6L76hTl3hZ7P8LYKVS6i+mbW8BuMy3fimA2abt5xNRVyLq\nD1/ja9+tXR0RjSEiAnCJ6TWCe4j5WluO59X6IsmOLdeZiO4DkK2U+mVCRp2q2D0bC2AcuJLb1+CZ\n8a8AnAGgJ4D54Bn19wDkml5zJ3jmfBWA00zbjwawDDz58henZ5rlL67X+kGwX7YFwCYAdzv9/uTP\n3usM9rO3AVhhOs7lTr8/L/5J5qkgCILHkMxTQRAEjyHCLgiC4DFE2AVBEDyGCLsgCILHEGEXBEHw\nGCLsgiAIHkOEXRAEwWOIsAuCIHiM/wdmZTsWqfC5wQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1176e5d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))\n",
    "ts = ts.cumsum()\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1025bcc90>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11789b2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEMCAYAAADHxQ0LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzRxIX9UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1025bc810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index,\n",
    "   .....:                   columns=['A', 'B', 'C', 'D'])\n",
    "\n",
    "df = df.cumsum()\n",
    "plt.figure(); df.plot(); plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('foo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>-1.225072</td>\n",
       "      <td>0.801684</td>\n",
       "      <td>-0.379105</td>\n",
       "      <td>-1.239740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>-1.637213</td>\n",
       "      <td>0.674406</td>\n",
       "      <td>0.041368</td>\n",
       "      <td>-1.748890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>-2.025446</td>\n",
       "      <td>-0.213028</td>\n",
       "      <td>-0.387017</td>\n",
       "      <td>-0.046392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>-1.376932</td>\n",
       "      <td>0.938919</td>\n",
       "      <td>-0.141218</td>\n",
       "      <td>0.475459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>-0.263447</td>\n",
       "      <td>1.447945</td>\n",
       "      <td>0.146585</td>\n",
       "      <td>0.191720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>0.103593</td>\n",
       "      <td>2.440335</td>\n",
       "      <td>-1.329681</td>\n",
       "      <td>2.303396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>0.034375</td>\n",
       "      <td>4.027924</td>\n",
       "      <td>-0.807556</td>\n",
       "      <td>2.416217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000-01-08</td>\n",
       "      <td>-0.234895</td>\n",
       "      <td>2.608389</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>3.007350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000-01-09</td>\n",
       "      <td>-1.232289</td>\n",
       "      <td>3.889698</td>\n",
       "      <td>1.914607</td>\n",
       "      <td>5.014900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>-2.862024</td>\n",
       "      <td>4.299781</td>\n",
       "      <td>1.699958</td>\n",
       "      <td>5.410799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2000-01-11</td>\n",
       "      <td>-2.562192</td>\n",
       "      <td>3.565857</td>\n",
       "      <td>1.861770</td>\n",
       "      <td>5.018266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2000-01-12</td>\n",
       "      <td>-2.719852</td>\n",
       "      <td>1.728034</td>\n",
       "      <td>3.230262</td>\n",
       "      <td>3.968318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2000-01-13</td>\n",
       "      <td>-2.669539</td>\n",
       "      <td>4.009945</td>\n",
       "      <td>2.345474</td>\n",
       "      <td>5.123213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2000-01-14</td>\n",
       "      <td>-3.334017</td>\n",
       "      <td>4.136389</td>\n",
       "      <td>1.291245</td>\n",
       "      <td>6.834034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2000-01-15</td>\n",
       "      <td>-4.187475</td>\n",
       "      <td>4.304222</td>\n",
       "      <td>0.619532</td>\n",
       "      <td>6.352414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2000-01-16</td>\n",
       "      <td>-4.570406</td>\n",
       "      <td>3.448199</td>\n",
       "      <td>1.485252</td>\n",
       "      <td>6.597377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2000-01-17</td>\n",
       "      <td>-4.422479</td>\n",
       "      <td>4.541083</td>\n",
       "      <td>-0.042886</td>\n",
       "      <td>5.793299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2000-01-18</td>\n",
       "      <td>-6.306480</td>\n",
       "      <td>4.054810</td>\n",
       "      <td>0.640942</td>\n",
       "      <td>7.139785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2000-01-19</td>\n",
       "      <td>-6.677662</td>\n",
       "      <td>3.803965</td>\n",
       "      <td>-0.431401</td>\n",
       "      <td>7.089509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2000-01-20</td>\n",
       "      <td>-5.351948</td>\n",
       "      <td>3.878014</td>\n",
       "      <td>-1.726403</td>\n",
       "      <td>6.810476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2000-01-21</td>\n",
       "      <td>-5.423939</td>\n",
       "      <td>5.681259</td>\n",
       "      <td>-1.147128</td>\n",
       "      <td>6.777682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2000-01-22</td>\n",
       "      <td>-6.024956</td>\n",
       "      <td>5.282127</td>\n",
       "      <td>-0.184408</td>\n",
       "      <td>7.085197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2000-01-23</td>\n",
       "      <td>-6.848976</td>\n",
       "      <td>5.652299</td>\n",
       "      <td>-0.810096</td>\n",
       "      <td>7.338369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2000-01-24</td>\n",
       "      <td>-7.040223</td>\n",
       "      <td>5.870063</td>\n",
       "      <td>-0.011249</td>\n",
       "      <td>8.173743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2000-01-25</td>\n",
       "      <td>-6.247456</td>\n",
       "      <td>5.549304</td>\n",
       "      <td>1.900613</td>\n",
       "      <td>9.681444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2000-01-26</td>\n",
       "      <td>-5.782543</td>\n",
       "      <td>5.070565</td>\n",
       "      <td>0.825723</td>\n",
       "      <td>9.962603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2000-01-27</td>\n",
       "      <td>-5.411138</td>\n",
       "      <td>5.974291</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>9.910227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2000-01-28</td>\n",
       "      <td>-5.024961</td>\n",
       "      <td>4.659042</td>\n",
       "      <td>1.636149</td>\n",
       "      <td>10.831800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2000-01-29</td>\n",
       "      <td>-4.274795</td>\n",
       "      <td>5.062583</td>\n",
       "      <td>2.618473</td>\n",
       "      <td>10.239645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2000-01-30</td>\n",
       "      <td>-3.603870</td>\n",
       "      <td>5.140397</td>\n",
       "      <td>1.277127</td>\n",
       "      <td>10.700395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>2002-08-28</td>\n",
       "      <td>-34.150385</td>\n",
       "      <td>-14.143460</td>\n",
       "      <td>-77.495464</td>\n",
       "      <td>42.058465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>2002-08-29</td>\n",
       "      <td>-35.772792</td>\n",
       "      <td>-14.631071</td>\n",
       "      <td>-77.788227</td>\n",
       "      <td>41.126313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>2002-08-30</td>\n",
       "      <td>-36.629357</td>\n",
       "      <td>-15.356738</td>\n",
       "      <td>-77.515531</td>\n",
       "      <td>42.397074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>2002-08-31</td>\n",
       "      <td>-37.335796</td>\n",
       "      <td>-15.028817</td>\n",
       "      <td>-77.640279</td>\n",
       "      <td>42.802496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>2002-09-01</td>\n",
       "      <td>-38.593959</td>\n",
       "      <td>-15.031997</td>\n",
       "      <td>-76.808900</td>\n",
       "      <td>43.104644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>2002-09-02</td>\n",
       "      <td>-38.273346</td>\n",
       "      <td>-14.574022</td>\n",
       "      <td>-77.654011</td>\n",
       "      <td>41.356871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>2002-09-03</td>\n",
       "      <td>-38.382406</td>\n",
       "      <td>-14.361195</td>\n",
       "      <td>-78.640685</td>\n",
       "      <td>41.204238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>2002-09-04</td>\n",
       "      <td>-38.401388</td>\n",
       "      <td>-13.844929</td>\n",
       "      <td>-77.205115</td>\n",
       "      <td>40.843013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>2002-09-05</td>\n",
       "      <td>-38.113559</td>\n",
       "      <td>-14.084699</td>\n",
       "      <td>-76.362048</td>\n",
       "      <td>41.973272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>2002-09-06</td>\n",
       "      <td>-38.758620</td>\n",
       "      <td>-14.541632</td>\n",
       "      <td>-77.561806</td>\n",
       "      <td>41.629165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>2002-09-07</td>\n",
       "      <td>-38.010311</td>\n",
       "      <td>-14.673665</td>\n",
       "      <td>-76.696958</td>\n",
       "      <td>41.095907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>2002-09-08</td>\n",
       "      <td>-37.216409</td>\n",
       "      <td>-13.984856</td>\n",
       "      <td>-77.244416</td>\n",
       "      <td>40.363504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>2002-09-09</td>\n",
       "      <td>-37.729941</td>\n",
       "      <td>-14.216131</td>\n",
       "      <td>-78.248521</td>\n",
       "      <td>42.014916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>2002-09-10</td>\n",
       "      <td>-37.661044</td>\n",
       "      <td>-14.303651</td>\n",
       "      <td>-77.574108</td>\n",
       "      <td>40.230393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>2002-09-11</td>\n",
       "      <td>-35.672480</td>\n",
       "      <td>-14.862236</td>\n",
       "      <td>-77.236224</td>\n",
       "      <td>39.481927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>2002-09-12</td>\n",
       "      <td>-35.021623</td>\n",
       "      <td>-13.298113</td>\n",
       "      <td>-77.886686</td>\n",
       "      <td>40.080035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>2002-09-13</td>\n",
       "      <td>-33.644029</td>\n",
       "      <td>-13.081617</td>\n",
       "      <td>-77.194291</td>\n",
       "      <td>40.807073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>2002-09-14</td>\n",
       "      <td>-32.314466</td>\n",
       "      <td>-12.171955</td>\n",
       "      <td>-77.633082</td>\n",
       "      <td>40.270444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>2002-09-15</td>\n",
       "      <td>-32.414417</td>\n",
       "      <td>-11.098192</td>\n",
       "      <td>-76.014992</td>\n",
       "      <td>41.253721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>2002-09-16</td>\n",
       "      <td>-32.397789</td>\n",
       "      <td>-10.006114</td>\n",
       "      <td>-76.986016</td>\n",
       "      <td>40.716936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>2002-09-17</td>\n",
       "      <td>-34.503392</td>\n",
       "      <td>-8.802649</td>\n",
       "      <td>-78.136208</td>\n",
       "      <td>40.655025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>2002-09-18</td>\n",
       "      <td>-34.508642</td>\n",
       "      <td>-9.096068</td>\n",
       "      <td>-79.447899</td>\n",
       "      <td>40.363022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>2002-09-19</td>\n",
       "      <td>-32.806020</td>\n",
       "      <td>-10.482351</td>\n",
       "      <td>-78.196450</td>\n",
       "      <td>41.164869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>2002-09-20</td>\n",
       "      <td>-32.879839</td>\n",
       "      <td>-9.779931</td>\n",
       "      <td>-77.746712</td>\n",
       "      <td>41.898806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>2002-09-21</td>\n",
       "      <td>-30.896324</td>\n",
       "      <td>-8.729997</td>\n",
       "      <td>-77.210806</td>\n",
       "      <td>42.025220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2002-09-22</td>\n",
       "      <td>-29.928935</td>\n",
       "      <td>-9.748260</td>\n",
       "      <td>-76.134071</td>\n",
       "      <td>40.533357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2002-09-23</td>\n",
       "      <td>-30.557811</td>\n",
       "      <td>-10.019924</td>\n",
       "      <td>-76.301156</td>\n",
       "      <td>39.887543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2002-09-24</td>\n",
       "      <td>-30.306213</td>\n",
       "      <td>-11.042034</td>\n",
       "      <td>-75.510902</td>\n",
       "      <td>40.625243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2002-09-25</td>\n",
       "      <td>-29.976402</td>\n",
       "      <td>-11.342606</td>\n",
       "      <td>-75.460807</td>\n",
       "      <td>39.197878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2002-09-26</td>\n",
       "      <td>-28.964423</td>\n",
       "      <td>-10.467306</td>\n",
       "      <td>-76.033409</td>\n",
       "      <td>39.311493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0          A          B          C          D\n",
       "0    2000-01-01  -1.225072   0.801684  -0.379105  -1.239740\n",
       "1    2000-01-02  -1.637213   0.674406   0.041368  -1.748890\n",
       "2    2000-01-03  -2.025446  -0.213028  -0.387017  -0.046392\n",
       "3    2000-01-04  -1.376932   0.938919  -0.141218   0.475459\n",
       "4    2000-01-05  -0.263447   1.447945   0.146585   0.191720\n",
       "5    2000-01-06   0.103593   2.440335  -1.329681   2.303396\n",
       "6    2000-01-07   0.034375   4.027924  -0.807556   2.416217\n",
       "7    2000-01-08  -0.234895   2.608389   0.007215   3.007350\n",
       "8    2000-01-09  -1.232289   3.889698   1.914607   5.014900\n",
       "9    2000-01-10  -2.862024   4.299781   1.699958   5.410799\n",
       "10   2000-01-11  -2.562192   3.565857   1.861770   5.018266\n",
       "11   2000-01-12  -2.719852   1.728034   3.230262   3.968318\n",
       "12   2000-01-13  -2.669539   4.009945   2.345474   5.123213\n",
       "13   2000-01-14  -3.334017   4.136389   1.291245   6.834034\n",
       "14   2000-01-15  -4.187475   4.304222   0.619532   6.352414\n",
       "15   2000-01-16  -4.570406   3.448199   1.485252   6.597377\n",
       "16   2000-01-17  -4.422479   4.541083  -0.042886   5.793299\n",
       "17   2000-01-18  -6.306480   4.054810   0.640942   7.139785\n",
       "18   2000-01-19  -6.677662   3.803965  -0.431401   7.089509\n",
       "19   2000-01-20  -5.351948   3.878014  -1.726403   6.810476\n",
       "20   2000-01-21  -5.423939   5.681259  -1.147128   6.777682\n",
       "21   2000-01-22  -6.024956   5.282127  -0.184408   7.085197\n",
       "22   2000-01-23  -6.848976   5.652299  -0.810096   7.338369\n",
       "23   2000-01-24  -7.040223   5.870063  -0.011249   8.173743\n",
       "24   2000-01-25  -6.247456   5.549304   1.900613   9.681444\n",
       "25   2000-01-26  -5.782543   5.070565   0.825723   9.962603\n",
       "26   2000-01-27  -5.411138   5.974291   1.647352   9.910227\n",
       "27   2000-01-28  -5.024961   4.659042   1.636149  10.831800\n",
       "28   2000-01-29  -4.274795   5.062583   2.618473  10.239645\n",
       "29   2000-01-30  -3.603870   5.140397   1.277127  10.700395\n",
       "..          ...        ...        ...        ...        ...\n",
       "970  2002-08-28 -34.150385 -14.143460 -77.495464  42.058465\n",
       "971  2002-08-29 -35.772792 -14.631071 -77.788227  41.126313\n",
       "972  2002-08-30 -36.629357 -15.356738 -77.515531  42.397074\n",
       "973  2002-08-31 -37.335796 -15.028817 -77.640279  42.802496\n",
       "974  2002-09-01 -38.593959 -15.031997 -76.808900  43.104644\n",
       "975  2002-09-02 -38.273346 -14.574022 -77.654011  41.356871\n",
       "976  2002-09-03 -38.382406 -14.361195 -78.640685  41.204238\n",
       "977  2002-09-04 -38.401388 -13.844929 -77.205115  40.843013\n",
       "978  2002-09-05 -38.113559 -14.084699 -76.362048  41.973272\n",
       "979  2002-09-06 -38.758620 -14.541632 -77.561806  41.629165\n",
       "980  2002-09-07 -38.010311 -14.673665 -76.696958  41.095907\n",
       "981  2002-09-08 -37.216409 -13.984856 -77.244416  40.363504\n",
       "982  2002-09-09 -37.729941 -14.216131 -78.248521  42.014916\n",
       "983  2002-09-10 -37.661044 -14.303651 -77.574108  40.230393\n",
       "984  2002-09-11 -35.672480 -14.862236 -77.236224  39.481927\n",
       "985  2002-09-12 -35.021623 -13.298113 -77.886686  40.080035\n",
       "986  2002-09-13 -33.644029 -13.081617 -77.194291  40.807073\n",
       "987  2002-09-14 -32.314466 -12.171955 -77.633082  40.270444\n",
       "988  2002-09-15 -32.414417 -11.098192 -76.014992  41.253721\n",
       "989  2002-09-16 -32.397789 -10.006114 -76.986016  40.716936\n",
       "990  2002-09-17 -34.503392  -8.802649 -78.136208  40.655025\n",
       "991  2002-09-18 -34.508642  -9.096068 -79.447899  40.363022\n",
       "992  2002-09-19 -32.806020 -10.482351 -78.196450  41.164869\n",
       "993  2002-09-20 -32.879839  -9.779931 -77.746712  41.898806\n",
       "994  2002-09-21 -30.896324  -8.729997 -77.210806  42.025220\n",
       "995  2002-09-22 -29.928935  -9.748260 -76.134071  40.533357\n",
       "996  2002-09-23 -30.557811 -10.019924 -76.301156  39.887543\n",
       "997  2002-09-24 -30.306213 -11.042034 -75.510902  40.625243\n",
       "998  2002-09-25 -29.976402 -11.342606 -75.460807  39.197878\n",
       "999  2002-09-26 -28.964423 -10.467306 -76.033409  39.311493\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('foo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_hdf('foo.h5','df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>-1.225072</td>\n",
       "      <td>0.801684</td>\n",
       "      <td>-0.379105</td>\n",
       "      <td>-1.239740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-02</th>\n",
       "      <td>-1.637213</td>\n",
       "      <td>0.674406</td>\n",
       "      <td>0.041368</td>\n",
       "      <td>-1.748890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>-2.025446</td>\n",
       "      <td>-0.213028</td>\n",
       "      <td>-0.387017</td>\n",
       "      <td>-0.046392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>-1.376932</td>\n",
       "      <td>0.938919</td>\n",
       "      <td>-0.141218</td>\n",
       "      <td>0.475459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>-0.263447</td>\n",
       "      <td>1.447945</td>\n",
       "      <td>0.146585</td>\n",
       "      <td>0.191720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>0.103593</td>\n",
       "      <td>2.440335</td>\n",
       "      <td>-1.329681</td>\n",
       "      <td>2.303396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>0.034375</td>\n",
       "      <td>4.027924</td>\n",
       "      <td>-0.807556</td>\n",
       "      <td>2.416217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-08</th>\n",
       "      <td>-0.234895</td>\n",
       "      <td>2.608389</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>3.007350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-09</th>\n",
       "      <td>-1.232289</td>\n",
       "      <td>3.889698</td>\n",
       "      <td>1.914607</td>\n",
       "      <td>5.014900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>-2.862024</td>\n",
       "      <td>4.299781</td>\n",
       "      <td>1.699958</td>\n",
       "      <td>5.410799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-11</th>\n",
       "      <td>-2.562192</td>\n",
       "      <td>3.565857</td>\n",
       "      <td>1.861770</td>\n",
       "      <td>5.018266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-12</th>\n",
       "      <td>-2.719852</td>\n",
       "      <td>1.728034</td>\n",
       "      <td>3.230262</td>\n",
       "      <td>3.968318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-13</th>\n",
       "      <td>-2.669539</td>\n",
       "      <td>4.009945</td>\n",
       "      <td>2.345474</td>\n",
       "      <td>5.123213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-14</th>\n",
       "      <td>-3.334017</td>\n",
       "      <td>4.136389</td>\n",
       "      <td>1.291245</td>\n",
       "      <td>6.834034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-15</th>\n",
       "      <td>-4.187475</td>\n",
       "      <td>4.304222</td>\n",
       "      <td>0.619532</td>\n",
       "      <td>6.352414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-16</th>\n",
       "      <td>-4.570406</td>\n",
       "      <td>3.448199</td>\n",
       "      <td>1.485252</td>\n",
       "      <td>6.597377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-17</th>\n",
       "      <td>-4.422479</td>\n",
       "      <td>4.541083</td>\n",
       "      <td>-0.042886</td>\n",
       "      <td>5.793299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-18</th>\n",
       "      <td>-6.306480</td>\n",
       "      <td>4.054810</td>\n",
       "      <td>0.640942</td>\n",
       "      <td>7.139785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-19</th>\n",
       "      <td>-6.677662</td>\n",
       "      <td>3.803965</td>\n",
       "      <td>-0.431401</td>\n",
       "      <td>7.089509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-20</th>\n",
       "      <td>-5.351948</td>\n",
       "      <td>3.878014</td>\n",
       "      <td>-1.726403</td>\n",
       "      <td>6.810476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-21</th>\n",
       "      <td>-5.423939</td>\n",
       "      <td>5.681259</td>\n",
       "      <td>-1.147128</td>\n",
       "      <td>6.777682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-22</th>\n",
       "      <td>-6.024956</td>\n",
       "      <td>5.282127</td>\n",
       "      <td>-0.184408</td>\n",
       "      <td>7.085197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-23</th>\n",
       "      <td>-6.848976</td>\n",
       "      <td>5.652299</td>\n",
       "      <td>-0.810096</td>\n",
       "      <td>7.338369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-24</th>\n",
       "      <td>-7.040223</td>\n",
       "      <td>5.870063</td>\n",
       "      <td>-0.011249</td>\n",
       "      <td>8.173743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-25</th>\n",
       "      <td>-6.247456</td>\n",
       "      <td>5.549304</td>\n",
       "      <td>1.900613</td>\n",
       "      <td>9.681444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-26</th>\n",
       "      <td>-5.782543</td>\n",
       "      <td>5.070565</td>\n",
       "      <td>0.825723</td>\n",
       "      <td>9.962603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-27</th>\n",
       "      <td>-5.411138</td>\n",
       "      <td>5.974291</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>9.910227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-28</th>\n",
       "      <td>-5.024961</td>\n",
       "      <td>4.659042</td>\n",
       "      <td>1.636149</td>\n",
       "      <td>10.831800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-29</th>\n",
       "      <td>-4.274795</td>\n",
       "      <td>5.062583</td>\n",
       "      <td>2.618473</td>\n",
       "      <td>10.239645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30</th>\n",
       "      <td>-3.603870</td>\n",
       "      <td>5.140397</td>\n",
       "      <td>1.277127</td>\n",
       "      <td>10.700395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-08-28</th>\n",
       "      <td>-34.150385</td>\n",
       "      <td>-14.143460</td>\n",
       "      <td>-77.495464</td>\n",
       "      <td>42.058465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-08-29</th>\n",
       "      <td>-35.772792</td>\n",
       "      <td>-14.631071</td>\n",
       "      <td>-77.788227</td>\n",
       "      <td>41.126313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-08-30</th>\n",
       "      <td>-36.629357</td>\n",
       "      <td>-15.356738</td>\n",
       "      <td>-77.515531</td>\n",
       "      <td>42.397074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-08-31</th>\n",
       "      <td>-37.335796</td>\n",
       "      <td>-15.028817</td>\n",
       "      <td>-77.640279</td>\n",
       "      <td>42.802496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-01</th>\n",
       "      <td>-38.593959</td>\n",
       "      <td>-15.031997</td>\n",
       "      <td>-76.808900</td>\n",
       "      <td>43.104644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-02</th>\n",
       "      <td>-38.273346</td>\n",
       "      <td>-14.574022</td>\n",
       "      <td>-77.654011</td>\n",
       "      <td>41.356871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-03</th>\n",
       "      <td>-38.382406</td>\n",
       "      <td>-14.361195</td>\n",
       "      <td>-78.640685</td>\n",
       "      <td>41.204238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-04</th>\n",
       "      <td>-38.401388</td>\n",
       "      <td>-13.844929</td>\n",
       "      <td>-77.205115</td>\n",
       "      <td>40.843013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-05</th>\n",
       "      <td>-38.113559</td>\n",
       "      <td>-14.084699</td>\n",
       "      <td>-76.362048</td>\n",
       "      <td>41.973272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-06</th>\n",
       "      <td>-38.758620</td>\n",
       "      <td>-14.541632</td>\n",
       "      <td>-77.561806</td>\n",
       "      <td>41.629165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-07</th>\n",
       "      <td>-38.010311</td>\n",
       "      <td>-14.673665</td>\n",
       "      <td>-76.696958</td>\n",
       "      <td>41.095907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-08</th>\n",
       "      <td>-37.216409</td>\n",
       "      <td>-13.984856</td>\n",
       "      <td>-77.244416</td>\n",
       "      <td>40.363504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-09</th>\n",
       "      <td>-37.729941</td>\n",
       "      <td>-14.216131</td>\n",
       "      <td>-78.248521</td>\n",
       "      <td>42.014916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-10</th>\n",
       "      <td>-37.661044</td>\n",
       "      <td>-14.303651</td>\n",
       "      <td>-77.574108</td>\n",
       "      <td>40.230393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-11</th>\n",
       "      <td>-35.672480</td>\n",
       "      <td>-14.862236</td>\n",
       "      <td>-77.236224</td>\n",
       "      <td>39.481927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-12</th>\n",
       "      <td>-35.021623</td>\n",
       "      <td>-13.298113</td>\n",
       "      <td>-77.886686</td>\n",
       "      <td>40.080035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-13</th>\n",
       "      <td>-33.644029</td>\n",
       "      <td>-13.081617</td>\n",
       "      <td>-77.194291</td>\n",
       "      <td>40.807073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-14</th>\n",
       "      <td>-32.314466</td>\n",
       "      <td>-12.171955</td>\n",
       "      <td>-77.633082</td>\n",
       "      <td>40.270444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-15</th>\n",
       "      <td>-32.414417</td>\n",
       "      <td>-11.098192</td>\n",
       "      <td>-76.014992</td>\n",
       "      <td>41.253721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-16</th>\n",
       "      <td>-32.397789</td>\n",
       "      <td>-10.006114</td>\n",
       "      <td>-76.986016</td>\n",
       "      <td>40.716936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-17</th>\n",
       "      <td>-34.503392</td>\n",
       "      <td>-8.802649</td>\n",
       "      <td>-78.136208</td>\n",
       "      <td>40.655025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-18</th>\n",
       "      <td>-34.508642</td>\n",
       "      <td>-9.096068</td>\n",
       "      <td>-79.447899</td>\n",
       "      <td>40.363022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-19</th>\n",
       "      <td>-32.806020</td>\n",
       "      <td>-10.482351</td>\n",
       "      <td>-78.196450</td>\n",
       "      <td>41.164869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-20</th>\n",
       "      <td>-32.879839</td>\n",
       "      <td>-9.779931</td>\n",
       "      <td>-77.746712</td>\n",
       "      <td>41.898806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-21</th>\n",
       "      <td>-30.896324</td>\n",
       "      <td>-8.729997</td>\n",
       "      <td>-77.210806</td>\n",
       "      <td>42.025220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-22</th>\n",
       "      <td>-29.928935</td>\n",
       "      <td>-9.748260</td>\n",
       "      <td>-76.134071</td>\n",
       "      <td>40.533357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-23</th>\n",
       "      <td>-30.557811</td>\n",
       "      <td>-10.019924</td>\n",
       "      <td>-76.301156</td>\n",
       "      <td>39.887543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-24</th>\n",
       "      <td>-30.306213</td>\n",
       "      <td>-11.042034</td>\n",
       "      <td>-75.510902</td>\n",
       "      <td>40.625243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-25</th>\n",
       "      <td>-29.976402</td>\n",
       "      <td>-11.342606</td>\n",
       "      <td>-75.460807</td>\n",
       "      <td>39.197878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-26</th>\n",
       "      <td>-28.964423</td>\n",
       "      <td>-10.467306</td>\n",
       "      <td>-76.033409</td>\n",
       "      <td>39.311493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    A          B          C          D\n",
       "2000-01-01  -1.225072   0.801684  -0.379105  -1.239740\n",
       "2000-01-02  -1.637213   0.674406   0.041368  -1.748890\n",
       "2000-01-03  -2.025446  -0.213028  -0.387017  -0.046392\n",
       "2000-01-04  -1.376932   0.938919  -0.141218   0.475459\n",
       "2000-01-05  -0.263447   1.447945   0.146585   0.191720\n",
       "2000-01-06   0.103593   2.440335  -1.329681   2.303396\n",
       "2000-01-07   0.034375   4.027924  -0.807556   2.416217\n",
       "2000-01-08  -0.234895   2.608389   0.007215   3.007350\n",
       "2000-01-09  -1.232289   3.889698   1.914607   5.014900\n",
       "2000-01-10  -2.862024   4.299781   1.699958   5.410799\n",
       "2000-01-11  -2.562192   3.565857   1.861770   5.018266\n",
       "2000-01-12  -2.719852   1.728034   3.230262   3.968318\n",
       "2000-01-13  -2.669539   4.009945   2.345474   5.123213\n",
       "2000-01-14  -3.334017   4.136389   1.291245   6.834034\n",
       "2000-01-15  -4.187475   4.304222   0.619532   6.352414\n",
       "2000-01-16  -4.570406   3.448199   1.485252   6.597377\n",
       "2000-01-17  -4.422479   4.541083  -0.042886   5.793299\n",
       "2000-01-18  -6.306480   4.054810   0.640942   7.139785\n",
       "2000-01-19  -6.677662   3.803965  -0.431401   7.089509\n",
       "2000-01-20  -5.351948   3.878014  -1.726403   6.810476\n",
       "2000-01-21  -5.423939   5.681259  -1.147128   6.777682\n",
       "2000-01-22  -6.024956   5.282127  -0.184408   7.085197\n",
       "2000-01-23  -6.848976   5.652299  -0.810096   7.338369\n",
       "2000-01-24  -7.040223   5.870063  -0.011249   8.173743\n",
       "2000-01-25  -6.247456   5.549304   1.900613   9.681444\n",
       "2000-01-26  -5.782543   5.070565   0.825723   9.962603\n",
       "2000-01-27  -5.411138   5.974291   1.647352   9.910227\n",
       "2000-01-28  -5.024961   4.659042   1.636149  10.831800\n",
       "2000-01-29  -4.274795   5.062583   2.618473  10.239645\n",
       "2000-01-30  -3.603870   5.140397   1.277127  10.700395\n",
       "...               ...        ...        ...        ...\n",
       "2002-08-28 -34.150385 -14.143460 -77.495464  42.058465\n",
       "2002-08-29 -35.772792 -14.631071 -77.788227  41.126313\n",
       "2002-08-30 -36.629357 -15.356738 -77.515531  42.397074\n",
       "2002-08-31 -37.335796 -15.028817 -77.640279  42.802496\n",
       "2002-09-01 -38.593959 -15.031997 -76.808900  43.104644\n",
       "2002-09-02 -38.273346 -14.574022 -77.654011  41.356871\n",
       "2002-09-03 -38.382406 -14.361195 -78.640685  41.204238\n",
       "2002-09-04 -38.401388 -13.844929 -77.205115  40.843013\n",
       "2002-09-05 -38.113559 -14.084699 -76.362048  41.973272\n",
       "2002-09-06 -38.758620 -14.541632 -77.561806  41.629165\n",
       "2002-09-07 -38.010311 -14.673665 -76.696958  41.095907\n",
       "2002-09-08 -37.216409 -13.984856 -77.244416  40.363504\n",
       "2002-09-09 -37.729941 -14.216131 -78.248521  42.014916\n",
       "2002-09-10 -37.661044 -14.303651 -77.574108  40.230393\n",
       "2002-09-11 -35.672480 -14.862236 -77.236224  39.481927\n",
       "2002-09-12 -35.021623 -13.298113 -77.886686  40.080035\n",
       "2002-09-13 -33.644029 -13.081617 -77.194291  40.807073\n",
       "2002-09-14 -32.314466 -12.171955 -77.633082  40.270444\n",
       "2002-09-15 -32.414417 -11.098192 -76.014992  41.253721\n",
       "2002-09-16 -32.397789 -10.006114 -76.986016  40.716936\n",
       "2002-09-17 -34.503392  -8.802649 -78.136208  40.655025\n",
       "2002-09-18 -34.508642  -9.096068 -79.447899  40.363022\n",
       "2002-09-19 -32.806020 -10.482351 -78.196450  41.164869\n",
       "2002-09-20 -32.879839  -9.779931 -77.746712  41.898806\n",
       "2002-09-21 -30.896324  -8.729997 -77.210806  42.025220\n",
       "2002-09-22 -29.928935  -9.748260 -76.134071  40.533357\n",
       "2002-09-23 -30.557811 -10.019924 -76.301156  39.887543\n",
       "2002-09-24 -30.306213 -11.042034 -75.510902  40.625243\n",
       "2002-09-25 -29.976402 -11.342606 -75.460807  39.197878\n",
       "2002-09-26 -28.964423 -10.467306 -76.033409  39.311493\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_hdf('foo.h5','df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_excel('foo.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>-1.225072</td>\n",
       "      <td>0.801684</td>\n",
       "      <td>-0.379105</td>\n",
       "      <td>-1.239740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-02</th>\n",
       "      <td>-1.637213</td>\n",
       "      <td>0.674406</td>\n",
       "      <td>0.041368</td>\n",
       "      <td>-1.748890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>-2.025446</td>\n",
       "      <td>-0.213028</td>\n",
       "      <td>-0.387017</td>\n",
       "      <td>-0.046392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>-1.376932</td>\n",
       "      <td>0.938919</td>\n",
       "      <td>-0.141218</td>\n",
       "      <td>0.475459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>-0.263447</td>\n",
       "      <td>1.447945</td>\n",
       "      <td>0.146585</td>\n",
       "      <td>0.191720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>0.103593</td>\n",
       "      <td>2.440335</td>\n",
       "      <td>-1.329681</td>\n",
       "      <td>2.303396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>0.034375</td>\n",
       "      <td>4.027924</td>\n",
       "      <td>-0.807556</td>\n",
       "      <td>2.416217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-08</th>\n",
       "      <td>-0.234895</td>\n",
       "      <td>2.608389</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>3.007350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-09</th>\n",
       "      <td>-1.232289</td>\n",
       "      <td>3.889698</td>\n",
       "      <td>1.914607</td>\n",
       "      <td>5.014900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>-2.862024</td>\n",
       "      <td>4.299781</td>\n",
       "      <td>1.699958</td>\n",
       "      <td>5.410799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-11</th>\n",
       "      <td>-2.562192</td>\n",
       "      <td>3.565857</td>\n",
       "      <td>1.861770</td>\n",
       "      <td>5.018266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-12</th>\n",
       "      <td>-2.719852</td>\n",
       "      <td>1.728034</td>\n",
       "      <td>3.230262</td>\n",
       "      <td>3.968318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-13</th>\n",
       "      <td>-2.669539</td>\n",
       "      <td>4.009945</td>\n",
       "      <td>2.345474</td>\n",
       "      <td>5.123213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-14</th>\n",
       "      <td>-3.334017</td>\n",
       "      <td>4.136389</td>\n",
       "      <td>1.291245</td>\n",
       "      <td>6.834034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-15</th>\n",
       "      <td>-4.187475</td>\n",
       "      <td>4.304222</td>\n",
       "      <td>0.619532</td>\n",
       "      <td>6.352414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-16</th>\n",
       "      <td>-4.570406</td>\n",
       "      <td>3.448199</td>\n",
       "      <td>1.485252</td>\n",
       "      <td>6.597377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-17</th>\n",
       "      <td>-4.422479</td>\n",
       "      <td>4.541083</td>\n",
       "      <td>-0.042886</td>\n",
       "      <td>5.793299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-18</th>\n",
       "      <td>-6.306480</td>\n",
       "      <td>4.054810</td>\n",
       "      <td>0.640942</td>\n",
       "      <td>7.139785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-19</th>\n",
       "      <td>-6.677662</td>\n",
       "      <td>3.803965</td>\n",
       "      <td>-0.431401</td>\n",
       "      <td>7.089509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-20</th>\n",
       "      <td>-5.351948</td>\n",
       "      <td>3.878014</td>\n",
       "      <td>-1.726403</td>\n",
       "      <td>6.810476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-21</th>\n",
       "      <td>-5.423939</td>\n",
       "      <td>5.681259</td>\n",
       "      <td>-1.147128</td>\n",
       "      <td>6.777682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-22</th>\n",
       "      <td>-6.024956</td>\n",
       "      <td>5.282127</td>\n",
       "      <td>-0.184408</td>\n",
       "      <td>7.085197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-23</th>\n",
       "      <td>-6.848976</td>\n",
       "      <td>5.652299</td>\n",
       "      <td>-0.810096</td>\n",
       "      <td>7.338369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-24</th>\n",
       "      <td>-7.040223</td>\n",
       "      <td>5.870063</td>\n",
       "      <td>-0.011249</td>\n",
       "      <td>8.173743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-25</th>\n",
       "      <td>-6.247456</td>\n",
       "      <td>5.549304</td>\n",
       "      <td>1.900613</td>\n",
       "      <td>9.681444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-26</th>\n",
       "      <td>-5.782543</td>\n",
       "      <td>5.070565</td>\n",
       "      <td>0.825723</td>\n",
       "      <td>9.962603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-27</th>\n",
       "      <td>-5.411138</td>\n",
       "      <td>5.974291</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>9.910227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-28</th>\n",
       "      <td>-5.024961</td>\n",
       "      <td>4.659042</td>\n",
       "      <td>1.636149</td>\n",
       "      <td>10.831800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-29</th>\n",
       "      <td>-4.274795</td>\n",
       "      <td>5.062583</td>\n",
       "      <td>2.618473</td>\n",
       "      <td>10.239645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30</th>\n",
       "      <td>-3.603870</td>\n",
       "      <td>5.140397</td>\n",
       "      <td>1.277127</td>\n",
       "      <td>10.700395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-08-28</th>\n",
       "      <td>-34.150385</td>\n",
       "      <td>-14.143460</td>\n",
       "      <td>-77.495464</td>\n",
       "      <td>42.058465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-08-29</th>\n",
       "      <td>-35.772792</td>\n",
       "      <td>-14.631071</td>\n",
       "      <td>-77.788227</td>\n",
       "      <td>41.126313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-08-30</th>\n",
       "      <td>-36.629357</td>\n",
       "      <td>-15.356738</td>\n",
       "      <td>-77.515531</td>\n",
       "      <td>42.397074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-08-31</th>\n",
       "      <td>-37.335796</td>\n",
       "      <td>-15.028817</td>\n",
       "      <td>-77.640279</td>\n",
       "      <td>42.802496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-01</th>\n",
       "      <td>-38.593959</td>\n",
       "      <td>-15.031997</td>\n",
       "      <td>-76.808900</td>\n",
       "      <td>43.104644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-02</th>\n",
       "      <td>-38.273346</td>\n",
       "      <td>-14.574022</td>\n",
       "      <td>-77.654011</td>\n",
       "      <td>41.356871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-03</th>\n",
       "      <td>-38.382406</td>\n",
       "      <td>-14.361195</td>\n",
       "      <td>-78.640685</td>\n",
       "      <td>41.204238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-04</th>\n",
       "      <td>-38.401388</td>\n",
       "      <td>-13.844929</td>\n",
       "      <td>-77.205115</td>\n",
       "      <td>40.843013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-05</th>\n",
       "      <td>-38.113559</td>\n",
       "      <td>-14.084699</td>\n",
       "      <td>-76.362048</td>\n",
       "      <td>41.973272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-06</th>\n",
       "      <td>-38.758620</td>\n",
       "      <td>-14.541632</td>\n",
       "      <td>-77.561806</td>\n",
       "      <td>41.629165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-07</th>\n",
       "      <td>-38.010311</td>\n",
       "      <td>-14.673665</td>\n",
       "      <td>-76.696958</td>\n",
       "      <td>41.095907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-08</th>\n",
       "      <td>-37.216409</td>\n",
       "      <td>-13.984856</td>\n",
       "      <td>-77.244416</td>\n",
       "      <td>40.363504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-09</th>\n",
       "      <td>-37.729941</td>\n",
       "      <td>-14.216131</td>\n",
       "      <td>-78.248521</td>\n",
       "      <td>42.014916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-10</th>\n",
       "      <td>-37.661044</td>\n",
       "      <td>-14.303651</td>\n",
       "      <td>-77.574108</td>\n",
       "      <td>40.230393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-11</th>\n",
       "      <td>-35.672480</td>\n",
       "      <td>-14.862236</td>\n",
       "      <td>-77.236224</td>\n",
       "      <td>39.481927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-12</th>\n",
       "      <td>-35.021623</td>\n",
       "      <td>-13.298113</td>\n",
       "      <td>-77.886686</td>\n",
       "      <td>40.080035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-13</th>\n",
       "      <td>-33.644029</td>\n",
       "      <td>-13.081617</td>\n",
       "      <td>-77.194291</td>\n",
       "      <td>40.807073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-14</th>\n",
       "      <td>-32.314466</td>\n",
       "      <td>-12.171955</td>\n",
       "      <td>-77.633082</td>\n",
       "      <td>40.270444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-15</th>\n",
       "      <td>-32.414417</td>\n",
       "      <td>-11.098192</td>\n",
       "      <td>-76.014992</td>\n",
       "      <td>41.253721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-16</th>\n",
       "      <td>-32.397789</td>\n",
       "      <td>-10.006114</td>\n",
       "      <td>-76.986016</td>\n",
       "      <td>40.716936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-17</th>\n",
       "      <td>-34.503392</td>\n",
       "      <td>-8.802649</td>\n",
       "      <td>-78.136208</td>\n",
       "      <td>40.655025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-18</th>\n",
       "      <td>-34.508642</td>\n",
       "      <td>-9.096068</td>\n",
       "      <td>-79.447899</td>\n",
       "      <td>40.363022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-19</th>\n",
       "      <td>-32.806020</td>\n",
       "      <td>-10.482351</td>\n",
       "      <td>-78.196450</td>\n",
       "      <td>41.164869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-20</th>\n",
       "      <td>-32.879839</td>\n",
       "      <td>-9.779931</td>\n",
       "      <td>-77.746712</td>\n",
       "      <td>41.898806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-21</th>\n",
       "      <td>-30.896324</td>\n",
       "      <td>-8.729997</td>\n",
       "      <td>-77.210806</td>\n",
       "      <td>42.025220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-22</th>\n",
       "      <td>-29.928935</td>\n",
       "      <td>-9.748260</td>\n",
       "      <td>-76.134071</td>\n",
       "      <td>40.533357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-23</th>\n",
       "      <td>-30.557811</td>\n",
       "      <td>-10.019924</td>\n",
       "      <td>-76.301156</td>\n",
       "      <td>39.887543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-24</th>\n",
       "      <td>-30.306213</td>\n",
       "      <td>-11.042034</td>\n",
       "      <td>-75.510902</td>\n",
       "      <td>40.625243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-25</th>\n",
       "      <td>-29.976402</td>\n",
       "      <td>-11.342606</td>\n",
       "      <td>-75.460807</td>\n",
       "      <td>39.197878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-26</th>\n",
       "      <td>-28.964423</td>\n",
       "      <td>-10.467306</td>\n",
       "      <td>-76.033409</td>\n",
       "      <td>39.311493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    A          B          C          D\n",
       "2000-01-01  -1.225072   0.801684  -0.379105  -1.239740\n",
       "2000-01-02  -1.637213   0.674406   0.041368  -1.748890\n",
       "2000-01-03  -2.025446  -0.213028  -0.387017  -0.046392\n",
       "2000-01-04  -1.376932   0.938919  -0.141218   0.475459\n",
       "2000-01-05  -0.263447   1.447945   0.146585   0.191720\n",
       "2000-01-06   0.103593   2.440335  -1.329681   2.303396\n",
       "2000-01-07   0.034375   4.027924  -0.807556   2.416217\n",
       "2000-01-08  -0.234895   2.608389   0.007215   3.007350\n",
       "2000-01-09  -1.232289   3.889698   1.914607   5.014900\n",
       "2000-01-10  -2.862024   4.299781   1.699958   5.410799\n",
       "2000-01-11  -2.562192   3.565857   1.861770   5.018266\n",
       "2000-01-12  -2.719852   1.728034   3.230262   3.968318\n",
       "2000-01-13  -2.669539   4.009945   2.345474   5.123213\n",
       "2000-01-14  -3.334017   4.136389   1.291245   6.834034\n",
       "2000-01-15  -4.187475   4.304222   0.619532   6.352414\n",
       "2000-01-16  -4.570406   3.448199   1.485252   6.597377\n",
       "2000-01-17  -4.422479   4.541083  -0.042886   5.793299\n",
       "2000-01-18  -6.306480   4.054810   0.640942   7.139785\n",
       "2000-01-19  -6.677662   3.803965  -0.431401   7.089509\n",
       "2000-01-20  -5.351948   3.878014  -1.726403   6.810476\n",
       "2000-01-21  -5.423939   5.681259  -1.147128   6.777682\n",
       "2000-01-22  -6.024956   5.282127  -0.184408   7.085197\n",
       "2000-01-23  -6.848976   5.652299  -0.810096   7.338369\n",
       "2000-01-24  -7.040223   5.870063  -0.011249   8.173743\n",
       "2000-01-25  -6.247456   5.549304   1.900613   9.681444\n",
       "2000-01-26  -5.782543   5.070565   0.825723   9.962603\n",
       "2000-01-27  -5.411138   5.974291   1.647352   9.910227\n",
       "2000-01-28  -5.024961   4.659042   1.636149  10.831800\n",
       "2000-01-29  -4.274795   5.062583   2.618473  10.239645\n",
       "2000-01-30  -3.603870   5.140397   1.277127  10.700395\n",
       "...               ...        ...        ...        ...\n",
       "2002-08-28 -34.150385 -14.143460 -77.495464  42.058465\n",
       "2002-08-29 -35.772792 -14.631071 -77.788227  41.126313\n",
       "2002-08-30 -36.629357 -15.356738 -77.515531  42.397074\n",
       "2002-08-31 -37.335796 -15.028817 -77.640279  42.802496\n",
       "2002-09-01 -38.593959 -15.031997 -76.808900  43.104644\n",
       "2002-09-02 -38.273346 -14.574022 -77.654011  41.356871\n",
       "2002-09-03 -38.382406 -14.361195 -78.640685  41.204238\n",
       "2002-09-04 -38.401388 -13.844929 -77.205115  40.843013\n",
       "2002-09-05 -38.113559 -14.084699 -76.362048  41.973272\n",
       "2002-09-06 -38.758620 -14.541632 -77.561806  41.629165\n",
       "2002-09-07 -38.010311 -14.673665 -76.696958  41.095907\n",
       "2002-09-08 -37.216409 -13.984856 -77.244416  40.363504\n",
       "2002-09-09 -37.729941 -14.216131 -78.248521  42.014916\n",
       "2002-09-10 -37.661044 -14.303651 -77.574108  40.230393\n",
       "2002-09-11 -35.672480 -14.862236 -77.236224  39.481927\n",
       "2002-09-12 -35.021623 -13.298113 -77.886686  40.080035\n",
       "2002-09-13 -33.644029 -13.081617 -77.194291  40.807073\n",
       "2002-09-14 -32.314466 -12.171955 -77.633082  40.270444\n",
       "2002-09-15 -32.414417 -11.098192 -76.014992  41.253721\n",
       "2002-09-16 -32.397789 -10.006114 -76.986016  40.716936\n",
       "2002-09-17 -34.503392  -8.802649 -78.136208  40.655025\n",
       "2002-09-18 -34.508642  -9.096068 -79.447899  40.363022\n",
       "2002-09-19 -32.806020 -10.482351 -78.196450  41.164869\n",
       "2002-09-20 -32.879839  -9.779931 -77.746712  41.898806\n",
       "2002-09-21 -30.896324  -8.729997 -77.210806  42.025220\n",
       "2002-09-22 -29.928935  -9.748260 -76.134071  40.533357\n",
       "2002-09-23 -30.557811 -10.019924 -76.301156  39.887543\n",
       "2002-09-24 -30.306213 -11.042034 -75.510902  40.625243\n",
       "2002-09-25 -29.976402 -11.342606 -75.460807  39.197878\n",
       "2002-09-26 -28.964423 -10.467306 -76.033409  39.311493\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_excel('foo.xlsx', 'Sheet1', index_col=None, na_values=['NA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
